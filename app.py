import streamlit as st
import pandas as pd
from datetime import date, timedelta
import tempfile
import io
import os
from html import escape
from pathlib import Path

# ============ S3 ì—°ë™ ============

import boto3
from botocore.exceptions import ClientError

S3_BUCKET = "rec-and-ship"
S3_KEY_EXCEL = "bulk-ledger.xlsx"   # ê¸°ì¡´ ì—‘ì…€
S3_KEY_LABEL = "label_db.csv"       # ğŸ”¸ ë¼ë²¨ ì „ìš© DB (CSV)

def get_s3_client():
    try:
        return boto3.client(
            "s3",
            aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
            aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
            region_name="ap-northeast-2",
        )
    except Exception as e:
        st.error(f"S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

s3_client = get_s3_client()


@st.cache_data(show_spinner=True)
def load_file_from_s3():
    """S3ì— ì—‘ì…€ íŒŒì¼ì´ ìˆìœ¼ë©´ bytesë¡œ ì½ì–´ì˜¨ë‹¤."""
    if s3_client is None:
        return None
    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY_EXCEL)  # ğŸ”´ ì—¬ê¸° S3_KEY â†’ S3_KEY_EXCEL ë¡œ ìˆ˜ì •
        return obj["Body"].read()
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            return None
        st.error(f"S3ì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

@st.cache_data(show_spinner=True)
def load_label_db_from_s3() -> pd.DataFrame:
    """
    S3ì—ì„œ ë¼ë²¨ DB CSVë¥¼ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜.
    ì—†ìœ¼ë©´ ë¹ˆ DF ë°˜í™˜.
    """
    if s3_client is None:
        return pd.DataFrame()

    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY_LABEL)
        data = obj["Body"].read().decode("utf-8-sig")
        df = pd.read_csv(io.StringIO(data))
        return df
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            # ì•„ì§ ë¼ë²¨ DBë¥¼ ë§Œë“  ì ì´ ì—†ìŒ
            return pd.DataFrame()
        st.error(f"S3ì—ì„œ ë¼ë²¨ DBë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()


def save_label_db_to_s3(df: pd.DataFrame):
    """
    í˜„ì¬ ë¼ë²¨ DB DataFrameì„ S3ì— CSVë¡œ ì €ì¥.
    """
    if s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¼ë²¨ DBë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    csv_buf = io.StringIO()
    df.to_csv(csv_buf, index=False)
    s3_client.put_object(
        Bucket=S3_BUCKET,
        Key=S3_KEY_LABEL,
        Body=csv_buf.getvalue().encode("utf-8-sig"),
    )
    # ìºì‹œëœ ë¼ë²¨ DB ë¬´íš¨í™”
    load_label_db_from_s3.clear()


# PDF ìƒì„±ìš© (reportlab ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ì²˜ë¦¬)
try:
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.platypus import (
        SimpleDocTemplate,
        Table,
        TableStyle,
        Paragraph,
        Spacer,
    )
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    KOREAN_FONT_NAME = "MalgunGothic"

    # ğŸ”¹ app.py ê¸°ì¤€ìœ¼ë¡œ font/malgun.ttf ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê¸°
    FONT_PATH = os.path.join(os.path.dirname(__file__), "font", "malgun.ttf")

    if not os.path.exists(FONT_PATH):
        st.write("âš ï¸ í°íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤:", FONT_PATH)
        KOREAN_FONT_NAME = "Helvetica"
    else:
        try:
            pdfmetrics.registerFont(TTFont(KOREAN_FONT_NAME, FONT_PATH))
        except Exception as e:
            st.write("âš ï¸ í°íŠ¸ ë¡œë”© ì‹¤íŒ¨:", repr(e))
            KOREAN_FONT_NAME = "Helvetica"

    REPORTLAB_AVAILABLE = True
except ModuleNotFoundError:
    REPORTLAB_AVAILABLE = False
    KOREAN_FONT_NAME = "Helvetica"


st.set_page_config(page_title="ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_data
def load_excel(file_bytes: bytes):
    """bytes ë˜ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ë°›ì•„ ì „ì²´ ì‹œíŠ¸ë¥¼ dictë¡œ ë°˜í™˜"""
    xls = pd.ExcelFile(file_bytes)
    sheets = {}
    for sheet_name in xls.sheet_names:
        try:
            sheets[sheet_name] = pd.read_excel(xls, sheet_name)
        except Exception:
            pass
    return sheets


def get_week_of_month(d: date) -> str:
    """ê°„ë‹¨íˆ: 1~7ì¼=1ì£¼ì°¨, 8~14=2ì£¼ì°¨, ..."""
    week_no = (d.day - 1) // 7 + 1
    return f"{d.month}ì›”{week_no}ì£¼ì°¨"


def ensure_session_df(key: str, columns: list):
    if key not in st.session_state:
        st.session_state[key] = pd.DataFrame(columns=columns)
    return st.session_state[key]


def excel_col_to_index(col_letter: str) -> int:
    """ì—‘ì…€ ì—´ ë¬¸ì(A, B, ... AA, AB...)ë¥¼ 0-base indexë¡œ ë³€í™˜"""
    col_letter = col_letter.upper()
    result = 0
    for ch in col_letter:
        if not ("A" <= ch <= "Z"):
            continue
        result = result * 26 + (ord(ch) - ord("A") + 1)
    return result - 1  # 0-base


def pick_col(df: pd.DataFrame, letter: str, preferred_names: list):
    """
    ìš°ì„  ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ì—‘ì…€ ì—´ ìœ„ì¹˜(letter)ë¡œ ì°¾ê¸°
    (preferred_names ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©)
    """
    cols = list(df.columns)
    for name in preferred_names:
        if name in df.columns:
            return name
    idx = excel_col_to_index(letter)
    if 0 <= idx < len(cols):
        return cols[idx]
    return None


def safe_num(x):
    """ìˆ«ìê°€ ì•„ë‹ˆë©´ ìµœëŒ€í•œ floatìœ¼ë¡œ ë³€í™˜, ì•ˆ ë˜ë©´ 0"""
    try:
        if pd.isna(x):
            return 0
    except Exception:
        pass
    if isinstance(x, (int, float)):
        return float(x)
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return 0.0

import re

LABEL_TYPES = [
    "ë´‰í•©ë¼ë²¨",
    "ë¦¬ì‹¤ëŸ¬ë¸”ë¼ë²¨",
    "ìš©ê¸°ë¼ë²¨",
    "ìƒë‹¨ë¼ë²¨",
    "ìš©ê¸°ì „ë©´ë¼ë²¨",
    "ìš©ê¸°í›„ë©´ë¼ë²¨",
    "ìš©ê¸°ìƒë‹¨ë¼ë²¨",
    "ìš©ê¸°ìš°ì¸¡ë¼ë²¨",
    "ìš©ê¸°ì¢Œì¸¡ë¼ë²¨",
    "ì— ë¸”ëŸ¼",
    "ì‹¤ë§ì§€",
    "ë§ë°©ë¼ë²¨",
]

def parse_label_db(file_obj) -> pd.DataFrame:
    """
    ê¸°ì¡´ 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤ ì§€ê´€ë¬´ê²Œ+ìˆ˜ëŸ‰ ê³„ì‚°ê¸°_*.xlsx' íŒŒì¼ì—ì„œ
    ë¼ë²¨ DBë¥¼ ë½‘ì•„ì„œ í†µì¼ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ë¦¬í•œë‹¤.

    - ì‚¬ìš© ì‹œíŠ¸: 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤'
    - í—¤ë” í–‰: 5ë²ˆì§¸ ì¤„(0-base index=4)
    - ì£¼ìš” ì»¬ëŸ¼ ë§¤í•‘:
        No.        â†’ ìƒ˜í”Œë²ˆí˜¸
        í’ˆë²ˆ       â†’ í’ˆë²ˆ
        í’ˆëª…       â†’ í’ˆëª…
        êµ¬ë¶„       â†’ êµ¬ë¶„
        ì‹¤ë¬´ê²Œ     â†’ ì§€ê´€ë¬´ê²Œ
        ì¶”ì •ê°’     â†’ ì¶”ì •ê°’
        ì˜¤ì°¨       â†’ ì˜¤ì°¨
        ì™¸ê²½       â†’ ì™¸ê²½
        ë‚´ê²½       â†’ ë‚´ê²½
        ë†’ì´       â†’ ë†’ì´
        1Rë¬´ê²Œ     â†’ 1Rë¬´ê²Œ
        ê¸°ì¤€ ìƒ˜í”Œ  â†’ ê¸°ì¤€ìƒ˜í”Œ
        ìƒ˜í”Œë¬´ê²Œ   â†’ ìƒ˜í”Œë¬´ê²Œ
    """
    try:
        xls = pd.ExcelFile(file_obj)
    except Exception as e:
        st.error(f"ë¼ë²¨ ì—‘ì…€ íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    # ì‹œíŠ¸ ì´ë¦„ ì°¾ê¸° (ì •í™•íˆ 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤'ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ìµœìš°ì„ )
    sheet_name = None
    for s in xls.sheet_names:
        if "ë¼ë²¨" in s and "ìŠ¤í‹°ì»¤" in s:
            sheet_name = s
            break
    if sheet_name is None:
        # ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸
        sheet_name = xls.sheet_names[0]

    # header=4 â†’ 5ë²ˆì§¸ ì¤„ì„ í—¤ë”ë¡œ ì‚¬ìš© (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ì¤€)
    try:
        df_raw = pd.read_excel(xls, sheet_name=sheet_name, header=4)
    except Exception as e:
        st.error(f"ë¼ë²¨ ì‹œíŠ¸ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
    rename_map = {}
    cols = list(df_raw.columns)

    for c in cols:
        cname = str(c).strip()
        if cname == "No.":
            rename_map[c] = "ìƒ˜í”Œë²ˆí˜¸"
        elif cname == "í’ˆë²ˆ":
            rename_map[c] = "í’ˆë²ˆ"
        elif cname == "í’ˆëª…":
            rename_map[c] = "í’ˆëª…"
        elif cname == "êµ¬ë¶„":
            rename_map[c] = "êµ¬ë¶„"
        elif cname == "ì‹¤ë¬´ê²Œ":
            rename_map[c] = "ì§€ê´€ë¬´ê²Œ"
        elif cname == "ì¶”ì •ê°’":
            rename_map[c] = "ì¶”ì •ê°’"
        elif cname == "ì˜¤ì°¨":
            rename_map[c] = "ì˜¤ì°¨"
        elif cname == "ì™¸ê²½":
            rename_map[c] = "ì™¸ê²½"
        elif cname == "ë‚´ê²½":
            rename_map[c] = "ë‚´ê²½"
        elif cname == "ë†’ì´":
            rename_map[c] = "ë†’ì´"
        elif cname == "1Rë¬´ê²Œ":
            rename_map[c] = "1Rë¬´ê²Œ"
        elif cname.replace(" ", "") in ("ê¸°ì¤€ìƒ˜í”Œ", "ê¸°ì¤€ìƒ˜í”Œ"):
            rename_map[c] = "ê¸°ì¤€ìƒ˜í”Œ"
        elif cname.replace(" ", "") in ("ìƒ˜í”Œë¬´ê²Œ", "ìƒ˜í”Œë¬´ê²Œ"):
            rename_map[c] = "ìƒ˜í”Œë¬´ê²Œ"

    df = df_raw.rename(columns=rename_map)

    # ìš°ë¦¬ê°€ ì“¸ ì»¬ëŸ¼ë§Œ ê³¨ë¼ì„œ ìƒˆ DF êµ¬ì„±
    base_cols = [
        "ìƒ˜í”Œë²ˆí˜¸",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "êµ¬ë¶„",
        "ì§€ê´€ë¬´ê²Œ",
        "ì¶”ì •ê°’",
        "ì˜¤ì°¨",
        "ì™¸ê²½",
        "ë‚´ê²½",
        "ë†’ì´",
        "1Rë¬´ê²Œ",
        "ê¸°ì¤€ìƒ˜í”Œ",
        "ìƒ˜í”Œë¬´ê²Œ",
    ]
    existing = [c for c in base_cols if c in df.columns]
    df_out = df[existing].copy()

    # êµ¬ë¶„ì´ ì •í•´ì§„ 12ê°œ ì¤‘ í•˜ë‚˜ì¸ í–‰ë§Œ ì‚¬ìš© (ì“°ë ˆê¸° í–‰ ì œê±° ìš©ë„)
    if "êµ¬ë¶„" in df_out.columns:
        df_out = df_out[df_out["êµ¬ë¶„"].isin(LABEL_TYPES)]

    # í’ˆë²ˆ/í’ˆëª… ë‘˜ ë‹¤ ì—†ëŠ” í–‰ì€ ë²„ë¦¬ê¸°
    if "í’ˆë²ˆ" in df_out.columns and "í’ˆëª…" in df_out.columns:
        df_out = df_out.dropna(subset=["í’ˆë²ˆ", "í’ˆëª…"], how="all")

    # ìˆ«ì ì»¬ëŸ¼ float ë³€í™˜
    num_cols = ["ì§€ê´€ë¬´ê²Œ", "ì¶”ì •ê°’", "ì˜¤ì°¨", "ì™¸ê²½", "ë‚´ê²½", "ë†’ì´", "1Rë¬´ê²Œ", "ìƒ˜í”Œë¬´ê²Œ"]
    for c in num_cols:
        if c in df_out.columns:
            df_out[c] = df_out[c].apply(safe_num)

    # ì¸ë±ìŠ¤ ë¦¬ì…‹
    df_out = df_out.reset_index(drop=True)

    return df_out


def parse_label_sample_count(text: str) -> float:
    """
    ê¸°ì¤€ìƒ˜í”Œ ë¬¸ìì—´ì—ì„œ 'ëª‡ ë§¤'ì¸ì§€ ìˆ«ìë§Œ ë½‘ì•„ì„œ floatìœ¼ë¡œ ë°˜í™˜.
    ì˜ˆ) '4ë§¤' â†’ 4, '2ë§¤(ì•„ì´ë§ˆí¬)' â†’ 2, '1ë§¤' â†’ 1
    ìˆ«ìê°€ ì—†ìœ¼ë©´ 1ë¡œ ì²˜ë¦¬.
    """
    if pd.isna(text):
        return 1.0
    s = str(text)
    m = re.search(r"(\d+)", s)
    if not m:
        return 1.0
    try:
        return float(m.group(1))
    except Exception:
        return 1.0

# ë¼ë²¨ DFë¥¼ í•œ ë²ˆ ì •ë¦¬í•´ ì£¼ëŠ” ê³µí†µ í•¨ìˆ˜
def normalize_label_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë¼ë²¨ DB DataFrameì„ í‘œì¤€ í˜•íƒœë¡œ ì •ë¦¬í•œë‹¤.

    - í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
    - ìˆ«ì ì»¬ëŸ¼ì€ safe_numìœ¼ë¡œ float ë³€í™˜
    - ì™¸ê²½/ë‚´ê²½/ë†’ì´ê°€ ìˆëŠ”ë° ì¶”ì •ê°’ì´ ì—†ê±°ë‚˜ 0ì´ë©´ ê³µì‹ìœ¼ë¡œ ì¬ê³„ì‚°
    - ì§€ê´€ë¬´ê²Œê°€ ìˆìœ¼ë©´ ì˜¤ì°¨(ì¶”ì •ê°’-ì§€ê´€ë¬´ê²Œ) ì¬ê³„ì‚°
    """
    df = df.copy()

    # í•„ìˆ˜ ì»¬ëŸ¼ ì„¸íŠ¸
    required_cols = [
        "ìƒ˜í”Œë²ˆí˜¸",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "êµ¬ë¶„",
        "ì§€ê´€ë¬´ê²Œ",
        "ì¶”ì •ê°’",
        "ì˜¤ì°¨",
        "ì™¸ê²½",
        "ë‚´ê²½",
        "ë†’ì´",
        "1Rë¬´ê²Œ",
        "ê¸°ì¤€ìƒ˜í”Œ",
        "ìƒ˜í”Œë¬´ê²Œ",
    ]

    for c in required_cols:
        if c not in df.columns:
            df[c] = None

    # ìˆ«ì ì»¬ëŸ¼ì€ safe_numìœ¼ë¡œ í†µì¼
    num_cols = ["ì§€ê´€ë¬´ê²Œ", "ì¶”ì •ê°’", "ì˜¤ì°¨", "ì™¸ê²½", "ë‚´ê²½", "ë†’ì´", "1Rë¬´ê²Œ", "ìƒ˜í”Œë¬´ê²Œ"]
    for c in num_cols:
        df[c] = df[c].apply(safe_num)

    # êµ¬ë¶„ì´ ìˆìœ¼ë©´ LABEL_TYPES ì•ˆì— ìˆëŠ” ê°’ë§Œ ë‚¨ê¸°ê¸° (ìˆì„ ë•Œë§Œ)
    if "êµ¬ë¶„" in df.columns and "LABEL_TYPES" in globals():
        mask = df["êµ¬ë¶„"].isin(LABEL_TYPES) | df["êµ¬ë¶„"].isna()
        df = df[mask]

    # ì¶”ì •ê°’ ì¬ê³„ì‚° (ì™¸ê²½/ë‚´ê²½/ë†’ì´ê°€ ìˆì„ ë•Œ, ì¶”ì •ê°’ì´ 0 ë˜ëŠ” NaNì¸ ê²½ìš°)
    def _recalc_est(row):
        od = safe_num(row["ì™¸ê²½"])
        inner = safe_num(row["ë‚´ê²½"])
        h = safe_num(row["ë†’ì´"])
        est = safe_num(row["ì¶”ì •ê°’"])

        if od > 0 and inner > 0 and h > 0 and est <= 0:
            est = 3.14 * h * ((od ** 2 - inner ** 2) / 4.0) * 0.78
        return round(est, 2) if est != 0 else est

    df["ì¶”ì •ê°’"] = df.apply(_recalc_est, axis=1)

    # ì˜¤ì°¨ ì¬ê³„ì‚° (ì§€ê´€ë¬´ê²Œê°€ ìˆì„ ë•Œë§Œ)
    def _recalc_err(row):
        core = safe_num(row["ì§€ê´€ë¬´ê²Œ"])
        est = safe_num(row["ì¶”ì •ê°’"])
        if core > 0 and est > 0:
            return est - core
        return safe_num(row["ì˜¤ì°¨"])

    df["ì˜¤ì°¨"] = df.apply(_recalc_err, axis=1)

    df = df.reset_index(drop=True)
    return df


# í™”ë©´ì— ë³´ì´ëŠ” í™˜ì… ì˜ˆìƒì¬ê³  í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œ
VISIBLE_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì™„ì„±í’ˆë²ˆ",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# CSVì— ë“¤ì–´ê°ˆ ì „ì²´ ì»¬ëŸ¼ (ìš”ì²­í•œ ìˆœì„œ ê·¸ëŒ€ë¡œ)
CSV_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì§€ì‹œë²ˆí˜¸",
    "ìƒì‚°ê³µì •",
    "ìƒì‚°ì‹œì‘ì¼",
    "ìƒì‚°ì¢…ë£Œì¼",
    "ì¢…ë£Œì¡°ê±´",
    "í™˜ì…ì¼",
    "í™˜ì…ì£¼ì°¨",
    "ì™„ì„±í’ˆë²ˆ",
    "ì™„ì„±í’ˆëª…",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# --------
# ê¸°ê°„ ê¸°ì¤€ ì…ê³  ìˆ˜ëŸ‰ í•©ê³„
# --------

def get_real_in_by_period(part_code, start_date, end_date):
    """
    í’ˆë²ˆ(part_code)ê³¼ ì…ê³  ê¸°ê°„(start_date ~ end_date)ì„ ê¸°ì¤€ìœ¼ë¡œ
    ì…ê³  ì‹œíŠ¸(df_in_raw)ì—ì„œ 'í˜„ì¥ì‹¤ë¬¼ì…ê³ ' í•©ê³„ë¥¼ êµ¬í•œë‹¤.
    """
    df = df_in_raw.copy()

    # ë‚ ì§œ / í’ˆë²ˆ / ì‹¤ë¬¼ì…ê³  ì»¬ëŸ¼ ì°¾ê¸°
    date_col = pick_col(df, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    part_col = pick_col(df, "M", ["í’ˆë²ˆ"])
    real_col = pick_col(df, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if not all([date_col, part_col, real_col]):
        return 0.0  # í•„ìˆ˜ ì»¬ëŸ¼ ì—†ìœ¼ë©´ 0 ë¦¬í„´

    # ë‚ ì§œí˜• ë³€í™˜
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce").dt.date

    # ê¸°ê°„ + í’ˆë²ˆìœ¼ë¡œ í•„í„°
    mask = (
        (df[part_col].astype(str) == str(part_code))
        & (df[date_col] >= start_date)
        & (df[date_col] <= end_date)
    )

    sub = df.loc[mask, real_col]

    if sub.empty:
        return 0.0

    return sub.apply(safe_num).sum()

# -----
# ì¶”ê°€ìˆ˜ì£¼ë²ˆí˜¸ ì°¾ê¸°
# ------

def get_extra_orders_by_period(part_code, base_suju, start_date, end_date):
    """
    ì…ê³  ì‹œíŠ¸(df_in_raw)ì—ì„œ
    - í’ˆë²ˆ(part_code)
    - ìš”ì²­ë‚ ì§œ: start_date ~ end_date
    ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ìˆ˜ì£¼ë²ˆí˜¸ë“¤ì„ ì°¾ì•„ì„œ,
    ê¸°ë³¸ ìˆ˜ì£¼ë²ˆí˜¸(base_suju)ëŠ” ì œì™¸í•˜ê³ 
    ì¤‘ë³µ ì—†ì´ ì‰¼í‘œë¡œ ì´ì–´ë¶™ì¸ ë¬¸ìì—´ì„ ë°˜í™˜í•œë‹¤.
    """
    df = df_in_raw.copy()

    date_col = pick_col(df, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    part_col = pick_col(df, "M", ["í’ˆë²ˆ"])
    suju_col = pick_col(df, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])

    if not all([date_col, part_col, suju_col]):
        return ""

    # ë‚ ì§œí˜• ë³€í™˜
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce").dt.date

    # í•„í„°: í’ˆë²ˆ + ê¸°ê°„
    mask = (
        (df[part_col].astype(str) == str(part_code))
        & (df[date_col] >= start_date)
        & (df[date_col] <= end_date)
    )

    sub = df.loc[mask, suju_col]

    if sub.empty:
        return ""

    # ìˆ˜ì£¼ë²ˆí˜¸ë“¤ ì •ë¦¬
    suju_list = (
        sub.dropna()
        .astype(str)
        .unique()
        .tolist()
    )

    # ê¸°ë³¸ ìˆ˜ì£¼ë²ˆí˜¸ ì œì™¸
    suju_list = [s for s in suju_list if s != str(base_suju)]

    if not suju_list:
        return ""

    # ì‰¼í‘œë¡œ ì´ì–´ë¶™ì—¬ì„œ ë°˜í™˜
    return ", ".join(suju_list)


# -----------------------------
# ì§‘ê³„ í…Œì´ë¸” ë¹Œë“œ
# -----------------------------
def build_aggregates(df_in_raw, df_job_raw, df_result_raw, df_defect_raw, df_stock_raw):
    """
    í° ì›ë³¸ ì‹œíŠ¸ë“¤ì„ ë¯¸ë¦¬ groupby í•´ì„œ, ë‚˜ì¤‘ì—” mergeë§Œ í•˜ë„ë¡ ë§Œë“œëŠ” ì§‘ê³„ í…Œì´ë¸”ë“¤
    """
    aggregates = {}

    # === 1) ì…ê³  ì§‘ê³„: [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ë³„ ERPë¶ˆì¶œìˆ˜ëŸ‰/í˜„ì¥ì‹¤ë¬¼ì…ê³  í•©ê³„ ===
    # ìˆ˜ì£¼ë²ˆí˜¸: Bì—´, ì§€ì‹œë²ˆí˜¸: Cì—´, í’ˆë²ˆ: Mì—´, ERPë¶ˆì¶œìˆ˜ëŸ‰: Qì—´, í˜„ì¥ì‹¤ë¬¼ì…ê³ : Rì—´
    in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
    in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
    in_erp_col = pick_col(df_in_raw, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰"])
    in_real_col = pick_col(df_in_raw, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if all([in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]):
        df_in = df_in_raw[
            [in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]
        ].copy()
        df_in.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        agg_in = (
            df_in.groupby(["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)
            .agg({"ERPë¶ˆì¶œìˆ˜ëŸ‰": "sum", "í˜„ì¥ì‹¤ë¬¼ì…ê³ ": "sum"})
        )
        aggregates["in"] = agg_in
    else:
        aggregates["in"] = pd.DataFrame(
            columns=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        )

    # === 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„: ì§€ì‹œë²ˆí˜¸ë³„ ì§€ì‹œìˆ˜ëŸ‰ ===
    job_jisi_col = (
        "ì§€ì‹œë²ˆí˜¸"
        if "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
        else pick_col(df_job_raw, "F", ["ì§€ì‹œë²ˆí˜¸"])
    )
    job_qty_col = (
        "ìˆ˜ëŸ‰"
        if "ìˆ˜ëŸ‰" in df_job_raw.columns
        else pick_col(df_job_raw, "R", ["ìˆ˜ëŸ‰", "ì§€ì‹œìˆ˜ëŸ‰"])
    )

    if job_jisi_col and job_qty_col:
        df_job = df_job_raw[[job_jisi_col, job_qty_col]].copy()
        df_job.columns = ["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"]
        agg_job = df_job.groupby("ì§€ì‹œë²ˆí˜¸", as_index=False).agg({"ì§€ì‹œìˆ˜ëŸ‰": "sum"})
        aggregates["job"] = agg_job
    else:
        aggregates["job"] = pd.DataFrame(columns=["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"])

    # === 3) ìƒì‚°ì‹¤ì  ì§‘ê³„: ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸)ë³„ ì–‘í’ˆ / QCìƒ˜í”Œ / ê¸°íƒ€ìƒ˜í”Œ í•©ê³„ ===
    # ì‘ì§€ë²ˆí˜¸: ë³´í†µ "ì‘ì§€ë²ˆí˜¸" ì»¬ëŸ¼ ì‚¬ìš© (Aì—´)
    res_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "A", ["ì‘ì§€ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"])
    )

    # ìˆ˜ì£¼ë²ˆí˜¸: ìˆìœ¼ë©´ ê°™ì´ ë“¤ê³ ë§Œ ë‹¤ë‹ˆë‹¤ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©
    res_suju_col = (
        "ìˆ˜ì£¼ë²ˆí˜¸"
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "E", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    )

    # ì–‘í’ˆ(ì‹¤ì œ ìƒì‚°ìˆ˜ëŸ‰) ì»¬ëŸ¼ ì°¾ê¸°
    res_good_col = None
    for cand in ["ì–‘í’ˆ", "ì–‘í’ˆìˆ˜ëŸ‰", "ì–‘í’ˆìˆ˜", "í•©ê²©", "ìƒì‚°ìˆ˜ëŸ‰"]:
        if cand in df_result_raw.columns:
            res_good_col = cand
            break

    # QCìƒ˜í”Œ: AGì—´, ê¸°íƒ€ìƒ˜í”Œ: AHì—´ ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì°¾ê¸°
    res_qc_col = pick_col(df_result_raw, "AG", ["QCìƒ˜í”Œ"])
    res_etc_col = pick_col(df_result_raw, "AH", ["ê¸°íƒ€ìƒ˜í”Œ"])

    # ìµœì†Œí•œ ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸)ë‚˜ ìˆ˜ì£¼ë²ˆí˜¸ ë‘˜ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ ì§‘ê³„ ê°€ëŠ¥
    if res_jisi_col or res_suju_col:
        use_cols = []
        if res_jisi_col:
            use_cols.append(res_jisi_col)
        if res_suju_col:
            use_cols.append(res_suju_col)
        if res_good_col:
            use_cols.append(res_good_col)
        if res_qc_col:
            use_cols.append(res_qc_col)
        if res_etc_col:
            use_cols.append(res_etc_col)

        df_res = df_result_raw[use_cols].copy()

        # ì»¬ëŸ¼ëª… í†µì¼
        rename_map = {}
        if res_jisi_col:
            rename_map[res_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
        if res_suju_col:
            rename_map[res_suju_col] = "ìˆ˜ì£¼ë²ˆí˜¸"
        if res_good_col:
            rename_map[res_good_col] = "ìƒì‚°ìˆ˜ëŸ‰"
        if res_qc_col:
            rename_map[res_qc_col] = "QCìƒ˜í”Œ"
        if res_etc_col:
            rename_map[res_etc_col] = "ê¸°íƒ€ìƒ˜í”Œ"

        df_res = df_res.rename(columns=rename_map)

        # NaN â†’ 0 ì²˜ë¦¬
        for col in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
            if col in df_res.columns:
                df_res[col] = df_res[col].apply(safe_num)

        # âœ… ê¸°ì¤€ í‚¤: ì§€ì‹œë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì§€ì‹œë²ˆí˜¸ë¡œ, ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ìˆ˜ì£¼ë²ˆí˜¸ë¡œ
        group_keys = []
        if "ì§€ì‹œë²ˆí˜¸" in df_res.columns:
            group_keys.append("ì§€ì‹œë²ˆí˜¸")
        elif "ìˆ˜ì£¼ë²ˆí˜¸" in df_res.columns:
            group_keys.append("ìˆ˜ì£¼ë²ˆí˜¸")

        # ì§‘ê³„ ë°©ì‹ ì •ì˜
        agg_dict = {}
        for col in df_res.columns:
            if col in group_keys:
                continue
            if col in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
                agg_dict[col] = "sum"
            elif col == "ìˆ˜ì£¼ë²ˆí˜¸" and "ì§€ì‹œë²ˆí˜¸" in group_keys:
                # ì§€ì‹œë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì„ ë•Œ ìˆ˜ì£¼ë²ˆí˜¸ëŠ” ëŒ€í‘œê°’ í•˜ë‚˜ë§Œ
                agg_dict[col] = "first"
            else:
                agg_dict[col] = "first"

        agg_res = df_res.groupby(group_keys, as_index=False).agg(agg_dict)
        aggregates["result"] = agg_res
    else:
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ DF
        aggregates["result"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "ìˆ˜ì£¼ë²ˆí˜¸", "ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]
        )


    # === 4) ë¶ˆëŸ‰ ì§‘ê³„: [ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ]ë³„ ì›ë¶ˆ/ì‘ë¶ˆ ìˆ˜ëŸ‰ ===
    def_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_defect_raw.columns
        else pick_col(df_defect_raw, "C", ["ì‘ì§€ë²ˆí˜¸"])
    )
    def_part_col = (
        "íˆ¬ì…í’ˆë²ˆ"
        if "íˆ¬ì…í’ˆë²ˆ" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Q", ["íˆ¬ì…í’ˆë²ˆ"])
    )
    def_qty_col = (
        "ë¶ˆëŸ‰ìˆ˜ëŸ‰"
        if "ë¶ˆëŸ‰ìˆ˜ëŸ‰" in df_defect_raw.columns
        else pick_col(df_defect_raw, "W", ["ë¶ˆëŸ‰ìˆ˜ëŸ‰"])
    )
    def_type_col = (
        "ë¶ˆëŸ‰ìœ í˜•.1"
        if "ë¶ˆëŸ‰ìœ í˜•.1" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Z", ["ë¶ˆëŸ‰ìœ í˜•.1", "ë¶ˆëŸ‰ìœ í˜•"])
    )

    if def_jisi_col and def_part_col and def_qty_col and def_type_col:
        df_def = df_defect_raw[
            [def_jisi_col, def_part_col, def_qty_col, def_type_col]
        ].copy()
        df_def.columns = ["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¶ˆëŸ‰ìˆ˜ëŸ‰", "ë¶ˆëŸ‰ìœ í˜•"]
        df_def["ë¶ˆëŸ‰ìœ í˜•"] = df_def["ë¶ˆëŸ‰ìœ í˜•"].astype(str)

        # ì›ë¶ˆ
        df_orig = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì›)")].copy()
        agg_orig = (
            df_orig.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì›ë¶ˆ"})
        )

        # ì‘ë¶ˆ
        df_proc = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì‘)")].copy()
        agg_proc = (
            df_proc.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì‘ë¶ˆ"})
        )

        # ë‘˜ í•©ì¹˜ê¸°
        agg_def = pd.merge(agg_orig, agg_proc, on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], how="outer")
        aggregates["defect"] = agg_def
    else:
        aggregates["defect"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ì›ë¶ˆ", "ì‘ë¶ˆ"]
        )

    # === 5) ì¬ê³  ì§‘ê³„: í’ˆë²ˆë³„ ERPì¬ê³  (ì‘ì—…ì¥ WC501~WC504) ===
    stock_wc_col = pick_col(df_stock_raw, "A", ["ì‘ì—…ì¥"])
    stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])

    # ERPì¬ê³ ëŠ” ë°˜ë“œì‹œ "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" ì»¬ëŸ¼ì„ ì‚¬ìš© (ì—†ìœ¼ë©´ Nì—´ fallback)
    if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in df_stock_raw.columns:
        stock_qty_col = "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"
    else:
        stock_qty_col = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

    if stock_wc_col and stock_part_col and stock_qty_col:
        df_stock = df_stock_raw[
            [stock_wc_col, stock_part_col, stock_qty_col]
        ].copy()
        df_stock.columns = ["ì‘ì—…ì¥", "í’ˆë²ˆ", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
        df_stock = df_stock[df_stock["ì‘ì—…ì¥"].isin(["WC501", "WC502", "WC503", "WC504"])]
        if not df_stock.empty:
            agg_stock = (
                df_stock.groupby("í’ˆë²ˆ", as_index=False)["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
                .sum()
                .rename(columns={"ì‹¤ì¬ê³ ìˆ˜ëŸ‰": "ERPì¬ê³ "})
            )
            aggregates["stock"] = agg_stock
        else:
            aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])
    else:
        aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])

    return aggregates


# -----------------------------
# í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚° (merge ê¸°ë°˜)
# -----------------------------
def recalc_return_expectation(df_return, aggs):
    """
    df_return(í™˜ì…ê´€ë¦¬ í…Œì´ë¸”)ì— ì§‘ê³„ ë°ì´í„°(aggs)ë¥¼ mergeë¡œ ë¶™ì—¬ì„œ
    ERPë¶ˆì¶œìˆ˜ëŸ‰, í˜„ì¥ì‹¤ë¬¼ì…ê³ , ì§€ì‹œìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰, QCìƒ˜í”Œ, ê¸°íƒ€ìƒ˜í”Œ, ì›ë¶ˆ, ì‘ë¶ˆ, ERPì¬ê³ , ì˜ˆìƒì¬ê³ ë¥¼ ê³„ì‚°

    ì˜ˆìƒì¬ê³  = í˜„ì¥ì‹¤ë¬¼ì…ê³  - (ìƒì‚°ìˆ˜ëŸ‰ + QCìƒ˜í”Œ + ê¸°íƒ€ìƒ˜í”Œ) * ë‹¨ìœ„ìˆ˜ëŸ‰ - ì‘ë¶ˆ
    """
    if df_return.empty:
        return pd.DataFrame(columns=CSV_COLS)

    # [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    df = df_return.drop_duplicates(
        subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
    ).copy()

    # 1) ì…ê³  ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["in"],
        how="left",
        on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
        suffixes=("", "_in"),
    )

    # 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["job"],
        how="left",
        on="ì§€ì‹œë²ˆí˜¸",
    )

    # 3) ìƒì‚°ì‹¤ì  ì§‘ê³„ ë¶™ì´ê¸°
    res_tbl = aggs["result"]

    # ìƒˆ ë°©ì‹: ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸) ê¸°ì¤€ ì§‘ê³„ê°€ ë˜ì–´ ìˆëŠ” ê²½ìš°
    if isinstance(res_tbl, pd.DataFrame) and not res_tbl.empty and "ì§€ì‹œë²ˆí˜¸" in res_tbl.columns:
        merge_cols = ["ì§€ì‹œë²ˆí˜¸"]
        for c in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
            if c in res_tbl.columns:
                merge_cols.append(c)

        df = df.merge(
            res_tbl[merge_cols],
            how="left",
            on="ì§€ì‹œë²ˆí˜¸",
        )
    else:
        # í˜¹ì‹œë¼ë„ ì§€ì‹œë²ˆí˜¸ ì§‘ê³„ê°€ ì•ˆ ë˜ì–´ ìˆëŠ” êµ¬ë²„ì „ êµ¬ì¡°ì¼ ë•ŒëŠ”
        # ê¸°ì¡´ëŒ€ë¡œ ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¶™ì´ë„ë¡ fallback
        df = df.merge(
            res_tbl,
            how="left",
            on="ìˆ˜ì£¼ë²ˆí˜¸",
        )

    # 4) ë¶ˆëŸ‰ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["defect"],
        how="left",
        on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
    )

    # 5) ì¬ê³  ì§‘ê³„ ë¶™ì´ê¸°
    if "ERPì¬ê³ " in df.columns:
        df = df.drop(columns=["ERPì¬ê³ "])
    df = df.merge(
        aggs["stock"],
        how="left",
        on="í’ˆë²ˆ",
    )

    # ìˆ«ì ì»¬ëŸ¼ë“¤ NaN -> 0
    num_cols = [
        "ERPë¶ˆì¶œìˆ˜ëŸ‰",
        "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
        "ì§€ì‹œìˆ˜ëŸ‰",
        "ìƒì‚°ìˆ˜ëŸ‰",
        "QCìƒ˜í”Œ",
        "ê¸°íƒ€ìƒ˜í”Œ",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ì›ë¶ˆ",
        "ì‘ë¶ˆ",
        "ERPì¬ê³ ",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = df[col].apply(safe_num)
        else:
            df[col] = 0.0

    # âœ… ë„¤ê°€ ë§í•œ ê³µì‹ ê·¸ëŒ€ë¡œ
    df["ì˜ˆìƒì¬ê³ "] = (
        df["í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        - (df["ìƒì‚°ìˆ˜ëŸ‰"] + df["QCìƒ˜í”Œ"] + df["ê¸°íƒ€ìƒ˜í”Œ"]) * df["ë‹¨ìœ„ìˆ˜ëŸ‰"]
        - df["ì›ë¶ˆ"]
        - df["ì‘ë¶ˆ"]
    )

    # ì™„ì„±í’ˆëª…ì€ ì œí’ˆëª… ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    df["ì™„ì„±í’ˆëª…"] = df.get("ì œí’ˆëª…", None)

    # CSVìš© ì „ì²´ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    for col in CSV_COLS:
        if col not in df.columns:
            df[col] = None

    out = df[CSV_COLS].copy()
    return out

# -----------------------------
# PDF ìƒì„± í•¨ìˆ˜
# -----------------------------
if REPORTLAB_AVAILABLE:
    from xml.sax.saxutils import escape
    from reportlab.graphics.barcode import code128
    from reportlab.graphics.shapes import Drawing
    from reportlab.lib.units import mm
    from reportlab.platypus import PageBreak

    def generate_pdf(
        df_export: pd.DataFrame,
        uploaded_image=None,
        pasted_text: str | None = None,
    ) -> bytes:
        """
        - ì œëª© / í‘œ ëª¨ë‘ ì™¼ìª½ ì •ë ¬
        - pasted_textê°€ ìˆìœ¼ë©´ ì œëª© ì•„ë˜ì— ê·¸ëŒ€ë¡œ ì¶œë ¥
        - uploaded_imageëŠ” ì§€ê¸ˆì€ ì•ˆ ì¨ë„ ë¨(ì°¨í›„ í™•ì¥ìš©)
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Table,
            TableStyle,
            Paragraph,
            Spacer,
            Image,
        )
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors

        buffer = io.BytesIO()

        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=20,
            rightMargin=20,
            topMargin=20,
            bottomMargin=20,
        )

        styles = getSampleStyleSheet()

        title_style = ParagraphStyle(
            "TitleStyle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=15,
            alignment=0,   # LEFT
        )

        text_style = ParagraphStyle(
            "TextStyle",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=10,
            leading=14,
            alignment=0,   # LEFT
        )

        table_style = TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                ("ALIGN", (0, 0), (-1, -1), "LEFT"),  # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
                ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                ("FONTSIZE", (0, 0), (-1, -1), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                ("BOTTOMPADDING", (0, 0), (-1, -1), 20),
                ("TOPPADDING",    (0, 0), (-1, -1), 20),
                ("MINROWHEIGHT",  (0, 0), (-1, -1), 35),
            ]
        )

        story = []

        # 1) ì œëª©
        suju_list = df_export["ìˆ˜ì£¼ë²ˆí˜¸"].dropna().astype(str).unique()
        name_list = df_export["ì™„ì„±í’ˆëª…"].dropna().astype(str).unique()
        title_text = f"{suju_list[0] if len(suju_list) else ''} {name_list[0] if len(name_list) else ''}".strip()

        story.append(Paragraph(title_text, title_style))
        story.append(Spacer(1, 12))

        # 2) ìƒë‹¨ ë©”ëª¨ (í…ìŠ¤íŠ¸)
        if pasted_text is not None and pasted_text.strip() != "":
            # <, >, & ë“± ì´ìŠ¤ì¼€ì´í”„ + ì¤„ë°”ê¿ˆì„ <br/>ë¡œ ë³€í™˜
            safe_text = escape(pasted_text).replace("\n", "<br/>")
            story.append(Paragraph(safe_text, text_style))
            story.append(Spacer(1, 12))

        # 3) (ì›í•˜ë©´ ì´ë¯¸ì§€ë„ ì—¬ê¸°ì—)
        if uploaded_image:
            try:
                img = Image(uploaded_image, width=400, height=300)
                story.append(img)
                story.append(Spacer(1, 12))
            except Exception:
                pass

        # í‘œ êµ¬ì„±: ê¸°ì¡´ + 1P, 2P, 3P, 4P 4ì¹¸ ì¶”ê°€
        base_cols = ["í’ˆë²ˆ", "í’ˆëª…", "ì‘ë¶ˆ", "ì˜ˆìƒì¬ê³ ", "ERPì¬ê³ "]
        table_cols = base_cols + ["1P", "2P", "3P", "4P"]
        table_data = [table_cols]

        for _, row in df_export.iterrows():
            # df_export ì—ëŠ” 1P~4P ì»¬ëŸ¼ì´ ì—†ìœ¼ë‹ˆê¹Œ, ê¸°ì¡´ ë°ì´í„°ë§Œ ë„£ê³  4ì¹¸ì€ ê³µë°±ìœ¼ë¡œ ì±„ì›€
            base_values = [str(row.get(c, "")) for c in base_cols]
            extra_values = ["", "", "", ""]  # 1P, 2P, 3P, 4P
            table_data.append(base_values + extra_values)

        # í–‰ ë†’ì´ (í—¤ë”ëŠ” ê¸°ë³¸, ë°ì´í„° í–‰ë§Œ ë†’ê²Œ)
        default_height = None        # í—¤ë”
        data_height = 40             # ë°ì´í„° í–‰
        row_heights = [default_height] + [data_height] * (len(table_data) - 1)

        # ì»¬ëŸ¼ í­ ì„¤ì •
        #  - ì•ì˜ 5ê°œ ì»¬ëŸ¼ì€ None(ìë™)
        #  - 1P~4P 4ì¹¸ë§Œ ë„“ê²Œ
        col_widths = [None, None, None, None, None, 130, 130, 80, 80]

        table = Table(
            table_data,
            repeatRows=1,
            rowHeights=row_heights,
            colWidths=col_widths,
            hAlign="LEFT",   # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
        )

        table.setStyle(
            TableStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                    ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                    ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                    ("FONTSIZE", (0, 0), (-1, -1), 8),
                    ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                    ("LEFTPADDING", (0, 0), (-1, -1), 0),
                    ("RIGHTPADDING", (0, 0), (-1, -1), 4),

                    # ë°ì´í„° í–‰ë§Œ ìœ„/ì•„ë˜ ì—¬ë°± í¬ê²Œ
                    ("TOPPADDING",    (0, 1), (-1, -1), 12),
                    ("BOTTOMPADDING", (0, 1), (-1, -1), 12),
                ]
            )
        )

        story.append(table)

        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

    # ğŸ”¹ ì†Œí˜• ë¼ë²¨í”„ë¦°í„°(100Ã—120mm)ìš© ë¶€ìì¬ë°˜ì… ë¼ë²¨ PDF
    def generate_label_pdf(df_labels: pd.DataFrame, barcode_value: str, unit_value: str) -> bytes:
        """
        df_labels: 'í’ˆëª…', 'í’ˆë²ˆ', 'í™˜ì…ì¼' ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame
        barcode_value: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë°”ì½”ë“œ ê°’ (ì˜ˆ: B202511-00120001)
        unit_value: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‹¨ìœ„ìˆ˜ëŸ‰
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Paragraph,
            Spacer,
            PageBreak,
            Flowable,
            Table,
            TableStyle,
        )
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_CENTER, TA_LEFT
        from reportlab.lib.units import mm
        from reportlab.lib import colors
        from reportlab.graphics.barcode import code128
        from xml.sax.saxutils import escape

        buffer = io.BytesIO()

        # ë¼ë²¨ í¬ê¸°: 100mm * 120mm
        LABEL_WIDTH = 100 * mm
        LABEL_HEIGHT = 120 * mm

        doc = SimpleDocTemplate(
            buffer,
            pagesize=(LABEL_WIDTH, LABEL_HEIGHT),
            leftMargin=5 * mm,
            rightMargin=5 * mm,
            topMargin=5 * mm,
            bottomMargin=5 * mm,
        )

        styles = getSampleStyleSheet()

        # ì œëª© ìŠ¤íƒ€ì¼ (25pt, ì¤‘ì•™ì •ë ¬)
        title_style = ParagraphStyle(
            "LabelTitle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=25,
            alignment=TA_CENTER,
        )

        # ì™¼ìª½ í•„ë“œëª… ìŠ¤íƒ€ì¼ (êµµê²Œ)
        field_label_style = ParagraphStyle(
            "FieldLabel",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=13,
            leading=16,
            alignment=TA_LEFT,
        )

        # ì˜¤ë¥¸ìª½ ê°’ ìŠ¤íƒ€ì¼ (êµµê²Œ â€” ì›í•˜ë©´ ì–‡ê²Œë„ ë°”ê¿€ ìˆ˜ ìˆìŒ)
        field_value_style = ParagraphStyle(
            "FieldValue",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=13,
            leading=16,
            alignment=TA_LEFT,
        )

        # ë°”ì½”ë“œ í•˜ë‹¨ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ (ì¤‘ì•™ì •ë ¬)
        barcode_text_style = ParagraphStyle(
            "BarcodeText",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=12,
            alignment=TA_CENTER,
        )

        # âœ… ë°”ì½”ë“œë¥¼ ê°€ë¡œ ì¤‘ì•™ ì •ë ¬í•˜ê¸° ìœ„í•œ Flowable
        class CenteredBarcode(Flowable):
            def __init__(self, barcode):
                super().__init__()
                self.barcode = barcode
                self._avail_width = None
                self.width = barcode.width
                self.height = barcode.height

            def wrap(self, availWidth, availHeight):
                self._avail_width = availWidth
                return availWidth, self.height

            def draw(self):
                if self._avail_width is None:
                    x = 0
                else:
                    x = (self._avail_width - self.barcode.width) / 2.0
                self.barcode.drawOn(self.canv, x, 0)

        story = []

        # ğŸ”² í˜ì´ì§€ë§ˆë‹¤ ë³´ë”ë¼ì¸ ê·¸ë¦¬ê¸°ìš© ì½œë°±
        def draw_border(canvas, doc_obj):
            canvas.saveState()
            # 3px â‰ˆ 0.8mm ì •ë„ ì•ˆìª½ìœ¼ë¡œ
            inset = 0.8 * mm
            x = inset
            y = inset
            w = LABEL_WIDTH - 2 * inset
            h = LABEL_HEIGHT - 2 * inset
            canvas.setLineWidth(0.75)  # â‰ˆ 1px
            canvas.rect(x, y, w, h)
            canvas.restoreState()

        for idx, row in df_labels.iterrows():
            í’ˆëª… = str(row.get("í’ˆëª…", ""))
            í’ˆë²ˆ = str(row.get("í’ˆë²ˆ", ""))
            í™˜ì…ì¼ = row.get("í™˜ì…ì¼", "")

            # í™˜ì…ì¼ ì •ë¦¬
            try:
                if pd.notna(í™˜ì…ì¼):
                    í™˜ì…ì¼_str = pd.to_datetime(í™˜ì…ì¼).strftime("%Y-%m-%d")
                else:
                    í™˜ì…ì¼_str = ""
            except Exception:
                í™˜ì…ì¼_str = str(í™˜ì…ì¼)

            # ----- ì œëª© -----
            story.append(Paragraph("ë¶€ìì¬ë°˜ì…", title_style))
            # ê³µë°± 3ì¤„ ì •ë„
            story.append(Spacer(1, field_label_style.leading * 3))

            # ----- í•„ë“œ 4ì¤„ì„ 2ì—´ í…Œì´ë¸”ë¡œ êµ¬ì„± (ì™¼ìª½ ì—´ ë„ˆë¹„ ê³ ì •) -----
            # ì™¼ìª½ ì—´ ë„ˆë¹„ë¥¼ ê³ ì •í•˜ë©´ ì˜¤ë¥¸ìª½ ê°’ ì‹œì‘ ìœ„ì¹˜ê°€ ëª¨ë‘ ë™ì¼í•´ì§
            first_col_width = 28 * mm  # í•„ìš”í•˜ë©´ mm ê°’ ì¡°ì ˆí•´ì„œ ë§ì¶”ë©´ ë¨
            second_col_width = doc.width - first_col_width

            data = [
                [
                    Paragraph("<b>í’ˆëª…</b>", field_label_style),
                    Paragraph(f"<b>{escape(í’ˆëª…)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>í’ˆëª©ì½”ë“œ</b>", field_label_style),
                    Paragraph(f"<b>{escape(í’ˆë²ˆ)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>ë‹¨ìœ„ìˆ˜ëŸ‰</b>", field_label_style),
                    Paragraph(f"<b>{escape(unit_value)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>ë°˜ì…ì¼ì</b>", field_label_style),
                    Paragraph(f"<b>{escape(í™˜ì…ì¼_str)}</b>", field_value_style),
                ],
            ]

            row_height = field_label_style.leading * 2  # í•œ ì¤„ + ê³µë°± 1ì¤„ ëŠë‚Œ
            row_heights = [row_height] * len(data)

            tbl = Table(
                data,
                colWidths=[first_col_width, second_col_width],
                rowHeights=row_heights,
            )
            tbl.setStyle(
                TableStyle(
                    [
                        ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                        ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                        ("LEFTPADDING", (0, 0), (-1, -1), 0),
                        ("RIGHTPADDING", (0, 0), (-1, -1), 0),
                        ("TOPPADDING", (0, 0), (-1, -1), 0),
                        ("BOTTOMPADDING", (0, 0), (-1, -1), 0),
                    ]
                )
            )

            story.append(tbl)
            story.append(Spacer(1, 8))

            # ğŸ”¥ ë°”ì½”ë“œ ìƒì„± (ì „ì²´ ë„ˆë¹„ ì•½ 90px ê¸°ì¤€)
            bar_width_px = 30
            bar_width_pt = bar_width_px * 0.75  # px â†’ pt
            char_count = max(len(barcode_value), 1)
            bar_width = bar_width_pt / char_count

            bc = code128.Code128(
                barcode_value,
                barHeight=15 * mm,
                barWidth=bar_width,
            )

            # ì¤‘ì•™ì •ë ¬ Flowableë¡œ ê°ì‹¸ê¸°
            center_bc = CenteredBarcode(bc)

            story.append(Spacer(1, 5))
            story.append(center_bc)
            story.append(Spacer(1, 5))

            # ë°”ì½”ë“œ ê°’ í…ìŠ¤íŠ¸ (ì¤‘ì•™ì •ë ¬)
            story.append(Paragraph(barcode_value, barcode_text_style))

            # ì—¬ëŸ¬ ì¥ì¼ ê²½ìš° ë‹¤ìŒ í˜ì´ì§€
            if idx != len(df_labels) - 1:
                story.append(PageBreak())

        # ë³´ë”ë¼ì¸ ì½œë°± ì ìš©
        doc.build(story, onFirstPage=draw_border, onLaterPages=draw_border)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes


# -----------------------------
# ë©”ì¸ í™”ë©´
# -----------------------------
st.title("ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

menu = st.radio(
    "ë©”ë‰´ ì„ íƒ",
    [
        "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ",
        "ğŸ“¦ ì…ê³  ì¡°íšŒ",
        "â†©ï¸ í™˜ì… ê´€ë¦¬",
        "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°",
        "ğŸ§© ê³µí†µìì¬",
        "ğŸ· ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚°",  
    ],
    horizontal=True,
)

# ==========================================
# ğŸ“¤ 1. íŒŒì¼ ì—…ë¡œë“œ íƒ­ (S3ì— ì—‘ì…€ë§Œ ì €ì¥)
# ==========================================
if menu == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    st.subheader("ğŸ“¤ 2025ë…„ ë¶€ìì¬ ê´€ë¦¬ëŒ€ì¥ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xlsm", "xlsx"])

    if uploaded_file and s3_client is not None:
        try:
            file_bytes = uploaded_file.read()

            # 1) ì—‘ì…€ ì›ë³¸ì„ S3ì— ì €ì¥ (ì´ì œ ì´ê±¸ë§Œ ì“´ë‹¤)
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=S3_KEY_EXCEL,
                Body=file_bytes,
            )

            # 2) ìºì‹œ ì´ˆê¸°í™”
            load_file_from_s3.clear()
            load_excel.clear()

            st.success("ì—‘ì…€ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íƒ­ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”.")
        except Exception as e:
            st.error(f"S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    elif uploaded_file and s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.stop()  # ì—…ë¡œë“œ íƒ­ì—ì„œëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ

# ==========================================
# ë‚˜ë¨¸ì§€ íƒ­: S3ì—ì„œ ì—‘ì…€ ë¡œë”©
# ==========================================
excel_bytes = load_file_from_s3()
if excel_bytes is None:
    st.warning("S3ì— ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ] íƒ­ì—ì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    st.stop()

# ìºì‹œëœ ì—‘ì…€ íŒŒì‹± í•¨ìˆ˜ë¡œ ì „ì²´ ì‹œíŠ¸ ë¡œë”©
sheets = load_excel(excel_bytes)

required_sheets = ["ì…ê³ ", "ì‘ì—…ì§€ì‹œ", "ìˆ˜ì£¼", "BOM", "ì¬ê³ ", "ìƒì‚°ì‹¤ì ", "ë¶ˆëŸ‰"]
missing_sheets = [s for s in required_sheets if s not in sheets]
if missing_sheets:
    st.error(f"ì—‘ì…€ íŒŒì¼ì— ë‹¤ìŒ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_sheets)}")
    st.stop()

# ê° ì‹œíŠ¸ DataFrame í• ë‹¹ (ì´ë¦„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
df_in_raw     = sheets["ì…ê³ "]
df_job_raw    = sheets["ì‘ì—…ì§€ì‹œ"]
df_suju_raw   = sheets["ìˆ˜ì£¼"]
df_bom_raw    = sheets["BOM"]
df_stock_raw  = sheets["ì¬ê³ "]
df_result_raw = sheets["ìƒì‚°ì‹¤ì "]
df_defect_raw = sheets["ë¶ˆëŸ‰"]

# ì§‘ê³„ëŠ” í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹œ ìµœì´ˆ 1íšŒ
if "aggregates" not in st.session_state:
    st.session_state["aggregates"] = None

# ============================
# 2. ì…ê³  ì¡°íšŒ íƒ­
# ============================
if menu == "ğŸ“¦ ì…ê³  ì¡°íšŒ":
    st.header("ğŸ“¦ ì…ê³  ì¡°íšŒ")
    st.caption("ìš”ì²­ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì…ê³  ë‚´ì—­ì„ ì¡°íšŒí•©ë‹ˆë‹¤.")

    # ì…ê³  ì‹œíŠ¸ ì›ë³¸
    df_in = df_in_raw.copy()

    # ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ ì°¾ê¸°
    req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    if req_date_col is None:
        st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜
        df_in[req_date_col] = pd.to_datetime(df_in[req_date_col], errors="coerce").dt.date

        # ğŸ”¹ ê¸°ë³¸ ë²”ìœ„: ì–´ì œ ~ ì˜¤ëŠ˜
        today = date.today()
        default_start = today - timedelta(days=1)

        # ë‚ ì§œ ì„ íƒ + í’ˆëª… ê²€ìƒ‰ì„ ê°™ì€ ì¤„(col) ì— ë°°ì¹˜
        col_date, col_name = st.columns([1, 2])

        with col_date:
            date_range = st.date_input(
                "ìš”ì²­ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
                (default_start, today),
                key="in_date_range",
            )

        with col_name:
            name_filter = st.text_input(
                "í’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰",
                key="in_name_filter",
                placeholder="ë¶€ë¶„ ê²€ìƒ‰ (ì˜ˆ: í¬ë¦¼, ì•°í”Œ ë“±)",
            )

        # Streamlit ë²„ì „ì— ë”°ë¼ tuple ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ì„œ ë°©ì–´ ì½”ë“œ
        if isinstance(date_range, (tuple, list)):
            start_date, end_date = date_range
        else:
            start_date = date_range
            end_date = date_range

        # ë‚ ì§œ í•„í„° ë§ˆìŠ¤í¬
        mask = (df_in[req_date_col] >= start_date) & (df_in[req_date_col] <= end_date)

        # ê° ì—´ ì»¬ëŸ¼ ì°¾ê¸°
        col_process  = pick_col(df_in, "J", ["ìƒì‚°ê³µì •"])
        col_req_no   = pick_col(df_in, "L", ["ìš”ì²­ë²ˆí˜¸"])
        col_part     = pick_col(df_in, "M", ["í’ˆë²ˆ"])
        col_name     = pick_col(df_in, "O", ["í’ˆëª…"])
        col_req_qty  = pick_col(df_in, "P", ["ìš”ì²­ìˆ˜ëŸ‰"])
        col_erp_out  = pick_col(df_in, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "ë¶ˆì¶œìˆ˜ëŸ‰"])
        col_real_in  = pick_col(df_in, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

        # ğŸ‘‰ í™”ë©´ì— ë³´ì—¬ì¤„ ì»¬ëŸ¼ ìˆœì„œ: ìƒì‚°ê³µì • â†’ ìš”ì²­ë‚ ì§œ â†’ ë‚˜ë¨¸ì§€
        raw_cols = [c for c in [
            col_process,
            req_date_col,
            col_req_no,
            col_part,
            col_name,
            col_req_qty,
            col_erp_out,
            col_real_in,
        ] if c is not None]

        if not raw_cols:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_filtered = df_in.loc[mask, raw_cols].copy()

            # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë§ì¶”ê¸°
            rename_map = {}
            rename_map[req_date_col] = "ìš”ì²­ë‚ ì§œ"
            if col_process: rename_map[col_process] = "ìƒì‚°ê³µì •"
            if col_req_no:  rename_map[col_req_no]  = "ìš”ì²­ë²ˆí˜¸"
            if col_part:    rename_map[col_part]    = "í’ˆë²ˆ"
            if col_name:    rename_map[col_name]    = "í’ˆëª…"
            if col_req_qty: rename_map[col_req_qty] = "ìš”ì²­ìˆ˜ëŸ‰"
            if col_erp_out: rename_map[col_erp_out] = "ERPë¶ˆì¶œìˆ˜ëŸ‰"
            if col_real_in: rename_map[col_real_in] = "í˜„ì¥ì‹¤ë¬¼ì…ê³ "

            df_filtered.rename(columns=rename_map, inplace=True)

            # ğŸ” í’ˆëª… í•„í„° ì¶”ê°€ (ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²½ìš°ë§Œ)
            if name_filter:
                if "í’ˆëª…" in df_filtered.columns:
                    df_filtered = df_filtered[
                        df_filtered["í’ˆëª…"].astype(str).str.contains(
                            name_filter, case=False, na=False
                        )
                    ]

            # ğŸ”¥ ì—‘ì…€ì—ì„œ "ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰"ì´ ìœ„ë¡œ ì˜¤ë„ë¡: ì¸ë±ìŠ¤ ì—­ìˆœ ì •ë ¬
            df_filtered = df_filtered.iloc[::-1].reset_index(drop=True)

            if df_filtered.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(df_filtered, use_container_width=True)

# ============================================================
# ğŸ” 3. ìˆ˜ì£¼ ì°¾ê¸° í™”ë©´
# ============================================================
if menu == "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°":
    st.subheader("ğŸ” ìˆ˜ì£¼ ì°¾ê¸°")

    st.markdown(
        """
        **ë™ì‘ ë°©ì‹**

        1. ê¸°ì¤€ í’ˆë²ˆì„ ì…ë ¥í•œë‹¤.  
        2. BOM ì‹œíŠ¸ì˜ **Cì—´ í’ˆë²ˆ**ì—ì„œ ê¸°ì¤€ í’ˆë²ˆê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ê³ , ê·¸ í–‰ì˜ **í’ˆëª©ì½”ë“œ(Aì—´)** ê°’ì„ êµ¬í•œë‹¤.  
        3. ì´ í’ˆëª©ì½”ë“œë¥¼ **ìˆ˜ì£¼ ì‹œíŠ¸ì˜ í’ˆë²ˆ(Jì—´)**ì—ì„œ ê²€ìƒ‰í•œë‹¤.  
        4. ì—†ìœ¼ë©´ 2ë‹¨ê³„ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•œë‹¤.  
        5. ì˜¤ëŠ˜(today) ê¸°ì¤€ìœ¼ë¡œ **1ê°œì›” ì´ë‚´ â†’ 1ë…„ ì´ë‚´ â†’ ê³¼ê±° 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”** ìˆœìœ¼ë¡œ ìœ íš¨í•œ ìˆ˜ì£¼ë¥¼ ì°¾ëŠ”ë‹¤.  
        """
    )

    base_part = st.text_input("ê¸°ì¤€ í’ˆë²ˆ ì…ë ¥", key="suju_find_part")

    if base_part:
        today = date.today()

        df_bom = df_bom_raw.copy()
        bom_cols = list(df_bom.columns)

        # Aì—´ = í’ˆëª©ì½”ë“œ, Bì—´ = í’ˆëª…, Cì—´ = í’ˆë²ˆ
        bom_item_col = pick_col(df_bom, "A", ["í’ˆëª©ì½”ë“œ"])
        bom_name_col = pick_col(df_bom, "B", ["í’ˆëª…"])
        bom_component_col = pick_col(df_bom, "C", ["í’ˆë²ˆ"])

        if not all([bom_item_col, bom_name_col, bom_component_col]):
            st.error("BOM ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(A), í’ˆëª…(B), í’ˆë²ˆ(C)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ê¸°ì¤€ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” BOM í–‰ ê²€ìƒ‰
            df_bom_hit = df_bom[df_bom[bom_component_col] == base_part]

            if df_bom_hit.empty:
                st.info("BOMì—ì„œ í•´ë‹¹ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” ì™„ì„±í’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # 1ì°¨ í’ˆëª©ì½”ë“œ ëª©ë¡
                item_codes = df_bom_hit[bom_item_col].dropna().unique().tolist()
                st.write("1ì°¨ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ):", item_codes)

                df_suju = df_suju_raw.copy()

                suju_part_col = pick_col(df_suju, "J", ["í’ˆë²ˆ"])
                suju_due_col = pick_col(df_suju, "G", ["ì¡°ì •ë‚©ê¸°ì¼ì"])

                if suju_part_col is None or suju_due_col is None:
                    st.error("ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(Jì—´) ë˜ëŠ” ì¡°ì •ë‚©ê¸°ì¼ì(Gì—´)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    df_suju[suju_due_col] = pd.to_datetime(
                        df_suju[suju_due_col], errors="coerce"
                    ).dt.date

                    # 1ì°¨ í’ˆëª©ì½”ë“œë¡œ ê²€ìƒ‰
                    df_suju_hit = df_suju[
                        df_suju[suju_part_col].isin(item_codes)
                    ].copy()

                    # ğŸ” 2ì°¨ BOM ê²½ë¡œë¥¼ ì¼ëŠ”ì§€ ì—¬ë¶€ í”Œë˜ê·¸
                    used_bom2_flow = False

                    # ì—†ìœ¼ë©´ ìƒìœ„(2ì°¨) í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰
                    if df_suju_hit.empty:
                        fallback_item_codes = set()
                        for code in item_codes:
                            df_bom_lvl2 = df_bom[df_bom[bom_component_col] == code]
                            if not df_bom_lvl2.empty:
                                lvl2 = (
                                    df_bom_lvl2[bom_item_col]
                                    .dropna()
                                    .unique()
                                    .tolist()
                                )
                                fallback_item_codes.update(lvl2)

                        fallback_item_codes = list(fallback_item_codes)

                        if fallback_item_codes:
                            st.info("1ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ì—†ì–´, 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                            st.write("2ì°¨ í’ˆëª©ì½”ë“œ:", fallback_item_codes)

                            df_suju_hit = df_suju[
                                df_suju[suju_part_col].isin(fallback_item_codes)
                            ].copy()

                        # âœ… 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œë„ ìˆ˜ì£¼ê°€ ì—†ìœ¼ë©´
                        #    â†’ ê·¸ 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ë‹¤ì‹œ BOM Cì—´(í’ˆë²ˆ)ì„ ë’¤ì ¸ì„œ
                        #       ê±°ê¸°ì„œ ë‚˜ì˜¨ ì™„ì„±í’ˆ í’ˆëª©ì½”ë“œ(Aì—´)ë¡œ ìˆ˜ì£¼ë¥¼ ì¬ê²€ìƒ‰
                        if df_suju_hit.empty and fallback_item_codes:
                            df_bom_from_lvl2 = df_bom[
                                df_bom[bom_component_col].isin(fallback_item_codes)
                            ].copy()

                            if df_bom_from_lvl2.empty:
                                st.warning(
                                    "1ì°¨Â·2ì°¨ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ë¥¼ ì°¾ì§€ ëª»í–ˆê³ , "
                                    "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ BOM í’ˆë²ˆ(Cì—´)ì„ ì¬ê²€ìƒ‰í•´ë„ "
                                    "ê´€ë ¨ í’ˆëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                )
                                df_show = pd.DataFrame()
                            else:
                                # 3ì°¨(ë” ìƒìœ„) ì™„ì„±í’ˆ í’ˆëª©ì½”ë“œ ëª©ë¡
                                third_item_codes = (
                                    df_bom_from_lvl2[bom_item_col]
                                    .dropna()
                                    .unique()
                                    .tolist()
                                )

                                st.info(
                                    "1ì°¨Â·2ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ìˆ˜ì£¼ê°€ ì—†ì–´ì„œ, "
                                    "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì—°ê²°ëœ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ) ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ìˆ˜ì£¼ë¥¼ ì°¾ìŠµë‹ˆë‹¤."
                                )
                                st.write("3ì°¨(ìƒìœ„) í’ˆëª©ì½”ë“œ:", third_item_codes)

                                # 3ì°¨ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ ì‹œíŠ¸ ì¬ê²€ìƒ‰
                                df_suju_bom2 = df_suju[
                                    df_suju[suju_part_col].isin(third_item_codes)
                                ].copy()

                                if df_suju_bom2.empty:
                                    st.warning(
                                        "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì—°ê²°ëœ ì™„ì„±í’ˆ ê¸°ì¤€ìœ¼ë¡œë„ "
                                        "ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                    )
                                    df_show = pd.DataFrame()
                                else:
                                    used_bom2_flow = True

                                    # -------------------------------
                                    # 1ï¸âƒ£ ìœ„ìª½ í‘œ: ìˆ˜ì£¼ ì‹œíŠ¸ ìš”ì•½
                                    #    (í’ˆë²ˆ, í’ˆëª…, ìˆ˜ì£¼ë²ˆí˜¸, ì¡°ì •ë‚©ê¸°ì¼ì, ìˆ˜ëŸ‰, ë§¤ì¶œì²˜)
                                    # -------------------------------
                                    # ì›í•˜ëŠ” í‘œì‹œ ìˆœì„œ ì •ì˜
                                    desired_cols = [
                                        suju_part_col,   # í’ˆë²ˆ (Jì—´)
                                        "í’ˆëª…",
                                        "ìˆ˜ì£¼ë²ˆí˜¸",
                                        suju_due_col,    # ì¡°ì •ë‚©ê¸°ì¼ì (Gì—´)
                                        "ìˆ˜ëŸ‰",
                                        "ë§¤ì¶œì²˜",
                                    ]

                                    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•´ì„œ ìˆœì„œ ìœ ì§€
                                    suju_disp_cols = [
                                        c for c in desired_cols if c in df_suju_bom2.columns
                                    ]

                                    # ë‚©ê¸°ì¼ì ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                                    if suju_due_col in df_suju_bom2.columns:
                                        df_suju_bom2 = df_suju_bom2.sort_values(
                                            by=suju_due_col, ascending=False
                                        )

                                    st.markdown("#### 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê¸°ì¤€ ìˆ˜ì£¼ ì •ë³´")
                                    if suju_disp_cols:
                                        st.dataframe(
                                            df_suju_bom2[suju_disp_cols],
                                            use_container_width=True,
                                        )
                                    else:
                                        # í˜¹ì‹œë¼ë„ ì»¬ëŸ¼ëª…ì„ ëª» ì°¾ì•˜ì„ ë•ŒëŠ” ì „ì²´ ë³´ì—¬ì£¼ê¸°
                                        st.dataframe(
                                            df_suju_bom2,
                                            use_container_width=True,
                                        )


                                    # -------------------------------
                                    # 2ï¸âƒ£ ì•„ë˜ í‘œ: ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ ì—°ê³„
                                    #    (ìˆ˜ì£¼ë²ˆí˜¸ A â†’ ì§€ì‹œë²ˆí˜¸ B, ì§€ì‹œì¼ì I, í’ˆëª… L)
                                    # -------------------------------
                                    if "ìˆ˜ì£¼ë²ˆí˜¸" in df_suju_bom2.columns:
                                        suju_values_bom2 = (
                                            df_suju_bom2["ìˆ˜ì£¼ë²ˆí˜¸"]
                                            .dropna()
                                            .astype(str)
                                            .unique()
                                            .tolist()
                                        )

                                        job_suju_col = pick_col(
                                            df_job_raw, "A", ["ìˆ˜ì£¼ë²ˆí˜¸"]
                                        )
                                        job_jisi_col = pick_col(
                                            df_job_raw, "B", ["ì§€ì‹œë²ˆí˜¸"]
                                        )
                                        job_date_col = pick_col(
                                            df_job_raw, "I", ["ì§€ì‹œì¼ì", "ì‘ì§€ì¼ì"]
                                        )
                                        job_name_col = pick_col(
                                            df_job_raw, "L", ["í’ˆëª…", "ì™„ì„±í’ˆëª…"]
                                        )

                                        if not all(
                                            [job_suju_col, job_jisi_col, job_name_col]
                                        ):
                                            st.info(
                                                "ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸(A), ì§€ì‹œë²ˆí˜¸(B), í’ˆëª…(L)ì„ ëª¨ë‘ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                            )
                                        else:
                                            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë½‘ê¸°
                                            use_cols = [job_suju_col, job_jisi_col]
                                            if job_date_col:
                                                use_cols.append(job_date_col)
                                            use_cols.append(job_name_col)

                                            df_job_map2 = df_job_raw[use_cols].copy()

                                            # ì»¬ëŸ¼ëª… í†µì¼
                                            new_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                            if job_date_col:
                                                new_cols.append("ì§€ì‹œì¼ì")
                                            new_cols.append("í’ˆëª…")
                                            df_job_map2.columns = new_cols

                                            # ë¬¸ìì—´ ë¹„êµìš©
                                            df_job_map2["ìˆ˜ì£¼ë²ˆí˜¸_str"] = df_job_map2[
                                                "ìˆ˜ì£¼ë²ˆí˜¸"
                                            ].astype(str)

                                            df_job_filtered2 = df_job_map2[
                                                df_job_map2["ìˆ˜ì£¼ë²ˆí˜¸_str"].isin(
                                                    suju_values_bom2
                                                )
                                            ].drop(columns=["ìˆ˜ì£¼ë²ˆí˜¸_str"])

                                            if not df_job_filtered2.empty:
                                                subset_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    subset_cols = [
                                                        "ìˆ˜ì£¼ë²ˆí˜¸",
                                                        "ì§€ì‹œë²ˆí˜¸",
                                                        "ì§€ì‹œì¼ì",
                                                        "í’ˆëª…",
                                                    ]

                                                df_job_filtered2 = df_job_filtered2.drop_duplicates(
                                                    subset=subset_cols
                                                )

                                                # ì§€ì‹œì¼ì ìµœì‹ ìˆœ + ì§€ì‹œë²ˆí˜¸ ì •ë ¬
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    df_job_filtered2["_ì§€ì‹œì¼ì_sort"] = pd.to_datetime(
                                                        df_job_filtered2["ì§€ì‹œì¼ì"],
                                                        errors="coerce",
                                                    )
                                                    df_job_filtered2 = df_job_filtered2.sort_values(
                                                        by=["_ì§€ì‹œì¼ì_sort", "ì§€ì‹œë²ˆí˜¸"],
                                                        ascending=[False, True],
                                                    ).drop(columns=["_ì§€ì‹œì¼ì_sort"])
                                                else:
                                                    df_job_filtered2 = df_job_filtered2.sort_values(
                                                        by=["ì§€ì‹œë²ˆí˜¸"]
                                                    )

                                                st.markdown(
                                                    "#### 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê¸°ì¤€ ìˆ˜ì£¼ â†’ ì‘ì—…ì§€ì‹œ ë§¤í•‘"
                                                )

                                                disp_cols2 = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    disp_cols2.append("ì§€ì‹œì¼ì")
                                                disp_cols2.append("í’ˆëª…")

                                                st.dataframe(
                                                    df_job_filtered2[disp_cols2],
                                                    use_container_width=True,
                                                )
                                            else:
                                                st.info(
                                                    "í•´ë‹¹ ìˆ˜ì£¼ë²ˆí˜¸ë¡œ ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì§€ì‹œë²ˆí˜¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                                )

                                    # ì´ ê²½ë¡œì—ì„œëŠ” ì•„ë˜ ì¼ë°˜ df_show ë¡œì§ì„ íƒ€ì§€ ì•Šë„ë¡ ë¹„ì›Œë‘ 
                                    df_show = pd.DataFrame()

                    # ğŸ” BOM 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê²½ë¡œë¥¼ ì“°ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ
                    #    ê¸°ì¡´ ë‚ ì§œ ë²”ìœ„(1ê°œì›”/1ë…„/ê³¼ê±°) ë¡œì§ ìˆ˜í–‰
                    if not used_bom2_flow:
                        if df_suju_hit.empty:
                            st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ ê²€ìƒ‰ëœ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            df_show = pd.DataFrame()
                        else:
                            # === ê²€ìƒ‰ ë²”ìœ„ ì„¤ì • ===
                            one_month_after = today + timedelta(days=30)
                            one_year_after = today + timedelta(days=365)

                            # 1) ì˜¤ëŠ˜ â†’ 1ê°œì›” ì´ë‚´
                            df_1m = df_suju_hit[



