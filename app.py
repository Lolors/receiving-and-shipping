import streamlit as st
import pandas as pd
from datetime import date, timedelta
import io
import os
from html import escape

# ============ S3 ì—°ë™ ============

import boto3
from botocore.exceptions import ClientError

S3_BUCKET = "rec-and-ship"
S3_KEY = "bulk-ledger.xlsx"  # í•­ìƒ ì´ ì´ë¦„ìœ¼ë¡œ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°

def get_s3_client():
    try:
        return boto3.client(
            "s3",
            aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
            aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
            region_name="ap-northeast-2",
        )
    except Exception as e:
        st.error(f"S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

s3_client = get_s3_client()

@st.cache_data(show_spinner=True)
def load_file_from_s3():
    """S3ì— íŒŒì¼ì´ ìˆìœ¼ë©´ bytesë¡œ ì½ì–´ì˜¨ë‹¤."""
    if s3_client is None:
        return None
    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY)
        return obj["Body"].read()
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            return None
        st.error(f"S3ì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# PDF ìƒì„±ìš© (reportlab ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ì²˜ë¦¬)
try:
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.platypus import (
        SimpleDocTemplate,
        Table,
        TableStyle,
        Paragraph,
        Spacer,
    )
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    KOREAN_FONT_NAME = "MalgunGothic"

    # ğŸ”¹ app.py ê¸°ì¤€ìœ¼ë¡œ font/malgun.ttf ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê¸°
    FONT_PATH = os.path.join(os.path.dirname(__file__), "font", "malgun.ttf")

    if not os.path.exists(FONT_PATH):
        st.write("âš ï¸ í°íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤:", FONT_PATH)
        KOREAN_FONT_NAME = "Helvetica"
    else:
        try:
            pdfmetrics.registerFont(TTFont(KOREAN_FONT_NAME, FONT_PATH))
        except Exception as e:
            st.write("âš ï¸ í°íŠ¸ ë¡œë”© ì‹¤íŒ¨:", repr(e))
            KOREAN_FONT_NAME = "Helvetica"

    REPORTLAB_AVAILABLE = True
except ModuleNotFoundError:
    REPORTLAB_AVAILABLE = False
    KOREAN_FONT_NAME = "Helvetica"


st.set_page_config(page_title="ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_data
def load_excel(file_bytes: bytes):
    """bytes ë˜ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ë°›ì•„ ì „ì²´ ì‹œíŠ¸ë¥¼ dictë¡œ ë°˜í™˜"""
    xls = pd.ExcelFile(file_bytes)
    sheets = {}
    for sheet_name in xls.sheet_names:
        try:
            sheets[sheet_name] = pd.read_excel(xls, sheet_name)
        except Exception:
            pass
    return sheets


def get_week_of_month(d: date) -> str:
    """ê°„ë‹¨íˆ: 1~7ì¼=1ì£¼ì°¨, 8~14=2ì£¼ì°¨, ..."""
    week_no = (d.day - 1) // 7 + 1
    return f"{d.month}ì›”{week_no}ì£¼ì°¨"


def ensure_session_df(key: str, columns: list):
    if key not in st.session_state:
        st.session_state[key] = pd.DataFrame(columns=columns)
    return st.session_state[key]


def excel_col_to_index(col_letter: str) -> int:
    """ì—‘ì…€ ì—´ ë¬¸ì(A, B, ... AA, AB...)ë¥¼ 0-base indexë¡œ ë³€í™˜"""
    col_letter = col_letter.upper()
    result = 0
    for ch in col_letter:
        if not ("A" <= ch <= "Z"):
            continue
        result = result * 26 + (ord(ch) - ord("A") + 1)
    return result - 1  # 0-base


def pick_col(df: pd.DataFrame, letter: str, preferred_names: list):
    """
    ìš°ì„  ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ì—‘ì…€ ì—´ ìœ„ì¹˜(letter)ë¡œ ì°¾ê¸°
    (preferred_names ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©)
    """
    cols = list(df.columns)
    for name in preferred_names:
        if name in df.columns:
            return name
    idx = excel_col_to_index(letter)
    if 0 <= idx < len(cols):
        return cols[idx]
    return None


def safe_num(x):
    """ìˆ«ìê°€ ì•„ë‹ˆë©´ ìµœëŒ€í•œ floatìœ¼ë¡œ ë³€í™˜, ì•ˆ ë˜ë©´ 0"""
    try:
        if pd.isna(x):
            return 0
    except Exception:
        pass
    if isinstance(x, (int, float)):
        return float(x)
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return 0.0


# í™”ë©´ì— ë³´ì´ëŠ” í™˜ì… ì˜ˆìƒì¬ê³  í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œ
VISIBLE_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì™„ì„±í’ˆë²ˆ",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# CSVì— ë“¤ì–´ê°ˆ ì „ì²´ ì»¬ëŸ¼ (ìš”ì²­í•œ ìˆœì„œ ê·¸ëŒ€ë¡œ)
CSV_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì§€ì‹œë²ˆí˜¸",
    "ìƒì‚°ê³µì •",
    "ìƒì‚°ì‹œì‘ì¼",
    "ìƒì‚°ì¢…ë£Œì¼",
    "ì¢…ë£Œì¡°ê±´",
    "í™˜ì…ì¼",
    "í™˜ì…ì£¼ì°¨",
    "ì™„ì„±í’ˆë²ˆ",
    "ì™„ì„±í’ˆëª…",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# -----------------------------
# ì§‘ê³„ í…Œì´ë¸” ë¹Œë“œ
# -----------------------------
def build_aggregates(df_in_raw, df_job_raw, df_result_raw, df_defect_raw, df_stock_raw):
    """
    í° ì›ë³¸ ì‹œíŠ¸ë“¤ì„ ë¯¸ë¦¬ groupby í•´ì„œ, ë‚˜ì¤‘ì—” mergeë§Œ í•˜ë„ë¡ ë§Œë“œëŠ” ì§‘ê³„ í…Œì´ë¸”ë“¤
    """
    aggregates = {}

    # === 1) ì…ê³  ì§‘ê³„: [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ë³„ ERPë¶ˆì¶œìˆ˜ëŸ‰/í˜„ì¥ì‹¤ë¬¼ì…ê³  í•©ê³„ ===
    # ìˆ˜ì£¼ë²ˆí˜¸: Bì—´, ì§€ì‹œë²ˆí˜¸: Cì—´, í’ˆë²ˆ: Mì—´, ERPë¶ˆì¶œìˆ˜ëŸ‰: Qì—´, í˜„ì¥ì‹¤ë¬¼ì…ê³ : Rì—´
    in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
    in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
    in_erp_col = pick_col(df_in_raw, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰"])
    in_real_col = pick_col(df_in_raw, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if all([in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]):
        df_in = df_in_raw[
            [in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]
        ].copy()
        df_in.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        agg_in = (
            df_in.groupby(["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)
            .agg({"ERPë¶ˆì¶œìˆ˜ëŸ‰": "sum", "í˜„ì¥ì‹¤ë¬¼ì…ê³ ": "sum"})
        )
        aggregates["in"] = agg_in
    else:
        aggregates["in"] = pd.DataFrame(
            columns=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        )

    # === 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„: ì§€ì‹œë²ˆí˜¸ë³„ ì§€ì‹œìˆ˜ëŸ‰ ===
    job_jisi_col = (
        "ì§€ì‹œë²ˆí˜¸"
        if "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
        else pick_col(df_job_raw, "F", ["ì§€ì‹œë²ˆí˜¸"])
    )
    job_qty_col = (
        "ìˆ˜ëŸ‰"
        if "ìˆ˜ëŸ‰" in df_job_raw.columns
        else pick_col(df_job_raw, "R", ["ìˆ˜ëŸ‰", "ì§€ì‹œìˆ˜ëŸ‰"])
    )

    if job_jisi_col and job_qty_col:
        df_job = df_job_raw[[job_jisi_col, job_qty_col]].copy()
        df_job.columns = ["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"]
        agg_job = df_job.groupby("ì§€ì‹œë²ˆí˜¸", as_index=False).agg({"ì§€ì‹œìˆ˜ëŸ‰": "sum"})
        aggregates["job"] = agg_job
    else:
        aggregates["job"] = pd.DataFrame(columns=["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"])

    # === 3) ìƒì‚°ì‹¤ì  ì§‘ê³„: ìˆ˜ì£¼ë²ˆí˜¸ë³„ ì–‘í’ˆ / QCìƒ˜í”Œ / ê¸°íƒ€ìƒ˜í”Œ í•©ê³„ ===
    # ìˆ˜ì£¼ë²ˆí˜¸: ë³´í†µ "ìˆ˜ì£¼ë²ˆí˜¸" ì»¬ëŸ¼ ì‚¬ìš©
    res_suju_col = (
        "ìˆ˜ì£¼ë²ˆí˜¸"
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "E", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    )

    # ì–‘í’ˆ(ì‹¤ì œ ìƒì‚°ìˆ˜ëŸ‰) ì»¬ëŸ¼ ì°¾ê¸°
    res_good_col = None
    for cand in ["ì–‘í’ˆ", "ì–‘í’ˆìˆ˜ëŸ‰", "ì–‘í’ˆìˆ˜", "í•©ê²©", "ìƒì‚°ìˆ˜ëŸ‰"]:
        if cand in df_result_raw.columns:
            res_good_col = cand
            break

    # QCìƒ˜í”Œ: AGì—´, ê¸°íƒ€ìƒ˜í”Œ: AHì—´ ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì°¾ê¸°
    res_qc_col = pick_col(df_result_raw, "AG", ["QCìƒ˜í”Œ"])
    res_etc_col = pick_col(df_result_raw, "AH", ["ê¸°íƒ€ìƒ˜í”Œ"])

    # ìµœì†Œí•œ ìˆ˜ì£¼ë²ˆí˜¸ëŠ” ìˆì–´ì•¼ ì§‘ê³„ ê°€ëŠ¥
    if res_suju_col:
        use_cols = [res_suju_col]
        if res_good_col:
            use_cols.append(res_good_col)
        if res_qc_col:
            use_cols.append(res_qc_col)
        if res_etc_col:
            use_cols.append(res_etc_col)

        df_res = df_result_raw[use_cols].copy()

        rename_map = {res_suju_col: "ìˆ˜ì£¼ë²ˆí˜¸"}
        if res_good_col:
            rename_map[res_good_col] = "ìƒì‚°ìˆ˜ëŸ‰"
        if res_qc_col:
            rename_map[res_qc_col] = "QCìƒ˜í”Œ"
        if res_etc_col:
            rename_map[res_etc_col] = "ê¸°íƒ€ìƒ˜í”Œ"

        df_res = df_res.rename(columns=rename_map)

        # NaN â†’ 0 ì²˜ë¦¬ í›„ ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€ í•©ê³„
        for col in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
            if col in df_res.columns:
                df_res[col] = df_res[col].apply(safe_num)

        agg_res = df_res.groupby("ìˆ˜ì£¼ë²ˆí˜¸", as_index=False).agg("sum")

        aggregates["result"] = agg_res
    else:
        aggregates["result"] = pd.DataFrame(
            columns=["ìˆ˜ì£¼ë²ˆí˜¸", "ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]
        )

    # === 4) ë¶ˆëŸ‰ ì§‘ê³„: [ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ]ë³„ ì›ë¶ˆ/ì‘ë¶ˆ ìˆ˜ëŸ‰ ===
    def_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_defect_raw.columns
        else pick_col(df_defect_raw, "C", ["ì‘ì§€ë²ˆí˜¸"])
    )
    def_part_col = (
        "íˆ¬ì…í’ˆë²ˆ"
        if "íˆ¬ì…í’ˆë²ˆ" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Q", ["íˆ¬ì…í’ˆë²ˆ"])
    )
    def_qty_col = (
        "ë¶ˆëŸ‰ìˆ˜ëŸ‰"
        if "ë¶ˆëŸ‰ìˆ˜ëŸ‰" in df_defect_raw.columns
        else pick_col(df_defect_raw, "W", ["ë¶ˆëŸ‰ìˆ˜ëŸ‰"])
    )
    def_type_col = (
        "ë¶ˆëŸ‰ìœ í˜•.1"
        if "ë¶ˆëŸ‰ìœ í˜•.1" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Z", ["ë¶ˆëŸ‰ìœ í˜•.1", "ë¶ˆëŸ‰ìœ í˜•"])
    )

    if def_jisi_col and def_part_col and def_qty_col and def_type_col:
        df_def = df_defect_raw[
            [def_jisi_col, def_part_col, def_qty_col, def_type_col]
        ].copy()
        df_def.columns = ["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¶ˆëŸ‰ìˆ˜ëŸ‰", "ë¶ˆëŸ‰ìœ í˜•"]
        df_def["ë¶ˆëŸ‰ìœ í˜•"] = df_def["ë¶ˆëŸ‰ìœ í˜•"].astype(str)

        # ì›ë¶ˆ
        df_orig = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì›)")].copy()
        agg_orig = (
            df_orig.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì›ë¶ˆ"})
        )

        # ì‘ë¶ˆ
        df_proc = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì‘)")].copy()
        agg_proc = (
            df_proc.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì‘ë¶ˆ"})
        )

        # ë‘˜ í•©ì¹˜ê¸°
        agg_def = pd.merge(agg_orig, agg_proc, on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], how="outer")
        aggregates["defect"] = agg_def
    else:
        aggregates["defect"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ì›ë¶ˆ", "ì‘ë¶ˆ"]
        )

    # === 5) ì¬ê³  ì§‘ê³„: í’ˆë²ˆë³„ ERPì¬ê³  (ì‘ì—…ì¥ WC501~WC504) ===
    stock_wc_col = pick_col(df_stock_raw, "A", ["ì‘ì—…ì¥"])
    stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])

    # ERPì¬ê³ ëŠ” ë°˜ë“œì‹œ "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" ì»¬ëŸ¼ì„ ì‚¬ìš© (ì—†ìœ¼ë©´ Nì—´ fallback)
    if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in df_stock_raw.columns:
        stock_qty_col = "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"
    else:
        stock_qty_col = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

    if stock_wc_col and stock_part_col and stock_qty_col:
        df_stock = df_stock_raw[
            [stock_wc_col, stock_part_col, stock_qty_col]
        ].copy()
        df_stock.columns = ["ì‘ì—…ì¥", "í’ˆë²ˆ", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
        df_stock = df_stock[df_stock["ì‘ì—…ì¥"].isin(["WC501", "WC502", "WC503", "WC504"])]
        if not df_stock.empty:
            agg_stock = (
                df_stock.groupby("í’ˆë²ˆ", as_index=False)["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
                .sum()
                .rename(columns={"ì‹¤ì¬ê³ ìˆ˜ëŸ‰": "ERPì¬ê³ "})
            )
            aggregates["stock"] = agg_stock
        else:
            aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])
    else:
        aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])

    return aggregates


# -----------------------------
# í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚° (merge ê¸°ë°˜)
# -----------------------------
def recalc_return_expectation(df_return, aggs):
    """
    df_return(í™˜ì…ê´€ë¦¬ í…Œì´ë¸”)ì— ì§‘ê³„ ë°ì´í„°(aggs)ë¥¼ mergeë¡œ ë¶™ì—¬ì„œ
    ERPë¶ˆì¶œìˆ˜ëŸ‰, í˜„ì¥ì‹¤ë¬¼ì…ê³ , ì§€ì‹œìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰, QCìƒ˜í”Œ, ê¸°íƒ€ìƒ˜í”Œ, ì›ë¶ˆ, ì‘ë¶ˆ, ERPì¬ê³ , ì˜ˆìƒì¬ê³ ë¥¼ ê³„ì‚°

    ì˜ˆìƒì¬ê³  = í˜„ì¥ì‹¤ë¬¼ì…ê³  - (ìƒì‚°ìˆ˜ëŸ‰ + QCìƒ˜í”Œ + ê¸°íƒ€ìƒ˜í”Œ) * ë‹¨ìœ„ìˆ˜ëŸ‰ - ì‘ë¶ˆ
    """
    if df_return.empty:
        return pd.DataFrame(columns=CSV_COLS)

    # [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    df = df_return.drop_duplicates(
        subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
    ).copy()

    # 1) ì…ê³  ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["in"],
        how="left",
        on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
        suffixes=("", "_in"),
    )

    # 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["job"],
        how="left",
        on="ì§€ì‹œë²ˆí˜¸",
    )

    # 3) ìƒì‚°ì‹¤ì  ì§‘ê³„ ë¶™ì´ê¸° (ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€: ìƒì‚°ìˆ˜ëŸ‰ / QC / ê¸°íƒ€ìƒ˜í”Œ)
    df = df.merge(
        aggs["result"],
        how="left",
        on="ìˆ˜ì£¼ë²ˆí˜¸",
    )

    # 4) ë¶ˆëŸ‰ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["defect"],
        how="left",
        on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
    )

    # 5) ì¬ê³  ì§‘ê³„ ë¶™ì´ê¸°
    if "ERPì¬ê³ " in df.columns:
        df = df.drop(columns=["ERPì¬ê³ "])
    df = df.merge(
        aggs["stock"],
        how="left",
        on="í’ˆë²ˆ",
    )

    # ìˆ«ì ì»¬ëŸ¼ë“¤ NaN -> 0
    num_cols = [
        "ERPë¶ˆì¶œìˆ˜ëŸ‰",
        "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
        "ì§€ì‹œìˆ˜ëŸ‰",
        "ìƒì‚°ìˆ˜ëŸ‰",
        "QCìƒ˜í”Œ",
        "ê¸°íƒ€ìƒ˜í”Œ",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ì›ë¶ˆ",
        "ì‘ë¶ˆ",
        "ERPì¬ê³ ",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = df[col].apply(safe_num)
        else:
            df[col] = 0.0

    # âœ… ë„¤ê°€ ë§í•œ ê³µì‹ ê·¸ëŒ€ë¡œ
    df["ì˜ˆìƒì¬ê³ "] = (
        df["í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        - (df["ìƒì‚°ìˆ˜ëŸ‰"] + df["QCìƒ˜í”Œ"] + df["ê¸°íƒ€ìƒ˜í”Œ"]) * df["ë‹¨ìœ„ìˆ˜ëŸ‰"]
        - df["ì›ë¶ˆ"]
        - df["ì‘ë¶ˆ"]
    )

    # ì™„ì„±í’ˆëª…ì€ ì œí’ˆëª… ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    df["ì™„ì„±í’ˆëª…"] = df.get("ì œí’ˆëª…", None)

    # CSVìš© ì „ì²´ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    for col in CSV_COLS:
        if col not in df.columns:
            df[col] = None

    out = df[CSV_COLS].copy()
    return out

# -----------------------------
# PDF ìƒì„± í•¨ìˆ˜
# -----------------------------
if REPORTLAB_AVAILABLE:
    from xml.sax.saxutils import escape
    from reportlab.platypus import PageBreak
    from reportlab.graphics.barcode import code128
    from reportlab.graphics.shapes import Drawing
    from reportlab.lib.units import mm

    def generate_pdf(
        df_export: pd.DataFrame,
        uploaded_image=None,
        pasted_text: str | None = None,
    ) -> bytes:
        """
        - ì œëª© / í‘œ ëª¨ë‘ ì™¼ìª½ ì •ë ¬
        - pasted_textê°€ ìˆìœ¼ë©´ ì œëª© ì•„ë˜ì— ê·¸ëŒ€ë¡œ ì¶œë ¥
        - uploaded_imageëŠ” ì§€ê¸ˆì€ ì•ˆ ì¨ë„ ë¨(ì°¨í›„ í™•ì¥ìš©)
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Table,
            TableStyle,
            Paragraph,
            Spacer,
            Image,
        )
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors

        buffer = io.BytesIO()

        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=20,
            rightMargin=20,
            topMargin=20,
            bottomMargin=20,
        )

        styles = getSampleStyleSheet()

        title_style = ParagraphStyle(
            "TitleStyle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=15,
            alignment=0,   # LEFT
        )

        text_style = ParagraphStyle(
            "TextStyle",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=10,
            leading=14,
            alignment=0,   # LEFT
        )

        table_style = TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                ("ALIGN", (0, 0), (-1, -1), "LEFT"),  # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
                ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                ("FONTSIZE", (0, 0), (-1, -1), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                ("BOTTOMPADDING", (0, 0), (-1, -1), 20),
                ("TOPPADDING",    (0, 0), (-1, -1), 20),
                ("MINROWHEIGHT",    (0, 0), (-1, -1), 35),
            ]
        )

        story = []

        # 1) ì œëª©
        suju_list = df_export["ìˆ˜ì£¼ë²ˆí˜¸"].dropna().astype(str).unique()
        name_list = df_export["ì™„ì„±í’ˆëª…"].dropna().astype(str).unique()
        title_text = f"{suju_list[0] if len(suju_list) else ''} {name_list[0] if len(name_list) else ''}".strip()

        story.append(Paragraph(title_text, title_style))
        story.append(Spacer(1, 12))

        # 2) ìƒë‹¨ ë©”ëª¨ (í…ìŠ¤íŠ¸)
        if pasted_text is not None and pasted_text.strip() != "":
            # <, >, & ë“± ì´ìŠ¤ì¼€ì´í”„ + ì¤„ë°”ê¿ˆì„ <br/>ë¡œ ë³€í™˜
            safe_text = escape(pasted_text).replace("\n", "<br/>")
            story.append(Paragraph(safe_text, text_style))
            story.append(Spacer(1, 12))

        # 3) (ì›í•˜ë©´ ì´ë¯¸ì§€ë„ ì—¬ê¸°ì—)
        if uploaded_image:
            try:
                img = Image(uploaded_image, width=400, height=300)
                story.append(img)
                story.append(Spacer(1, 12))
            except Exception:
                pass

        # í‘œ êµ¬ì„±: ê¸°ì¡´ + 1P, 2P, 3P, 4P 4ì¹¸ ì¶”ê°€
        base_cols = ["í’ˆë²ˆ", "í’ˆëª…", "ì‘ë¶ˆ", "ì˜ˆìƒì¬ê³ ", "ERPì¬ê³ "]
        table_cols = base_cols + ["1P", "2P", "3P", "4P"]
        table_data = [table_cols]

        for _, row in df_export.iterrows():
                # df_export ì—ëŠ” 1P~4P ì»¬ëŸ¼ì´ ì—†ìœ¼ë‹ˆê¹Œ, ê¸°ì¡´ ë°ì´í„°ë§Œ ë„£ê³  4ì¹¸ì€ ê³µë°±ìœ¼ë¡œ ì±„ì›€
                base_values = [str(row.get(c, "")) for c in base_cols]
                extra_values = ["", "", "", ""]  # 1P, 2P, 3P, 4P
                table_data.append(base_values + extra_values)

        # ğŸ”¥ í–‰ ë†’ì´ (í—¤ë”ëŠ” ê¸°ë³¸, ë°ì´í„° í–‰ë§Œ ë†’ê²Œ)
        default_height = None        # í—¤ë”
        data_height = 40             # ë°ì´í„° í–‰
        row_heights = [default_height] + [data_height] * (len(table_data) - 1)

        # ğŸ”¥ ì»¬ëŸ¼ í­ ì„¤ì •
        #  - ì•ì˜ 5ê°œ ì»¬ëŸ¼ì€ None(ìë™)
        #  - 1P~4P 4ì¹¸ë§Œ ë„“ê²Œ(ì˜ˆ: 80ptì”©) â†’ í•„ìš”í•˜ë©´ ìˆ«ì í‚¤ì›Œì„œ ì¡°ì ˆ
        col_widths = [None, None, None, None, None, 130, 130, 80, 80]

        table = Table(
                table_data,
                repeatRows=1,
                rowHeights=row_heights,
                colWidths=col_widths,
                hAlign="LEFT",   # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
        )

        table.setStyle(
                TableStyle(
                        [
                                ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                                ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                                ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                                ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                                ("FONTSIZE", (0, 0), (-1, -1), 8),
                                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                                ("LEFTPADDING", (0, 0), (-1, -1), 0),
                                ("RIGHTPADDING", (0, 0), (-1, -1), 4),

                                # ë°ì´í„° í–‰ë§Œ ìœ„/ì•„ë˜ ì—¬ë°± í¬ê²Œ
                                ("TOPPADDING",    (0, 1), (-1, -1), 12),
                                ("BOTTOMPADDING", (0, 1), (-1, -1), 12),
                        ]
                )
        )

        story.append(table)

        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

    # ğŸ”¹ ë¶€ìì¬ë°˜ì… ë¼ë²¨ PDF ìƒì„±ìš©
    def generate_label_pdf(df_labels: pd.DataFrame) -> bytes:
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
        from reportlab.lib.pagesizes import A4
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        import io

        buffer = io.BytesIO()

        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            leftMargin=40,
            rightMargin=40,
            topMargin=40,
            bottomMargin=40,
        )

        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            "LabelTitle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=32,
            alignment=1,
        )
        text_style = ParagraphStyle(
            "LabelText",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=14,
            leading=20,
            alignment=0,
        )

        story = []

        for idx, row in df_labels.iterrows():
            í’ˆëª… = str(row.get("í’ˆëª…", ""))
            í’ˆë²ˆ = str(row.get("í’ˆë²ˆ", ""))
            ë‹¨ìœ„ìˆ˜ëŸ‰ = str(row.get("ë‹¨ìœ„ìˆ˜ëŸ‰", ""))
            í™˜ì…ì¼ = row.get("í™˜ì…ì¼", "")

            try:
                if pd.notna(í™˜ì…ì¼):
                    í™˜ì…ì¼_str = pd.to_datetime(í™˜ì…ì¼).strftime("%Y-%m-%d")
                else:
                    í™˜ì…ì¼_str = ""
            except:
                í™˜ì…ì¼_str = str(í™˜ì…ì¼)

            date_for_barcode = (
                pd.to_datetime(í™˜ì…ì¼).strftime("%y%m%d")
                if pd.notna(í™˜ì…ì¼) else date.today().strftime("%y%m%d")
            )
            barcode_value = f"B{date_for_barcode}-{idx+1:07d}"

            story.append(Paragraph("ë¶€ìì¬ë°˜ì…", title_style))
            story.append(Spacer(1, 30))

            lines = [
                f"í’ˆëª…      {escape(í’ˆëª…)}",
                f"í’ˆëª©ì½”ë“œ  {escape(í’ˆë²ˆ)}",
                f"ë‹¨ìœ„ìˆ˜ëŸ‰  {escape(ë‹¨ìœ„ìˆ˜ëŸ‰)}",
                f"ë°˜ì…ì¼ì  {escape(í™˜ì…ì¼_str)}",
            ]
            for line in lines:
                story.append(Paragraph(line, text_style))
                story.append(Spacer(1, 6))

            story.append(Spacer(1, 40))

            bc = code128.Code128(barcode_value, barHeight=20*mm, barWidth=0.5)
            drawing = Drawing(0, 0)
            drawing.add(bc)
            story.append(drawing)

            story.append(Spacer(1, 10))
            story.append(Paragraph(barcode_value, text_style))

            if idx != len(df_labels) - 1:
                story.append(PageBreak())

        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

else:
    def generate_pdf(*args, **kwargs):
        raise RuntimeError("reportlab íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë¼ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    def generate_label_pdf(*args, **kwargs):
        raise RuntimeError("reportlab íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë¼ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")


# -----------------------------
# ë©”ì¸ í™”ë©´
# -----------------------------
st.title("ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

menu = st.radio(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¦ ì…ê³  ì¡°íšŒ", "â†©ï¸ í™˜ì… ê´€ë¦¬", "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°", "ğŸ§© ê³µí†µìì¬"],
    horizontal=True,
)

# ==========================================
# ğŸ“¤ 1. íŒŒì¼ ì—…ë¡œë“œ íƒ­ (S3ì— ì €ì¥)
# ==========================================
if menu == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    st.subheader("ğŸ“¤ 2025ë…„ ë¶€ìì¬ ê´€ë¦¬ëŒ€ì¥ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xlsm", "xlsx"])

    if uploaded_file and s3_client is not None:
        try:
            s3_client.upload_fileobj(uploaded_file, S3_BUCKET, S3_KEY)
            # ìºì‹œ ì´ˆê¸°í™”
            load_file_from_s3.clear()
            load_excel.clear()
            st.success("S3 ì—…ë¡œë“œ ì™„ë£Œ! ë‹¤ë¥¸ íƒ­ì—ì„œ ë°ì´í„° ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    elif uploaded_file and s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.stop()  # ì—…ë¡œë“œ íƒ­ì—ì„œëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ


# ==========================================
# ë‚˜ë¨¸ì§€ íƒ­: S3ì—ì„œ íŒŒì¼ ë¡œë”©
# ==========================================
file_bytes = load_file_from_s3()
if file_bytes is None:
    st.warning("S3ì— ì—…ë¡œë“œëœ ê´€ë¦¬ëŒ€ì¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ] íƒ­ì—ì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    st.stop()

sheets = load_excel(file_bytes)

# í•„ìˆ˜ ì‹œíŠ¸ ì²´í¬
required_sheets = ["ì…ê³ ", "ì‘ì—…ì§€ì‹œ", "ìˆ˜ì£¼", "BOM", "ì¬ê³ ", "ìƒì‚°ì‹¤ì ", "ë¶ˆëŸ‰"]
missing = [s for s in required_sheets if s not in sheets]
if missing:
    st.error(f"ë‹¤ìŒ ì‹œíŠ¸ê°€ ì—‘ì…€ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
    st.stop()

df_in_raw = sheets["ì…ê³ "]
df_job_raw = sheets["ì‘ì—…ì§€ì‹œ"]
df_suju_raw = sheets["ìˆ˜ì£¼"]
df_bom_raw = sheets["BOM"]
df_stock_raw = sheets["ì¬ê³ "]
df_result_raw = sheets["ìƒì‚°ì‹¤ì "]
df_defect_raw = sheets["ë¶ˆëŸ‰"]

# ì§‘ê³„ëŠ” í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹œ ìµœì´ˆ 1íšŒ
if "aggregates" not in st.session_state:
    st.session_state["aggregates"] = None


# ============================
# 2. ì…ê³  ì¡°íšŒ íƒ­
# ============================
if menu == "ğŸ“¦ ì…ê³  ì¡°íšŒ":
    st.header("ğŸ“¦ ì…ê³  ì¡°íšŒ")
    st.caption("ìš”ì²­ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì…ê³  ë‚´ì—­ì„ ì¡°íšŒí•©ë‹ˆë‹¤.")

    # ì…ê³  ì‹œíŠ¸ ì›ë³¸
    df_in = df_in_raw.copy()

    # ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ ì°¾ê¸°
    req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    if req_date_col is None:
        st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜
        df_in[req_date_col] = pd.to_datetime(df_in[req_date_col], errors="coerce").dt.date

        # ğŸ”¹ ê¸°ë³¸ ë²”ìœ„: ì–´ì œ ~ ì˜¤ëŠ˜
        today = date.today()
        default_start = today - timedelta(days=1)

        start_date, end_date = st.date_input(
            "ìš”ì²­ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
            (default_start, today),
            key="in_date_range",
        )

        # Streamlit ë²„ì „ì— ë”°ë¼ tuple ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ì„œ ë°©ì–´ ì½”ë“œ
        if isinstance(start_date, (tuple, list)):
            start_date, end_date = start_date

        # í•„í„° ë§ˆìŠ¤í¬
        mask = (df_in[req_date_col] >= start_date) & (df_in[req_date_col] <= end_date)

        # ê° ì—´ ì»¬ëŸ¼ ì°¾ê¸°
        col_req_no   = pick_col(df_in, "L", ["ìš”ì²­ë²ˆí˜¸"])
        col_part     = pick_col(df_in, "M", ["í’ˆë²ˆ"])
        col_name     = pick_col(df_in, "O", ["í’ˆëª…"])
        col_req_qty  = pick_col(df_in, "P", ["ìš”ì²­ìˆ˜ëŸ‰"])
        col_erp_out  = pick_col(df_in, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "ë¶ˆì¶œìˆ˜ëŸ‰"])
        col_real_in  = pick_col(df_in, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

        raw_cols = [c for c in [
            req_date_col,
            col_req_no,
            col_part,
            col_name,
            col_req_qty,
            col_erp_out,
            col_real_in,
        ] if c is not None]

        if not raw_cols:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_filtered = df_in.loc[mask, raw_cols].copy()

            # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë§ì¶”ê¸°
            rename_map = {}
            rename_map[req_date_col] = "ìš”ì²­ë‚ ì§œ"
            if col_req_no:  rename_map[col_req_no]  = "ìš”ì²­ë²ˆí˜¸"
            if col_part:    rename_map[col_part]    = "í’ˆë²ˆ"
            if col_name:    rename_map[col_name]    = "í’ˆëª…"
            if col_req_qty: rename_map[col_req_qty] = "ìš”ì²­ìˆ˜ëŸ‰"
            if col_erp_out: rename_map[col_erp_out] = "ERPë¶ˆì¶œìˆ˜ëŸ‰"
            if col_real_in: rename_map[col_real_in] = "í˜„ì¥ì‹¤ë¬¼ì…ê³ "

            df_filtered.rename(columns=rename_map, inplace=True)

            # ğŸ”¥ ì—‘ì…€ì—ì„œ "ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰"ì´ ìœ„ë¡œ ì˜¤ë„ë¡: ì¸ë±ìŠ¤ ì—­ìˆœ ì •ë ¬
            df_filtered = df_filtered.iloc[::-1].reset_index(drop=True)

            if df_filtered.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(df_filtered, use_container_width=True)

                # CSV ë‹¤ìš´ë¡œë“œ
                csv_inbound = df_filtered.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ì´ ì¡°íšŒ ê²°ê³¼ë¥¼ CSVë¡œ ë°›ê¸°",
                    data=csv_inbound,
                    file_name=f"ì…ê³ ì¡°íšŒ_{start_date}_{end_date}.csv",
                    mime="text/csv",
                )


# ============================================================
# ğŸ” 3. ìˆ˜ì£¼ ì°¾ê¸° í™”ë©´
# ============================================================
if menu == "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°":
        st.subheader("ğŸ” ìˆ˜ì£¼ ì°¾ê¸°")

        st.markdown(
            """
            **ë™ì‘ ë°©ì‹**

            1. ê¸°ì¤€ í’ˆë²ˆì„ ì…ë ¥í•œë‹¤.  
            2. BOM ì‹œíŠ¸ì˜ **Cì—´ í’ˆë²ˆ**ì—ì„œ ê¸°ì¤€ í’ˆë²ˆê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ê³ , ê·¸ í–‰ì˜ **í’ˆëª©ì½”ë“œ(Aì—´)** ê°’ì„ êµ¬í•œë‹¤.  
            3. ì´ í’ˆëª©ì½”ë“œë¥¼ **ìˆ˜ì£¼ ì‹œíŠ¸ì˜ í’ˆë²ˆ(Jì—´)**ì—ì„œ ê²€ìƒ‰í•œë‹¤.  
            4. ì—†ìœ¼ë©´ 2ë‹¨ê³„ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•œë‹¤.  
            5. ì˜¤ëŠ˜(today) ê¸°ì¤€ìœ¼ë¡œ **1ê°œì›” ì´ë‚´ â†’ 1ë…„ ì´ë‚´ â†’ ê³¼ê±° 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”** ìˆœìœ¼ë¡œ ìœ íš¨í•œ ìˆ˜ì£¼ë¥¼ ì°¾ëŠ”ë‹¤.  
            """
        )

        base_part = st.text_input("ê¸°ì¤€ í’ˆë²ˆ ì…ë ¥", key="suju_find_part")

        if base_part:
                today = date.today()

                df_bom = df_bom_raw.copy()
                bom_cols = list(df_bom.columns)

                # Aì—´ = í’ˆëª©ì½”ë“œ, Bì—´ = í’ˆëª…
                bom_item_col = pick_col(df_bom, "A", ["í’ˆëª©ì½”ë“œ"])
                bom_name_col = pick_col(df_bom, "B", ["í’ˆëª…"])
                bom_component_col = pick_col(df_bom, "C", ["í’ˆë²ˆ"])

                if not all([bom_item_col, bom_name_col, bom_component_col]):
                        st.error("BOM ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(A), í’ˆëª…(B), í’ˆë²ˆ(C)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                        # ê¸°ì¤€ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” BOM í–‰ ê²€ìƒ‰
                        df_bom_hit = df_bom[df_bom[bom_component_col] == base_part]

                        if df_bom_hit.empty:
                                st.info("BOMì—ì„œ í•´ë‹¹ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” ì™„ì„±í’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                                # 1ì°¨ í’ˆëª©ì½”ë“œ ëª©ë¡
                                item_codes = df_bom_hit[bom_item_col].dropna().unique().tolist()
                                st.write("1ì°¨ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ):", item_codes)

                                df_suju = df_suju_raw.copy()
                                suju_cols = list(df_suju.columns)

                                suju_part_col = pick_col(df_suju, "J", ["í’ˆë²ˆ"])
                                suju_due_col = pick_col(df_suju, "G", ["ì¡°ì •ë‚©ê¸°ì¼ì"])

                                df_suju[suju_due_col] = pd.to_datetime(
                                        df_suju[suju_due_col], errors="coerce"
                                ).dt.date

                                # 1ì°¨ í’ˆëª©ì½”ë“œë¡œ ê²€ìƒ‰
                                df_suju_hit = df_suju[df_suju[suju_part_col].isin(item_codes)].copy()

                                # ì—†ìœ¼ë©´ ìƒìœ„(2ì°¨) í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰
                                if df_suju_hit.empty:
                                        fallback_item_codes = set()
                                        for code in item_codes:
                                                df_bom_lvl2 = df_bom[df_bom[bom_component_col] == code]
                                                if not df_bom_lvl2.empty:
                                                        lvl2 = df_bom_lvl2[bom_item_col].dropna().unique().tolist()
                                                        fallback_item_codes.update(lvl2)

                                        fallback_item_codes = list(fallback_item_codes)
                                        st.info("1ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ì—†ì–´, 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                                        st.write("2ì°¨ í’ˆëª©ì½”ë“œ:", fallback_item_codes)

                                        df_suju_hit = df_suju[df_suju[suju_part_col].isin(fallback_item_codes)].copy()

                                if df_suju_hit.empty:
                                        st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ ê²€ìƒ‰ëœ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                        # === ê²€ìƒ‰ ë²”ìœ„ ì„¤ì • ===
                                        one_month_after = today + timedelta(days=30)
                                        one_year_after  = today + timedelta(days=365)

                                        # 1) ì˜¤ëŠ˜ â†’ 1ê°œì›” ì´ë‚´
                                        df_1m = df_suju_hit[
                                                df_suju_hit[suju_due_col].between(today, one_month_after)
                                        ].copy()

                                        if not df_1m.empty:
                                                st.success("ì˜¤ëŠ˜ ê¸°ì¤€ 1ê°œì›” ì´ë‚´ ìˆ˜ì£¼ ë°œê²¬!")
                                                df_show = df_1m

                                        else:
                                                # 2) ì˜¤ëŠ˜ â†’ 1ë…„ ì´ë‚´
                                                df_1y = df_suju_hit[
                                                        df_suju_hit[suju_due_col].between(today, one_year_after)
                                                ].copy()

                                                if not df_1y.empty:
                                                        st.info("1ê°œì›” ì´ë‚´ëŠ” ì—†ê³ , 1ë…„ ì´ë‚´ ìˆ˜ì£¼ê°€ ìˆìŠµë‹ˆë‹¤.")
                                                        df_1y.sort_values(by=suju_due_col, ascending=False, inplace=True)
                                                        df_show = df_1y

                                                else:
                                                        # 3) ê³¼ê±° íƒìƒ‰: 3ê°œì›”Â·6ê°œì›”Â·12ê°œì›”
                                                        back_3m  = today - timedelta(days=90)
                                                        back_6m  = today - timedelta(days=180)
                                                        back_12m = today - timedelta(days=365)

                                                        df_back3 = df_suju_hit[
                                                                df_suju_hit[suju_due_col].between(back_3m, today)
                                                        ].copy()

                                                        if not df_back3.empty:
                                                                st.info("1ë…„ ì´ë‚´ ìˆ˜ì£¼ëŠ” ì—†ì–´ì„œ, ê³¼ê±° 3ê°œì›” ìˆ˜ì£¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
                                                                df_back3.sort_values(by=suju_due_col, ascending=False, inplace=True)
                                                                df_show = df_back3

                                                        else:
                                                                df_back6 = df_suju_hit[
                                                                        df_suju_hit[suju_due_col].between(back_6m, today)
                                                                ].copy()

                                                                if not df_back6.empty:
                                                                        st.info("3ê°œì›” ì´ë‚´ ì—†ìŒ â†’ ê³¼ê±° 6ê°œì›” ìˆ˜ì£¼ í‘œì‹œ.")
                                                                        df_back6.sort_values(by=suju_due_col, ascending=False, inplace=True)
                                                                        df_show = df_back6

                                                                else:
                                                                        df_back12 = df_suju_hit[
                                                                                df_suju_hit[suju_due_col].between(back_12m, today)
                                                                        ].copy()

                                                                        if not df_back12.empty:
                                                                                st.info("6ê°œì›” ì´ë‚´ ì—†ìŒ â†’ ê³¼ê±° 12ê°œì›” ìˆ˜ì£¼ í‘œì‹œ.")
                                                                                df_back12.sort_values(by=suju_due_col, ascending=False, inplace=True)
                                                                                df_show = df_back12
                                                                        else:
                                                                                st.warning("ê³¼ê±° 12ê°œì›”ê¹Œì§€ë„ í•´ë‹¹ í’ˆëª©ì½”ë“œì˜ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                                                                df_show = pd.DataFrame()

                                        # ===== ê²°ê³¼ í‘œì‹œ =====
                                        if not df_show.empty:
                                                display_cols = []
                                                for c in [suju_part_col, "í’ˆëª…", "ìˆ˜ì£¼ë²ˆí˜¸", suju_due_col, "ìˆ˜ëŸ‰", "ë§¤ì¶œì²˜"]:
                                                        if c in df_show.columns:
                                                                display_cols.append(c)

                                                st.dataframe(df_show[display_cols], use_container_width=True)
                                            
                                        # =======================================================
                                        # ğŸ” ìˆ˜ì£¼ë²ˆí˜¸ â†’ ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì§€ì‹œë²ˆí˜¸ / í’ˆëª… ê°€ì ¸ì˜¤ê¸°
                                        # =======================================================
                                        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_show.columns:
                                            # 1) ìˆ˜ì£¼ ì°¾ê¸° ê²°ê³¼ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸ ëª©ë¡ ì¶”ì¶œ
                                            suju_values = (
                                                df_show["ìˆ˜ì£¼ë²ˆí˜¸"]
                                                .dropna()
                                                .astype(str)
                                                .unique()
                                                .tolist()
                                            )

                                            # 2) ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì»¬ëŸ¼ ì°¾ê¸°
                                            job_suju_col = pick_col(df_job_raw, "A", ["ìˆ˜ì£¼ë²ˆí˜¸"])
                                            job_jisi_col = pick_col(df_job_raw, "B", ["ì§€ì‹œë²ˆí˜¸"])
                                            job_name_col = pick_col(df_job_raw, "L", ["í’ˆëª…", "ì™„ì„±í’ˆëª…"])

                                            if not all([job_suju_col, job_jisi_col, job_name_col]):
                                                st.info("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸(A), ì§€ì‹œë²ˆí˜¸(B), í’ˆëª…(L)ì„ ëª¨ë‘ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                            else:
                                                # 3) í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ê°€ì ¸ì˜¤ê¸°
                                                df_job_map = df_job_raw[
                                                    [job_suju_col, job_jisi_col, job_name_col]
                                                ].copy()
                                                df_job_map.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]

                                                # ë¬¸ìì—´ ë§¤ì¹­ì„ ìœ„í•´ ë³€í™˜
                                                df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"] = df_job_map["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str)

                                                # 4) ìˆ˜ì£¼ì°¾ê¸°ì—ì„œ ë‚˜ì˜¨ ìˆ˜ì£¼ë²ˆí˜¸ ëª©ë¡ê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ í•„í„°ë§
                                                df_job_filtered = df_job_map[
                                                    df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"].isin(suju_values)
                                                ].drop(columns=["ìˆ˜ì£¼ë²ˆí˜¸_str"])

                                                if df_job_filtered.empty:
                                                    st.info("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ í•´ë‹¹ ìˆ˜ì£¼ë²ˆí˜¸ì˜ ì§€ì‹œë²ˆí˜¸/í’ˆëª…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                                else:
                                                    # ì¤‘ë³µ ì œê±°
                                                    df_job_filtered = df_job_filtered.drop_duplicates(
                                                        subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]
                                                    )

                                                    st.markdown("#### ìˆ˜ì£¼ë²ˆí˜¸ë³„ ì§€ì‹œë²ˆí˜¸ / í’ˆëª… (ì‘ì—…ì§€ì‹œ ê¸°ì¤€)")
                                                    st.dataframe(
                                                        df_job_filtered[["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]],
                                                        use_container_width=True,
                                                    )


# ============================================================
# â†©ï¸ 4. í™˜ì… ê´€ë¦¬ í™”ë©´ (+ í™˜ì… ì˜ˆìƒì¬ê³ )
# ============================================================
if menu == "â†©ï¸ í™˜ì… ê´€ë¦¬":
    st.subheader("â†©ï¸ í™˜ì… ê´€ë¦¬")

    # í™˜ì… ê´€ë¦¬ í…Œì´ë¸” êµ¬ì¡° (ë‚´ë¶€ ê³„ì‚°ìš©)
    return_cols = [
        "ìˆ˜ì£¼ë²ˆí˜¸",
        "ì§€ì‹œë²ˆí˜¸",
        "ìƒì‚°ê³µì •",
        "ìƒì‚°ì‹œì‘ì¼",
        "ìƒì‚°ì¢…ë£Œì¼",
        "ì¢…ë£Œì¡°ê±´",
        "í™˜ì…ì¼",
        "í™˜ì…ì£¼ì°¨",
        "ì™„ì„±í’ˆë²ˆ",
        "ì œí’ˆëª…",  # ì™„ì„±í’ˆëª…
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ERPì¬ê³ ",
        "ì‹¤ì¬ê³ ì˜ˆìƒ",
        "í™˜ì…ê²°ì •ìˆ˜",
        "ì°¨ì´",
        "ë¹„ê³ ",
    ]
    df_return = ensure_session_df("í™˜ì…ê´€ë¦¬", return_cols)
    df_full = ensure_session_df("í™˜ì…ì¬ê³ ì˜ˆìƒ", CSV_COLS)
    # ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)
    st.markdown("### ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)")

    search_keyword = st.text_input(
        "ì œí’ˆëª…ìœ¼ë¡œ ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ Eì—´, ë¶€ë¶„ ì¼ì¹˜)",
        key="return_search_product",
        placeholder="ì˜ˆ: ì•°í”Œ, í¬ë¦¼, ë§ˆìŠ¤í¬íŒ© ë“±"
    )

    if search_keyword:
        df_in_search = df_in_raw.copy()

        # ìš”ì²­ë‚ ì§œ(Kì—´), ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ ì°¾ê¸°
        in_req_date_col = pick_col(df_in_search, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
        in_prod_name_col = pick_col(df_in_search, "E", ["ì œí’ˆëª…", "í’ˆëª…"])

        if in_req_date_col is None or in_prod_name_col is None:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ë˜ëŠ” ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ë‚ ì§œí˜• ë³€í™˜
            df_in_search[in_req_date_col] = pd.to_datetime(
                df_in_search[in_req_date_col], errors="coerce"
            ).dt.date

            today = date.today()
            start_date = today - timedelta(days=30)  # ìµœê·¼ 1ê°œì›”

            # ë‚ ì§œ í•„í„°: í˜„ì¬ë¡œë¶€í„° 1ë‹¬ ì´ë‚´
            mask_date = df_in_search[in_req_date_col].between(start_date, today)

            # ì œí’ˆëª… ë¶€ë¶„ ì¼ì¹˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            mask_name = df_in_search[in_prod_name_col].astype(str).str.contains(
                search_keyword, case=False, na=False
            )

            df_hit = df_in_search[mask_date & mask_name].copy()

            if df_hit.empty:
                st.info("ìµœê·¼ 1ê°œì›” ì´ë‚´ì— í•´ë‹¹ ì œí’ˆëª…ì´ í¬í•¨ëœ ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¶”ê°€ë¡œ ë³´ì—¬ì¤„ ì»¬ëŸ¼ë“¤: ìˆ˜ì£¼ë²ˆí˜¸(B), ì§€ì‹œë²ˆí˜¸(C), í’ˆë²ˆ(M)
                in_suju_col = pick_col(df_hit, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
                in_jisi_col = pick_col(df_hit, "C", ["ì§€ì‹œë²ˆí˜¸"])
                in_part_col = pick_col(df_hit, "M", ["í’ˆë²ˆ"])

                show_cols = []
                for c in [
                    in_req_date_col,
                    in_suju_col,
                    in_jisi_col,
                    in_prod_name_col,
                    in_part_col,
                ]:
                    if c and c in df_hit.columns:
                        show_cols.append(c)

                df_show = df_hit[show_cols].copy()

                # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ì •ë¦¬
                rename_map = {}
                rename_map[in_req_date_col] = "ìš”ì²­ë‚ ì§œ"
                if in_suju_col:      rename_map[in_suju_col] = "ìˆ˜ì£¼ë²ˆí˜¸"
                if in_jisi_col:      rename_map[in_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
                if in_prod_name_col: rename_map[in_prod_name_col] = "ì œí’ˆëª…"
                if in_part_col:      rename_map[in_part_col] = "í’ˆë²ˆ"

                df_show.rename(columns=rename_map, inplace=True)

                # í’ˆë²ˆ ì œê±°
                if "í’ˆë²ˆ" in df_show.columns:
                    df_show = df_show.drop(columns=["í’ˆë²ˆ"])

                # ìš”ì²­ë‚ ì§œëŠ” ì¤‘ë³µ ì œê±° ê¸°ì¤€ì—ì„œ ì œì™¸í•˜ê³ ,
                # ìˆ˜ì£¼ë²ˆí˜¸ + ì§€ì‹œë²ˆí˜¸ë§Œ ìœ ì¼í•˜ë„ë¡ ì •ë¦¬
                uniq_cols = [c for c in ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"] if c in df_show.columns]
                df_show = df_show.drop_duplicates(subset=uniq_cols)

                st.dataframe(df_show, use_container_width=True)

                # ğŸ”½ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•œ í–‰ì„ ì„ íƒí•˜ë©´ ì•„ë˜ ìˆ˜ì£¼ë²ˆí˜¸/ì§€ì‹œë²ˆí˜¸ ìë™ ì±„ìš°ê¸°
                if "ìˆ˜ì£¼ë²ˆí˜¸" in df_show.columns:
                    df_select = df_show.reset_index(drop=True)

                    option_labels = []
                    option_map = {}

                    for _, row in df_select.iterrows():
                        suju_val = str(row.get("ìˆ˜ì£¼ë²ˆí˜¸", ""))
                        jisi_val = str(row.get("ì§€ì‹œë²ˆí˜¸", ""))
                        prod_val = str(row.get("ì œí’ˆëª…", ""))

                        # í™”ë©´ì— ë³´ì—¬ì¤„ ë¼ë²¨
                        label = f"{prod_val} | ìˆ˜ì£¼:{suju_val}"
                        if jisi_val:
                            label += f" / ì§€ì‹œ:{jisi_val}"

                        option_labels.append(label)
                        option_map[label] = (suju_val, jisi_val)

                    selected_label = st.selectbox(
                        "ğŸ‘‡ ì´ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ ì•„ë˜ ìˆ˜ì£¼ë²ˆí˜¸/ì§€ì‹œë²ˆí˜¸ê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.",
                        ["ì„ íƒ ì•ˆ í•¨"] + option_labels,
                        key="return_suju_autofill",
                    )

                    if selected_label != "ì„ íƒ ì•ˆ í•¨":
                        sel_suju, sel_jisi = option_map[selected_label]
                        # ì•„ë˜ ì…ë ¥ì¹¸ì— ìë™ ë°˜ì˜
                        st.session_state["return_suju_no"] = sel_suju
                        if sel_jisi:
                            st.session_state["return_jisi"] = sel_jisi

    
    # ----- ì…ë ¥ 1ì¤„ (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, ìƒì‚°ê³µì •, ì¢…ë£Œì¡°ê±´) -----
    col_suju, col_jisi, col_proc, col_reason = st.columns(4)
    with col_suju:
        suju_no = st.text_input("ìˆ˜ì£¼ë²ˆí˜¸", key="return_suju_no")
    with col_jisi:
        selected_jisi = None  # ì˜µì…˜ ìƒì„± í›„ ì±„ì›€
    with col_proc:
        process_options = [
            "4ì¸µ ë•ìš©",
            "4ì¸µ ë¡œí„°ë¦¬",
            "4ì¸µ ë¸”ë¦¬ìŠ¤í„°",
            "5ì¸µ ë•ìš©",
            "5ì¸µ ê¸°ì´ˆ",
            "6ì¸µ ìŠ¤í‹±",
            "6ì¸µ íŒŒìš°ì¹˜",
            "6ì¸µ ìŠ¤í‚¨íŒ©",
        ]
        process_value = st.selectbox(
            "ìƒì‚°ê³µì •", process_options, key="return_process"
        )
    with col_reason:
        finish_reason = st.text_input("ì¢…ë£Œì¡°ê±´", key="return_finish_reason")

    # ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ë°˜ ì§€ì‹œë²ˆí˜¸/ì™„ì„±í’ˆë²ˆ í›„ë³´ ì°¾ê¸°
    jisi_options = []
    finished_part_selected = None

    if suju_no:
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_job_raw.columns:
            df_job_suju = df_job_raw[df_job_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()

            finished_parts = (
                df_job_suju["í’ˆë²ˆ"].dropna().unique().tolist()
                if "í’ˆë²ˆ" in df_job_suju.columns
                else []
            )
            if len(finished_parts) > 1:
                finished_part_selected = st.selectbox(
                    "ì™„ì„±í’ˆë²ˆ", finished_parts, key="return_finished_part"
                )
                df_job_suju = df_job_suju[
                    df_job_suju["í’ˆë²ˆ"] == finished_part_selected
                ]
            elif len(finished_parts) == 1:
                finished_part_selected = finished_parts[0]

            if "ì§€ì‹œë²ˆí˜¸" in df_job_suju.columns:
                jisi_options = df_job_suju["ì§€ì‹œë²ˆí˜¸"].dropna().unique().tolist()
            else:
                st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ì§€ì‹œë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ìˆ˜ì£¼ë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ì§€ì‹œë²ˆí˜¸ ì„ íƒ (ìˆ˜ì£¼ë²ˆí˜¸ ì…ë ¥ í›„)
    if jisi_options:
        selected_jisi = col_jisi.selectbox(
            "ì§€ì‹œë²ˆí˜¸", jisi_options, key="return_jisi"
        )
    else:
        with col_jisi:
            st.write("ì§€ì‹œë²ˆí˜¸: ì„ íƒ ì—†ìŒ")

    # ----- ìƒì‚° ì‹œì‘/ì¢…ë£Œì¼ -----
    production_start_date = None
    production_end_date = None
    if (
        suju_no
        and "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        and "ìƒì‚°ì¼ì" in df_result_raw.columns
    ):
        df_res_suju = df_result_raw[df_result_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()
        df_res_suju["ìƒì‚°ì¼ì"] = pd.to_datetime(
            df_res_suju["ìƒì‚°ì¼ì"], errors="coerce"
        )
        if not df_res_suju["ìƒì‚°ì¼ì"].isna().all():
            production_start_date = df_res_suju["ìƒì‚°ì¼ì"].min().date()
            production_end_date = df_res_suju["ìƒì‚°ì¼ì"].max().date()

    st.write(f"ìƒì‚°ì‹œì‘ì¼: {production_start_date or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ìƒì‚°ì¢…ë£Œì¼: {production_end_date or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- í™˜ì…ì¼/í™˜ì…ì£¼ì°¨ -----
    return_date = date.today()
    return_week = get_week_of_month(return_date)
    st.write(f"í™˜ì…ì¼: {return_date}")
    st.write(f"í™˜ì…ì£¼ì°¨: {return_week}")

    # ----- ì™„ì„±í’ˆë²ˆ / ì™„ì„±í’ˆëª… (BOMì—ì„œ í’ˆëª… ê°€ì ¸ì˜¤ê¸°) -----
    finished_part = finished_part_selected
    finished_name = None

    # 1ì°¨: ì§€ì‹œë²ˆí˜¸ì—ì„œ ì™„ì„±í’ˆë²ˆ ìœ ì¶” (ì—†ì„ ë•Œë§Œ)
    if not finished_part and selected_jisi and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns:
        df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
        if not df_job_jisi.empty and "í’ˆë²ˆ" in df_job_jisi.columns:
            finished_part = df_job_jisi["í’ˆë²ˆ"].iloc[0]

    # BOMì—ì„œ ì™„ì„±í’ˆëª… ì°¾ê¸° (í’ˆëª©ì½”ë“œ=Aì—´, í’ˆëª…=Bì—´)
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        name_col = (
            "í’ˆëª…"
            if "í’ˆëª…" in bom_cols
            else (bom_cols[1] if len(bom_cols) > 1 else bom_cols[0])
        )

        df_bom_match = df_bom_raw[df_bom_raw[item_col] == finished_part]
        if not df_bom_match.empty:
            finished_name = df_bom_match[name_col].iloc[0]
        else:
            if (
                selected_jisi
                and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
                and "í’ˆëª…" in df_job_raw.columns
            ):
                df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
                if not df_job_jisi.empty:
                    finished_name = df_job_jisi["í’ˆëª…"].iloc[0]

    st.write(f"ì™„ì„±í’ˆë²ˆ: {finished_part or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ì™„ì„±í’ˆëª…: {finished_name or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- BOM ìì¬ ëª©ë¡ -----
    bom_component_df = pd.DataFrame()
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        bom_part_cols = [c for c in bom_cols if "í’ˆë²ˆ" in c]
        bom_name_cols = [c for c in bom_cols if "í’ˆëª…" in c]

        bom_component_col2 = (
            bom_part_cols[1]
            if len(bom_part_cols) >= 2
            else (bom_part_cols[0] if bom_part_cols else None)
        )
        bom_name_col2 = (
            bom_name_cols[1]
            if len(bom_name_cols) >= 2
            else (bom_name_cols[0] if bom_name_cols else None)
        )

        df_bom_finished = df_bom_raw[df_bom_raw[item_col] == finished_part].copy()
        if df_bom_finished.empty:
            st.warning("BOMì—ì„œ í•´ë‹¹ ì™„ì„±í’ˆë²ˆ(í’ˆëª©ì½”ë“œ)ì„ ì‚¬ìš©í•˜ëŠ” ìì¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            subset_cols = []
            if bom_component_col2 and bom_component_col2 in df_bom_finished.columns:
                subset_cols.append(bom_component_col2)
            if bom_name_col2 and bom_name_col2 in df_bom_finished.columns:
                subset_cols.append(bom_name_col2)
            if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_finished.columns:
                subset_cols.append("ë‹¨ìœ„ìˆ˜ëŸ‰")

            if subset_cols:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates(subset=subset_cols)
            else:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates()

            bom_component_df = pd.DataFrame(
                {
                    "ì„ íƒ": True,
                    "ì™„ì„±í’ˆë²ˆ": df_bom_fin_uniq[item_col],
                    "í’ˆë²ˆ": df_bom_fin_uniq[bom_component_col2]
                    if bom_component_col2 in df_bom_fin_uniq.columns
                    else "",
                    "í’ˆëª…": df_bom_fin_uniq[bom_name_col2]
                    if bom_name_col2 in df_bom_fin_uniq.columns
                    else "",
                    "ë‹¨ìœ„ìˆ˜ëŸ‰": df_bom_fin_uniq["ë‹¨ìœ„ìˆ˜ëŸ‰"]
                    if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_fin_uniq.columns
                    else "",
                }
            )

            st.markdown("BOM ìì¬ ëª©ë¡ì—ì„œ í™˜ì… ëŒ€ìƒ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            bom_component_df = st.data_editor(
                bom_component_df,
                use_container_width=True,
                num_rows="dynamic",
                key="bom_component_editor",
            )

    # ----- í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼ -----
    if st.button(
        "âœ… í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°",
        key="btn_return_load",
    ):
        if not suju_no:
            st.error("ìˆ˜ì£¼ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not selected_jisi:
            st.error("ì§€ì‹œë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif bom_component_df.empty:
            st.error("BOM ìì¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_rows = bom_component_df[bom_component_df["ì„ íƒ"] == True].copy()
            if selected_rows.empty:
                st.warning("ì„ íƒëœ ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                new_rows = []
                for _, row in selected_rows.iterrows():
                    part = row["í’ˆë²ˆ"]
                    name = row["í’ˆëª…"]
                    unit = row["ë‹¨ìœ„ìˆ˜ëŸ‰"]

                    new_rows.append(
                        {
                            "ìˆ˜ì£¼ë²ˆí˜¸": suju_no,
                            "ì§€ì‹œë²ˆí˜¸": selected_jisi,
                            "ìƒì‚°ê³µì •": process_value,
                            "ìƒì‚°ì‹œì‘ì¼": production_start_date,
                            "ìƒì‚°ì¢…ë£Œì¼": production_end_date,
                            "ì¢…ë£Œì¡°ê±´": finish_reason,
                            "í™˜ì…ì¼": return_date,
                            "í™˜ì…ì£¼ì°¨": return_week,
                            "ì™„ì„±í’ˆë²ˆ": finished_part,
                            "ì œí’ˆëª…": finished_name,  # ì™„ì„±í’ˆëª…
                            "í’ˆë²ˆ": part,
                            "í’ˆëª…": name,
                            "ë‹¨ìœ„ìˆ˜ëŸ‰": unit,
                            "ERPì¬ê³ ": None,
                            "ì‹¤ì¬ê³ ì˜ˆìƒ": None,
                            "í™˜ì…ê²°ì •ìˆ˜": None,
                            "ì°¨ì´": None,
                            "ë¹„ê³ ": "",
                        }
                    )

                df_new = pd.DataFrame(new_rows)

                # ê¸°ì¡´ + ì‹ ê·œ í•©ì³ì„œ [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
                df_return = pd.concat([df_return, df_new], ignore_index=True)
                df_return = df_return.drop_duplicates(
                    subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
                ).reset_index(drop=True)
                st.session_state["í™˜ì…ê´€ë¦¬"] = df_return

                # ì§‘ê³„ê°€ ì•„ì§ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ê³„ì‚°
                if st.session_state["aggregates"] is None:
                    st.session_state["aggregates"] = build_aggregates(
                        df_in_raw,
                        df_job_raw,
                        df_result_raw,
                        df_defect_raw,
                        df_stock_raw,
                    )

                aggs = st.session_state["aggregates"]

                # ì§‘ê³„ ì‚¬ìš©í•´ì„œ í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚°
                df_full = recalc_return_expectation(df_return, aggs)
                st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

                # ===== ERPì¬ê³  ì§ì ‘ ë§¤ì¹­ íŒ¨ì¹˜ =====
                stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])
                stock_qty_col  = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

                if stock_part_col and stock_qty_col:
                    stock_map = dict(
                        zip(
                            df_stock_raw[stock_part_col].astype(str),
                            df_stock_raw[stock_qty_col].apply(safe_num)
                        )
                    )
                    df_full["ERPì¬ê³ "] = df_full["í’ˆë²ˆ"].astype(str).map(stock_map).fillna(0)
                else:
                    st.warning("ì¬ê³  ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(D) ë˜ëŠ” ì‹¤ì¬ê³ ìˆ˜ëŸ‰(N) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.success(
                    f"ì„ íƒëœ ìì¬ {len(df_new)}ê°œì— ëŒ€í•´ í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤."
                )

    # ----- í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™” -----
    if st.button("ğŸ§¹ í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™”", key="btn_clear_expect"):
        st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = pd.DataFrame(columns=CSV_COLS)
        df_full = st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"]
        st.success("í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ----- í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„° í‘œì‹œ + CSV + PDF + ì½”ë©˜íŠ¸ -----
    st.markdown("### í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°")

    df_full = st.session_state.get(
        "í™˜ì…ì¬ê³ ì˜ˆìƒ", pd.DataFrame(columns=CSV_COLS)
    )

    if df_full.empty:
        st.write("í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹¤í–‰í•˜ë©´ ì´ê³³ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        # í™”ë©´ìš©: ê³„ì‚°ëœ df_full ê·¸ëŒ€ë¡œ VISIBLE_COLS ê¸°ì¤€ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°
        df_visible = df_full[[c for c in VISIBLE_COLS if c in df_full.columns]].copy()
        st.dataframe(df_visible, use_container_width=True)

         label_source_cols = ["í’ˆë²ˆ", "í’ˆëª…", "ë‹¨ìœ„ìˆ˜ëŸ‰", "í™˜ì…ì¼"]
        if all(col in df_full.columns for col in label_source_cols):
            st.markdown("#### ğŸ· ë¼ë²¨ ì¶œë ¥ìš© ìì¬ ì„ íƒ")

            label_df = df_full[label_source_cols].copy()
            # í‘œì‹œìš©: ì„ íƒ ì»¬ëŸ¼ ë§¨ ì•ì— ì¶”ê°€
            label_df.insert(0, "ì„ íƒ", False)

            label_df = st.data_editor(
                label_df,
                use_container_width=True,
                num_rows="dynamic",
                key="label_editor",
            )

            if st.button("ğŸ· ì„ íƒí•œ ìì¬ ë¼ë²¨ PDF ë§Œë“¤ê¸°", key="btn_make_labels"):
                selected_labels = label_df[label_df["ì„ íƒ"] == True].copy()

                if selected_labels.empty:
                    st.warning("ë¼ë²¨ì„ ì¶œë ¥í•  í–‰ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
                else:
                    try:
                        pdf_labels = generate_label_pdf(selected_labels)
                        st.download_button(
                            "ğŸ“„ ë¶€ìì¬ë°˜ì… ë¼ë²¨ PDF ë‹¤ìš´ë¡œë“œ",
                            data=pdf_labels,
                            file_name="ë¶€ìì¬_ë°˜ì…ë¼ë²¨.pdf",
                            mime="application/pdf",
                        )
                    except Exception as e:
                        st.error(f"ë¼ë²¨ PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")       

        # ---------- í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©) ----------
        merge_choices = {}
        work = df_full.copy()

        if "í’ˆë²ˆ" in work.columns and "ìˆ˜ì£¼ë²ˆí˜¸" in work.columns:
            suju_counts = work.groupby("í’ˆë²ˆ")["ìˆ˜ì£¼ë²ˆí˜¸"].nunique()
            dup_parts = suju_counts[suju_counts > 1].index.tolist()

            if dup_parts:
                st.markdown("#### í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©)")
                for part in dup_parts:
                    sub = work[work["í’ˆë²ˆ"] == part]
                    combos = sub[["ìˆ˜ì£¼ë²ˆí˜¸", "ì™„ì„±í’ˆëª…"]].drop_duplicates()

                    options = [
                        f"{str(row['ìˆ˜ì£¼ë²ˆí˜¸'])} {str(row['ì™„ì„±í’ˆëª…'])}"
                        for _, row in combos.iterrows()
                    ]
                    if not options:
                        continue

                    key = f"merge_choice_{part}"
                    default = st.session_state.get(key, options[0])
                    try:
                        default_index = options.index(default)
                    except ValueError:
                        default_index = 0

                    choice = st.selectbox(
                        f"í’ˆë²ˆ {part} - ìˆ˜ì£¼/ì™„ì„±í’ˆëª… ì„ íƒ",
                        options,
                        index=default_index,
                        key=key,
                    )
                    merge_choices[part] = choice

        # ---------- 1ë‹¨ê³„: (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ) ë™ì¼í•œ í–‰ ë¨¼ì € í†µí•© ----------
        key_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"]
        key_cols = [c for c in key_cols if c in work.columns]

        if key_cols:
            agg_dict_step1 = {}
            for col in work.columns:
                if col in key_cols:
                    continue
                if col in ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]:
                    agg_dict_step1[col] = "sum"
                else:
                    agg_dict_step1[col] = "first"

            work = work.groupby(key_cols, as_index=False).agg(agg_dict_step1)

        # ---------- 2ë‹¨ê³„: í’ˆë²ˆ ë‹¨ìœ„ë¡œ ìµœì¢… í†µí•© ----------
        result_rows = []

        header_cols = [
            "ìˆ˜ì£¼ë²ˆí˜¸",
            "ì§€ì‹œë²ˆí˜¸",
            "ìƒì‚°ê³µì •",
            "ìƒì‚°ì‹œì‘ì¼",
            "ìƒì‚°ì¢…ë£Œì¼",
            "ì¢…ë£Œì¡°ê±´",
            "í™˜ì…ì¼",
            "í™˜ì…ì£¼ì°¨",
            "ì™„ì„±í’ˆë²ˆ",
            "ì™„ì„±í’ˆëª…",
            "í’ˆëª…",
        ]

        sum_cols = [
            "ERPë¶ˆì¶œìˆ˜ëŸ‰",
            "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
            "ì§€ì‹œìˆ˜ëŸ‰",
            "ìƒì‚°ìˆ˜ëŸ‰",
            "QCìƒ˜í”Œ",
            "ê¸°íƒ€ìƒ˜í”Œ",
            "ì›ë¶ˆ",
            "ì‘ë¶ˆ",
            "ì˜ˆìƒì¬ê³ ",
        ]

        unit_col = "ë‹¨ìœ„ìˆ˜ëŸ‰"

        if "í’ˆë²ˆ" in work.columns:
            for part, part_df in work.groupby("í’ˆë²ˆ"):
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëŒ€í‘œ ìˆ˜ì£¼ë²ˆí˜¸ ì ìš©
                if part in merge_choices:
                    sel_suju, _, _ = merge_choices[part].partition(" ")
                    base = part_df[part_df["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str) == sel_suju]
                    header_row = base.iloc[0] if not base.empty else part_df.iloc[0]
                else:
                    header_row = part_df.iloc[0]

                row = {}
                row["í’ˆë²ˆ"] = part

                # í—¤ë” ê³„ì—´: ëŒ€í‘œ ìˆ˜ì£¼/ì§€ì‹œì˜ ê°’ ìœ ì§€
                for col in header_cols:
                    row[col] = header_row.get(col, None)

                # ìˆ˜ëŸ‰ ê³„ì—´: ëª¨ë‘ í•©ê³„
                for col in sum_cols:
                    if col in part_df.columns:
                        row[col] = part_df[col].apply(safe_num).sum()
                    else:
                        row[col] = 0

                # ë‹¨ìœ„ìˆ˜ëŸ‰: í•©ì¹˜ì§€ ì•Šê³  ëŒ€í‘œê°’ only
                row[unit_col] = safe_num(header_row.get(unit_col, 0))

                # ERPì¬ê³ : ê°™ì€ í’ˆë²ˆì´ë©´ ë™ì¼ â†’ ëŒ€í‘œê°’ë§Œ
                if "ERPì¬ê³ " in part_df.columns:
                    non_na = part_df["ERPì¬ê³ "].dropna()
                    row["ERPì¬ê³ "] = (
                        safe_num(non_na.iloc[0]) if not non_na.empty else 0
                    )
                else:
                    row["ERPì¬ê³ "] = 0

                result_rows.append(row)

        grouped = pd.DataFrame(result_rows) if result_rows else work.copy()

        # CSV ì»¬ëŸ¼ ì •ë¦¬
        for col in CSV_COLS:
            if col not in grouped.columns:
                grouped[col] = None

        csv_export_df = grouped[CSV_COLS].copy()

        # CSV ë°›ê¸° ë²„íŠ¼
        csv_data = csv_export_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ CSV ë°›ê¸°",
            data=csv_data,
            file_name="í™˜ì…_ì˜ˆìƒì¬ê³ _í†µí•©.csv",
            mime="text/csv",
        )

        # PDF ë°›ê¸° ë²„íŠ¼ (ìµœì¢… CSVìš© ë°ì´í„° ê¸°ì¤€)
        if REPORTLAB_AVAILABLE and not csv_export_df.empty:

            st.markdown("### ğŸ“ PDF ìƒë‹¨ì— ë“¤ì–´ê°ˆ ë©”ëª¨ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¶™ì—¬ë„£ê¸°(Ctrl+V) í•˜ì„¸ìš”")

            pasted_text = st.text_area(
                "PDF ë©”ëª¨",
                height=100,
                key="pdf_note_text",
                placeholder="ì—¬ê¸°ì— ë©”ëª¨ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ì…ë ¥/ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”."
            )

            # í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ì„œ PDF ìƒì„± (ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ì•ˆ í•¨)
            pdf_bytes = generate_pdf(csv_export_df, pasted_text=pasted_text)

            st.download_button(
                "ğŸ“„ PDF ë°›ê¸°",
                data=pdf_bytes,
                file_name="í™˜ì…_ì˜ˆìƒì¬ê³ .pdf",
                mime="application/pdf",
            )

        elif not REPORTLAB_AVAILABLE:
            st.info("PDF ì €ì¥ ê¸°ëŠ¥ì„ ì“°ë ¤ë©´ `pip install reportlab` ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ---------- ì…ê³  ì‹œíŠ¸ ë¹„ê³ (êµ¬ ë¹„ê³ 2) ì½”ë©˜íŠ¸ ----------
        in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
        in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
        in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
        # ì´ë¦„ì„ "ë¹„ê³ "ë¡œ ë°”ê¿¨ìœ¼ë¯€ë¡œ ìš°ì„  "ë¹„ê³ "ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ Vì—´/ë¹„ê³ 2ë„ í—ˆìš©
        in_cmt_col = pick_col(df_in_raw, "V", ["ë¹„ê³ ", "ë¹„ê³ 2"])

        if in_suju_col and in_jisi_col and in_part_col and in_cmt_col:
            df_in_comment = df_in_raw[
                [in_suju_col, in_jisi_col, in_part_col, in_cmt_col]
            ].copy()
            df_in_comment.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¹„ê³ 2"]
            df_in_comment = df_in_comment.dropna(subset=["ë¹„ê³ 2"])

            if not df_in_comment.empty:
                df_comment_merge = df_full.merge(
                    df_in_comment,
                    how="left",
                    on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
                )

                df_comment_show = df_comment_merge.dropna(subset=["ë¹„ê³ 2"])[
                    ["í’ˆë²ˆ", "í’ˆëª…", "ë¹„ê³ 2"]
                ].drop_duplicates()

                if not df_comment_show.empty:
                    st.markdown("#### ì…ê³  ë¹„ê³  ì½”ë©˜íŠ¸")
                    for _, row in df_comment_show.iterrows():
                        st.markdown(
                            f"- **{row['í’ˆë²ˆ']} / {row['í’ˆëª…']}** : {row['ë¹„ê³ 2']}"
                        )

# ============================================================
# ğŸ§© 5. ê³µí†µìì¬ íƒ­
# ============================================================
if menu == "ğŸ§© ê³µí†µìì¬":
    st.subheader("ğŸ§© ê³µí†µìì¬ í™•ì¸")

    search_part = st.text_input(
        "ì°¾ì„ ìì¬ í’ˆë²ˆì„ ì…ë ¥í•˜ì„¸ìš”",
        key="common_part_search",
        placeholder="ì˜ˆ: ìì¬ í’ˆë²ˆ ì…ë ¥"
    )

    if search_part:
        df_bom = df_bom_raw.copy()

        bom_item_col = pick_col(df_bom, "A", ["í’ˆëª©ì½”ë“œ"])
        bom_name_col = pick_col(df_bom, "B", ["í’ˆëª…"])
        bom_part_col = pick_col(df_bom, "C", ["í’ˆë²ˆ"])

        if not all([bom_item_col, bom_name_col, bom_part_col]):
            st.error("BOM ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(A), í’ˆëª…(B), í’ˆë²ˆ(C) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_bom_hit = df_bom[df_bom[bom_part_col] == search_part].copy()

            if df_bom_hit.empty:
                st.info("í•´ë‹¹ ìì¬ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” í’ˆëª©ì½”ë“œë¥¼ BOMì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                df_bom_hit = df_bom_hit[[bom_item_col, bom_name_col]].drop_duplicates()
                df_bom_hit.columns = ["ì™„ì„±í’ˆë²ˆ", "í’ˆëª…"]

                df_in = df_in_raw.copy()
                in_fin_col = pick_col(df_in, "D", ["ì™„ì„±í’ˆë²ˆ", "í’ˆëª©ì½”ë“œ", "í’ˆë²ˆ"])
                in_req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])

                if in_fin_col is None or in_req_date_col is None:
                    st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ì™„ì„±í’ˆë²ˆ(Dì—´) ë˜ëŠ” ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    df_in[in_req_date_col] = pd.to_datetime(
                        df_in[in_req_date_col], errors="coerce"
                    ).dt.date

                    today = date.today()
                    result_rows = []

                    for _, r in df_bom_hit.iterrows():
                        item_code = r["ì™„ì„±í’ˆë²ˆ"]
                        name = r["í’ˆëª…"]

                        sub = df_in[df_in[in_fin_col] == item_code].copy()
                        sub = sub.dropna(subset=[in_req_date_col])

                        if sub.empty:
                            last_date = None
                            days_diff = None
                            mark_1w = ""
                            mark_2w = ""
                        else:
                            # ê°€ì¥ ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰ ê¸°ì¤€ ìš”ì²­ë‚ ì§œ
                            sub = sub.sort_values(in_req_date_col)
                            last_date = sub[in_req_date_col].iloc[-1]
                            days_diff = (today - last_date).days

                            if days_diff <= 7:
                                mark_1w = "V"
                                mark_2w = ""
                            elif days_diff <= 14:
                                mark_1w = ""
                                mark_2w = "V"
                            else:
                                mark_1w = ""
                                mark_2w = ""

                        result_rows.append(
                            {
                                "ì™„ì„±í’ˆë²ˆ": item_code,
                                "í’ˆëª…": name,
                                "ë¶ˆì¶œìš”ì²­ì¼": last_date,
                                "1ì£¼ ì´ë‚´": mark_1w,
                                "2ì£¼ ì´ë‚´": mark_2w,
                            }
                        )

                    df_result = pd.DataFrame(result_rows)

                    if df_result.empty:
                        st.info("ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ìµœì‹  ë¶ˆì¶œìš”ì²­ì¼ì´ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬ (ì„ íƒì‚¬í•­)
                        df_result = df_result.sort_values(
                            by="ë¶ˆì¶œìš”ì²­ì¼", ascending=False, na_position="last"
                        ).reset_index(drop=True)

                        df_result_styled = df_result.style.set_properties(
                            subset=["1ì£¼ ì´ë‚´", "2ì£¼ ì´ë‚´"],
                            **{"text-align": "center"}
                        )

                        st.dataframe(df_result, use_container_width=True)
