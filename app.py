
import streamlit as st
import pandas as pd
from datetime import date, timedelta
import tempfile
import io
import os
from html import escape
import sqlite3
from pathlib import Path

# ============ S3 ì—°ë™ ============

import boto3
from botocore.exceptions import ClientError

S3_BUCKET = "rec-and-ship"
S3_KEY_EXCEL = "bulk-ledger.xlsx"   # ê¸°ì¡´ ì—‘ì…€
S3_KEY_DB    = "inout.db"           # ë¶€ìì¬ ë©”ì¸ DB
S3_KEY_LABEL = "label_db.csv"       # ğŸ”¸ ë¼ë²¨ ì „ìš© DB (CSV)

def get_s3_client():
    try:
        return boto3.client(
            "s3",
            aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
            aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
            region_name="ap-northeast-2",
        )
    except Exception as e:
        st.error(f"S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

s3_client = get_s3_client()


@st.cache_data(show_spinner=True)
def load_file_from_s3():
    """S3ì— ì—‘ì…€ íŒŒì¼ì´ ìˆìœ¼ë©´ bytesë¡œ ì½ì–´ì˜¨ë‹¤."""
    if s3_client is None:
        return None
    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY_EXCEL)  # ğŸ”´ ì—¬ê¸° S3_KEY â†’ S3_KEY_EXCEL ë¡œ ìˆ˜ì •
        return obj["Body"].read()
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            return None
        st.error(f"S3ì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

@st.cache_data(show_spinner=True)
def load_label_db_from_s3() -> pd.DataFrame:
    """
    S3ì—ì„œ ë¼ë²¨ DB CSVë¥¼ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜.
    ì—†ìœ¼ë©´ ë¹ˆ DF ë°˜í™˜.
    """
    if s3_client is None:
        return pd.DataFrame()

    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY_LABEL)
        data = obj["Body"].read().decode("utf-8-sig")
        df = pd.read_csv(io.StringIO(data))
        return df
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            # ì•„ì§ ë¼ë²¨ DBë¥¼ ë§Œë“  ì ì´ ì—†ìŒ
            return pd.DataFrame()
        st.error(f"S3ì—ì„œ ë¼ë²¨ DBë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()


def save_label_db_to_s3(df: pd.DataFrame):
    """
    í˜„ì¬ ë¼ë²¨ DB DataFrameì„ S3ì— CSVë¡œ ì €ì¥.
    """
    if s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¼ë²¨ DBë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    csv_buf = io.StringIO()
    df.to_csv(csv_buf, index=False)
    s3_client.put_object(
        Bucket=S3_BUCKET,
        Key=S3_KEY_LABEL,
        Body=csv_buf.getvalue().encode("utf-8-sig"),
    )
    # ìºì‹œëœ ë¼ë²¨ DB ë¬´íš¨í™”
    load_label_db_from_s3.clear()


# ğŸ”¹ğŸ”¹ğŸ”¹ ì—¬ê¸° ì•„ë˜ì— ìƒˆ í•¨ìˆ˜ 2ê°œ ì¶”ê°€ ğŸ”¹ğŸ”¹ğŸ”¹

@st.cache_data(show_spinner=True)
def load_db_from_s3() -> bytes | None:
    """S3ì—ì„œ inout.db íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ë°˜í™˜"""
    if s3_client is None:
        return None
    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY_DB)
        return obj["Body"].read()
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            return None
        st.error(f"S3 DB ë¡œë”© ì˜¤ë¥˜: {e}")
        return None


# ì—‘ì…€ DB ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€
@st.cache_resource(show_spinner=True)
def get_db_connection(db_bytes: bytes):
    """
    S3ì—ì„œ ë°›ì€ DB bytesë¥¼ ì„ì‹œíŒŒì¼ë¡œ ì €ì¥ í›„ SQLite ì—°ê²°í•˜ê¸°.
    Streamlit ì„¸ì…˜ ë™ì•ˆ ì¬ì‚¬ìš©ëœë‹¤.
    """
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".db")
    tmp.write(db_bytes)
    tmp.flush()
    conn = sqlite3.connect(tmp.name, check_same_thread=False)
    return conn

REQUIRED_SHEETS = ["ì…ê³ ", "ì‘ì—…ì§€ì‹œ", "ìˆ˜ì£¼", "BOM", "ì¬ê³ ", "ìƒì‚°ì‹¤ì ", "ë¶ˆëŸ‰"]

def excel_bytes_to_sqlite_bytes(excel_bytes: bytes) -> bytes:
    """
    ì—…ë¡œë“œëœ ì—‘ì…€ ë°”ì´íŠ¸ â†’ SQLite DB(inout.db) íŒŒì¼ bytesë¡œ ë³€í™˜.
    - ê¼­ í•„ìš”í•œ ì‹œíŠ¸ë§Œ ì½ìŒ
    - dtype=str ë¡œ ì½ì–´ì„œ íƒ€ì… ì¶”ë¡  ë¹„ìš© ìµœì†Œí™”
    """

    # 1) ì—‘ì…€ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ì½ê¸°
    bio = io.BytesIO(excel_bytes)

    # 2) í•œ ë²ˆì— ì—¬ëŸ¬ ì‹œíŠ¸ë¥¼ ì½ì–´ì„œ íŒŒì‹± ì˜¤ë²„í—¤ë“œ ì¤„ì´ê¸°
    #    sheet_name=list ë¥¼ ì£¼ë©´ dict[sheet_name] í˜•íƒœë¡œ ë°˜í™˜ë¨
    try:
        all_sheets = pd.read_excel(
            bio,
            sheet_name=REQUIRED_SHEETS,
            dtype=str,           # ìˆ«ì/ë‚ ì§œ ì¶”ë¡  ì•ˆ í•˜ê³  ë¬¸ìì—´ë¡œë§Œ ì½ê¸° (ë¹ ë¦„)
            engine="openpyxl",   # ì¼ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ì—”ì§„
        )
    except Exception as e:
        # í˜¹ì‹œ engine ì§€ì •ìœ¼ë¡œ ë¬¸ì œê°€ ìƒê¸°ë©´ ê¸°ë³¸ ì—”ì§„ìœ¼ë¡œ í•œë²ˆ ë” ì‹œë„
        bio.seek(0)
        all_sheets = pd.read_excel(
            bio,
            sheet_name=REQUIRED_SHEETS,
            dtype=str,
        )

    # 3) ì„ì‹œ DB íŒŒì¼ ìƒì„±
    tmp_db = tempfile.NamedTemporaryFile(delete=False, suffix=".db")
    conn = sqlite3.connect(tmp_db.name)

    try:
        # 4) í•„ìš”í•œ ì‹œíŠ¸ë§Œ í…Œì´ë¸”ë¡œ ì €ì¥
        for sheet in REQUIRED_SHEETS:
            if sheet not in all_sheets:
                continue
            df = all_sheets[sheet]

            # ì»¬ëŸ¼ ì´ë¦„ì— ê³µë°± ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ì–´ë„ ë˜ì§€ë§Œ,
            # ë‚˜ì¤‘ì— ì¿¼ë¦¬í•  ë•Œ ë¶ˆí¸í•˜ë©´ ì—¬ê¸°ì„œ strip ì •ë„ëŠ” í•´ë„ ë¨
            df.columns = [str(c).strip() for c in df.columns]

            df.to_sql(sheet, conn, if_exists="replace", index=False)

        conn.commit()
    finally:
        conn.close()

    # 5) ì™„ì„±ëœ DB íŒŒì¼ì„ bytesë¡œ ì½ì–´ ë°˜í™˜
    with open(tmp_db.name, "rb") as f:
        db_bytes = f.read()

    return db_bytes



# PDF ìƒì„±ìš© (reportlab ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ì²˜ë¦¬)
try:
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.platypus import (
        SimpleDocTemplate,
        Table,
        TableStyle,
        Paragraph,
        Spacer,
    )
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    KOREAN_FONT_NAME = "MalgunGothic"

    # ğŸ”¹ app.py ê¸°ì¤€ìœ¼ë¡œ font/malgun.ttf ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê¸°
    FONT_PATH = os.path.join(os.path.dirname(__file__), "font", "malgun.ttf")

    if not os.path.exists(FONT_PATH):
        st.write("âš ï¸ í°íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤:", FONT_PATH)
        KOREAN_FONT_NAME = "Helvetica"
    else:
        try:
            pdfmetrics.registerFont(TTFont(KOREAN_FONT_NAME, FONT_PATH))
        except Exception as e:
            st.write("âš ï¸ í°íŠ¸ ë¡œë”© ì‹¤íŒ¨:", repr(e))
            KOREAN_FONT_NAME = "Helvetica"

    REPORTLAB_AVAILABLE = True
except ModuleNotFoundError:
    REPORTLAB_AVAILABLE = False
    KOREAN_FONT_NAME = "Helvetica"


st.set_page_config(page_title="ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_data
def load_excel(file_bytes: bytes):
    """bytes ë˜ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ë°›ì•„ ì „ì²´ ì‹œíŠ¸ë¥¼ dictë¡œ ë°˜í™˜"""
    xls = pd.ExcelFile(file_bytes)
    sheets = {}
    for sheet_name in xls.sheet_names:
        try:
            sheets[sheet_name] = pd.read_excel(xls, sheet_name)
        except Exception:
            pass
    return sheets


def get_week_of_month(d: date) -> str:
    """ê°„ë‹¨íˆ: 1~7ì¼=1ì£¼ì°¨, 8~14=2ì£¼ì°¨, ..."""
    week_no = (d.day - 1) // 7 + 1
    return f"{d.month}ì›”{week_no}ì£¼ì°¨"


def ensure_session_df(key: str, columns: list):
    if key not in st.session_state:
        st.session_state[key] = pd.DataFrame(columns=columns)
    return st.session_state[key]


def excel_col_to_index(col_letter: str) -> int:
    """ì—‘ì…€ ì—´ ë¬¸ì(A, B, ... AA, AB...)ë¥¼ 0-base indexë¡œ ë³€í™˜"""
    col_letter = col_letter.upper()
    result = 0
    for ch in col_letter:
        if not ("A" <= ch <= "Z"):
            continue
        result = result * 26 + (ord(ch) - ord("A") + 1)
    return result - 1  # 0-base


def pick_col(df: pd.DataFrame, letter: str, preferred_names: list):
    """
    ìš°ì„  ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ì—‘ì…€ ì—´ ìœ„ì¹˜(letter)ë¡œ ì°¾ê¸°
    (preferred_names ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©)
    """
    cols = list(df.columns)
    for name in preferred_names:
        if name in df.columns:
            return name
    idx = excel_col_to_index(letter)
    if 0 <= idx < len(cols):
        return cols[idx]
    return None


def safe_num(x):
    """ìˆ«ìê°€ ì•„ë‹ˆë©´ ìµœëŒ€í•œ floatìœ¼ë¡œ ë³€í™˜, ì•ˆ ë˜ë©´ 0"""
    try:
        if pd.isna(x):
            return 0
    except Exception:
        pass
    if isinstance(x, (int, float)):
        return float(x)
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return 0.0

import re

LABEL_TYPES = [
    "ë´‰í•©ë¼ë²¨",
    "ë¦¬ì‹¤ëŸ¬ë¸”ë¼ë²¨",
    "ìš©ê¸°ë¼ë²¨",
    "ìƒë‹¨ë¼ë²¨",
    "ìš©ê¸°ì „ë©´ë¼ë²¨",
    "ìš©ê¸°í›„ë©´ë¼ë²¨",
    "ìš©ê¸°ìƒë‹¨ë¼ë²¨",
    "ìš©ê¸°ìš°ì¸¡ë¼ë²¨",
    "ìš©ê¸°ì¢Œì¸¡ë¼ë²¨",
    "ì— ë¸”ëŸ¼",
    "ì‹¤ë§ì§€",
    "ë§ë°©ë¼ë²¨",
]

def parse_label_db(file_obj) -> pd.DataFrame:
    """
    ê¸°ì¡´ 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤ ì§€ê´€ë¬´ê²Œ+ìˆ˜ëŸ‰ ê³„ì‚°ê¸°_*.xlsx' íŒŒì¼ì—ì„œ
    ë¼ë²¨ DBë¥¼ ë½‘ì•„ì„œ í†µì¼ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì •ë¦¬í•œë‹¤.

    - ì‚¬ìš© ì‹œíŠ¸: 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤'
    - í—¤ë” í–‰: 5ë²ˆì§¸ ì¤„(0-base index=4)
    - ì£¼ìš” ì»¬ëŸ¼ ë§¤í•‘:
        No.        â†’ ìƒ˜í”Œë²ˆí˜¸
        í’ˆë²ˆ       â†’ í’ˆë²ˆ
        í’ˆëª…       â†’ í’ˆëª…
        êµ¬ë¶„       â†’ êµ¬ë¶„
        ì‹¤ë¬´ê²Œ     â†’ ì§€ê´€ë¬´ê²Œ
        ì¶”ì •ê°’     â†’ ì¶”ì •ê°’
        ì˜¤ì°¨       â†’ ì˜¤ì°¨
        ì™¸ê²½       â†’ ì™¸ê²½
        ë‚´ê²½       â†’ ë‚´ê²½
        ë†’ì´       â†’ ë†’ì´
        1Rë¬´ê²Œ     â†’ 1Rë¬´ê²Œ
        ê¸°ì¤€ ìƒ˜í”Œ  â†’ ê¸°ì¤€ìƒ˜í”Œ
        ìƒ˜í”Œë¬´ê²Œ   â†’ ìƒ˜í”Œë¬´ê²Œ
    """
    try:
        xls = pd.ExcelFile(file_obj)
    except Exception as e:
        st.error(f"ë¼ë²¨ ì—‘ì…€ íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    # ì‹œíŠ¸ ì´ë¦„ ì°¾ê¸° (ì •í™•íˆ 'ë¼ë²¨ ë° ìŠ¤í‹°ì»¤'ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ìµœìš°ì„ )
    sheet_name = None
    for s in xls.sheet_names:
        if "ë¼ë²¨" in s and "ìŠ¤í‹°ì»¤" in s:
            sheet_name = s
            break
    if sheet_name is None:
        # ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸
        sheet_name = xls.sheet_names[0]

    # header=4 â†’ 5ë²ˆì§¸ ì¤„ì„ í—¤ë”ë¡œ ì‚¬ìš© (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ì¤€)
    try:
        df_raw = pd.read_excel(xls, sheet_name=sheet_name, header=4)
    except Exception as e:
        st.error(f"ë¼ë²¨ ì‹œíŠ¸ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
    rename_map = {}
    cols = list(df_raw.columns)

    for c in cols:
        cname = str(c).strip()
        if cname == "No.":
            rename_map[c] = "ìƒ˜í”Œë²ˆí˜¸"
        elif cname == "í’ˆë²ˆ":
            rename_map[c] = "í’ˆë²ˆ"
        elif cname == "í’ˆëª…":
            rename_map[c] = "í’ˆëª…"
        elif cname == "êµ¬ë¶„":
            rename_map[c] = "êµ¬ë¶„"
        elif cname == "ì‹¤ë¬´ê²Œ":
            rename_map[c] = "ì§€ê´€ë¬´ê²Œ"
        elif cname == "ì¶”ì •ê°’":
            rename_map[c] = "ì¶”ì •ê°’"
        elif cname == "ì˜¤ì°¨":
            rename_map[c] = "ì˜¤ì°¨"
        elif cname == "ì™¸ê²½":
            rename_map[c] = "ì™¸ê²½"
        elif cname == "ë‚´ê²½":
            rename_map[c] = "ë‚´ê²½"
        elif cname == "ë†’ì´":
            rename_map[c] = "ë†’ì´"
        elif cname == "1Rë¬´ê²Œ":
            rename_map[c] = "1Rë¬´ê²Œ"
        elif cname.replace(" ", "") in ("ê¸°ì¤€ìƒ˜í”Œ", "ê¸°ì¤€ìƒ˜í”Œ"):
            rename_map[c] = "ê¸°ì¤€ìƒ˜í”Œ"
        elif cname.replace(" ", "") in ("ìƒ˜í”Œë¬´ê²Œ", "ìƒ˜í”Œë¬´ê²Œ"):
            rename_map[c] = "ìƒ˜í”Œë¬´ê²Œ"

    df = df_raw.rename(columns=rename_map)

    # ìš°ë¦¬ê°€ ì“¸ ì»¬ëŸ¼ë§Œ ê³¨ë¼ì„œ ìƒˆ DF êµ¬ì„±
    base_cols = [
        "ìƒ˜í”Œë²ˆí˜¸",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "êµ¬ë¶„",
        "ì§€ê´€ë¬´ê²Œ",
        "ì¶”ì •ê°’",
        "ì˜¤ì°¨",
        "ì™¸ê²½",
        "ë‚´ê²½",
        "ë†’ì´",
        "1Rë¬´ê²Œ",
        "ê¸°ì¤€ìƒ˜í”Œ",
        "ìƒ˜í”Œë¬´ê²Œ",
    ]
    existing = [c for c in base_cols if c in df.columns]
    df_out = df[existing].copy()

    # êµ¬ë¶„ì´ ì •í•´ì§„ 12ê°œ ì¤‘ í•˜ë‚˜ì¸ í–‰ë§Œ ì‚¬ìš© (ì“°ë ˆê¸° í–‰ ì œê±° ìš©ë„)
    if "êµ¬ë¶„" in df_out.columns:
        df_out = df_out[df_out["êµ¬ë¶„"].isin(LABEL_TYPES)]

    # í’ˆë²ˆ/í’ˆëª… ë‘˜ ë‹¤ ì—†ëŠ” í–‰ì€ ë²„ë¦¬ê¸°
    if "í’ˆë²ˆ" in df_out.columns and "í’ˆëª…" in df_out.columns:
        df_out = df_out.dropna(subset=["í’ˆë²ˆ", "í’ˆëª…"], how="all")

    # ìˆ«ì ì»¬ëŸ¼ float ë³€í™˜
    num_cols = ["ì§€ê´€ë¬´ê²Œ", "ì¶”ì •ê°’", "ì˜¤ì°¨", "ì™¸ê²½", "ë‚´ê²½", "ë†’ì´", "1Rë¬´ê²Œ", "ìƒ˜í”Œë¬´ê²Œ"]
    for c in num_cols:
        if c in df_out.columns:
            df_out[c] = df_out[c].apply(safe_num)

    # ì¸ë±ìŠ¤ ë¦¬ì…‹
    df_out = df_out.reset_index(drop=True)

    return df_out


def parse_label_sample_count(text: str) -> float:
    """
    ê¸°ì¤€ìƒ˜í”Œ ë¬¸ìì—´ì—ì„œ 'ëª‡ ë§¤'ì¸ì§€ ìˆ«ìë§Œ ë½‘ì•„ì„œ floatìœ¼ë¡œ ë°˜í™˜.
    ì˜ˆ) '4ë§¤' â†’ 4, '2ë§¤(ì•„ì´ë§ˆí¬)' â†’ 2, '1ë§¤' â†’ 1
    ìˆ«ìê°€ ì—†ìœ¼ë©´ 1ë¡œ ì²˜ë¦¬.
    """
    if pd.isna(text):
        return 1.0
    s = str(text)
    m = re.search(r"(\d+)", s)
    if not m:
        return 1.0
    try:
        return float(m.group(1))
    except Exception:
        return 1.0


# í™”ë©´ì— ë³´ì´ëŠ” í™˜ì… ì˜ˆìƒì¬ê³  í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œ
VISIBLE_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì™„ì„±í’ˆë²ˆ",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# CSVì— ë“¤ì–´ê°ˆ ì „ì²´ ì»¬ëŸ¼ (ìš”ì²­í•œ ìˆœì„œ ê·¸ëŒ€ë¡œ)
CSV_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì§€ì‹œë²ˆí˜¸",
    "ìƒì‚°ê³µì •",
    "ìƒì‚°ì‹œì‘ì¼",
    "ìƒì‚°ì¢…ë£Œì¼",
    "ì¢…ë£Œì¡°ê±´",
    "í™˜ì…ì¼",
    "í™˜ì…ì£¼ì°¨",
    "ì™„ì„±í’ˆë²ˆ",
    "ì™„ì„±í’ˆëª…",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# --------
# ê¸°ê°„ ê¸°ì¤€ ì…ê³  ìˆ˜ëŸ‰ í•©ê³„
# --------

def get_real_in_by_period(part_code, start_date, end_date):
    """
    í’ˆë²ˆ(part_code)ê³¼ ì…ê³  ê¸°ê°„(start_date ~ end_date)ì„ ê¸°ì¤€ìœ¼ë¡œ
    ì…ê³  ì‹œíŠ¸(df_in_raw)ì—ì„œ 'í˜„ì¥ì‹¤ë¬¼ì…ê³ ' í•©ê³„ë¥¼ êµ¬í•œë‹¤.
    """
    df = df_in_raw.copy()

    # ë‚ ì§œ / í’ˆë²ˆ / ì‹¤ë¬¼ì…ê³  ì»¬ëŸ¼ ì°¾ê¸°
    date_col = pick_col(df, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    part_col = pick_col(df, "M", ["í’ˆë²ˆ"])
    real_col = pick_col(df, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if not all([date_col, part_col, real_col]):
        return 0.0  # í•„ìˆ˜ ì»¬ëŸ¼ ì—†ìœ¼ë©´ 0 ë¦¬í„´

    # ë‚ ì§œí˜• ë³€í™˜
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce").dt.date

    # ê¸°ê°„ + í’ˆë²ˆìœ¼ë¡œ í•„í„°
    mask = (
        (df[part_col].astype(str) == str(part_code))
        & (df[date_col] >= start_date)
        & (df[date_col] <= end_date)
    )

    sub = df.loc[mask, real_col]

    if sub.empty:
        return 0.0

    return sub.apply(safe_num).sum()

# -----
# ì¶”ê°€ìˆ˜ì£¼ë²ˆí˜¸ ì°¾ê¸°
# ------

def get_extra_orders_by_period(part_code, base_suju, start_date, end_date):
    """
    ì…ê³  ì‹œíŠ¸(df_in_raw)ì—ì„œ
    - í’ˆë²ˆ(part_code)
    - ìš”ì²­ë‚ ì§œ: start_date ~ end_date
    ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ìˆ˜ì£¼ë²ˆí˜¸ë“¤ì„ ì°¾ì•„ì„œ,
    ê¸°ë³¸ ìˆ˜ì£¼ë²ˆí˜¸(base_suju)ëŠ” ì œì™¸í•˜ê³ 
    ì¤‘ë³µ ì—†ì´ ì‰¼í‘œë¡œ ì´ì–´ë¶™ì¸ ë¬¸ìì—´ì„ ë°˜í™˜í•œë‹¤.
    """
    df = df_in_raw.copy()

    date_col = pick_col(df, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    part_col = pick_col(df, "M", ["í’ˆë²ˆ"])
    suju_col = pick_col(df, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])

    if not all([date_col, part_col, suju_col]):
        return ""

    # ë‚ ì§œí˜• ë³€í™˜
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce").dt.date

    # í•„í„°: í’ˆë²ˆ + ê¸°ê°„
    mask = (
        (df[part_col].astype(str) == str(part_code))
        & (df[date_col] >= start_date)
        & (df[date_col] <= end_date)
    )

    sub = df.loc[mask, suju_col]

    if sub.empty:
        return ""

    # ìˆ˜ì£¼ë²ˆí˜¸ë“¤ ì •ë¦¬
    suju_list = (
        sub.dropna()
        .astype(str)
        .unique()
        .tolist()
    )

    # ê¸°ë³¸ ìˆ˜ì£¼ë²ˆí˜¸ ì œì™¸
    suju_list = [s for s in suju_list if s != str(base_suju)]

    if not suju_list:
        return ""

    # ì‰¼í‘œë¡œ ì´ì–´ë¶™ì—¬ì„œ ë°˜í™˜
    return ", ".join(suju_list)


# -----------------------------
# ì§‘ê³„ í…Œì´ë¸” ë¹Œë“œ
# -----------------------------
def build_aggregates(df_in_raw, df_job_raw, df_result_raw, df_defect_raw, df_stock_raw):
    """
    í° ì›ë³¸ ì‹œíŠ¸ë“¤ì„ ë¯¸ë¦¬ groupby í•´ì„œ, ë‚˜ì¤‘ì—” mergeë§Œ í•˜ë„ë¡ ë§Œë“œëŠ” ì§‘ê³„ í…Œì´ë¸”ë“¤
    """
    aggregates = {}

    # === 1) ì…ê³  ì§‘ê³„: [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ë³„ ERPë¶ˆì¶œìˆ˜ëŸ‰/í˜„ì¥ì‹¤ë¬¼ì…ê³  í•©ê³„ ===
    # ìˆ˜ì£¼ë²ˆí˜¸: Bì—´, ì§€ì‹œë²ˆí˜¸: Cì—´, í’ˆë²ˆ: Mì—´, ERPë¶ˆì¶œìˆ˜ëŸ‰: Qì—´, í˜„ì¥ì‹¤ë¬¼ì…ê³ : Rì—´
    in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
    in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
    in_erp_col = pick_col(df_in_raw, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰"])
    in_real_col = pick_col(df_in_raw, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if all([in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]):
        df_in = df_in_raw[
            [in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]
        ].copy()
        df_in.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        agg_in = (
            df_in.groupby(["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)
            .agg({"ERPë¶ˆì¶œìˆ˜ëŸ‰": "sum", "í˜„ì¥ì‹¤ë¬¼ì…ê³ ": "sum"})
        )
        aggregates["in"] = agg_in
    else:
        aggregates["in"] = pd.DataFrame(
            columns=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        )

    # === 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„: ì§€ì‹œë²ˆí˜¸ë³„ ì§€ì‹œìˆ˜ëŸ‰ ===
    job_jisi_col = (
        "ì§€ì‹œë²ˆí˜¸"
        if "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
        else pick_col(df_job_raw, "F", ["ì§€ì‹œë²ˆí˜¸"])
    )
    job_qty_col = (
        "ìˆ˜ëŸ‰"
        if "ìˆ˜ëŸ‰" in df_job_raw.columns
        else pick_col(df_job_raw, "R", ["ìˆ˜ëŸ‰", "ì§€ì‹œìˆ˜ëŸ‰"])
    )

    if job_jisi_col and job_qty_col:
        df_job = df_job_raw[[job_jisi_col, job_qty_col]].copy()
        df_job.columns = ["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"]
        agg_job = df_job.groupby("ì§€ì‹œë²ˆí˜¸", as_index=False).agg({"ì§€ì‹œìˆ˜ëŸ‰": "sum"})
        aggregates["job"] = agg_job
    else:
        aggregates["job"] = pd.DataFrame(columns=["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"])

    # === 3) ìƒì‚°ì‹¤ì  ì§‘ê³„: ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸)ë³„ ì–‘í’ˆ / QCìƒ˜í”Œ / ê¸°íƒ€ìƒ˜í”Œ í•©ê³„ ===
    # ì‘ì§€ë²ˆí˜¸: ë³´í†µ "ì‘ì§€ë²ˆí˜¸" ì»¬ëŸ¼ ì‚¬ìš© (Aì—´)
    res_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "A", ["ì‘ì§€ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"])
    )

    # ìˆ˜ì£¼ë²ˆí˜¸: ìˆìœ¼ë©´ ê°™ì´ ë“¤ê³ ë§Œ ë‹¤ë‹ˆë‹¤ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©
    res_suju_col = (
        "ìˆ˜ì£¼ë²ˆí˜¸"
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "E", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    )

    # ì–‘í’ˆ(ì‹¤ì œ ìƒì‚°ìˆ˜ëŸ‰) ì»¬ëŸ¼ ì°¾ê¸°
    res_good_col = None
    for cand in ["ì–‘í’ˆ", "ì–‘í’ˆìˆ˜ëŸ‰", "ì–‘í’ˆìˆ˜", "í•©ê²©", "ìƒì‚°ìˆ˜ëŸ‰"]:
        if cand in df_result_raw.columns:
            res_good_col = cand
            break

    # QCìƒ˜í”Œ: AGì—´, ê¸°íƒ€ìƒ˜í”Œ: AHì—´ ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì°¾ê¸°
    res_qc_col = pick_col(df_result_raw, "AG", ["QCìƒ˜í”Œ"])
    res_etc_col = pick_col(df_result_raw, "AH", ["ê¸°íƒ€ìƒ˜í”Œ"])

    # ìµœì†Œí•œ ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸)ë‚˜ ìˆ˜ì£¼ë²ˆí˜¸ ë‘˜ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ ì§‘ê³„ ê°€ëŠ¥
    if res_jisi_col or res_suju_col:
        use_cols = []
        if res_jisi_col:
            use_cols.append(res_jisi_col)
        if res_suju_col:
            use_cols.append(res_suju_col)
        if res_good_col:
            use_cols.append(res_good_col)
        if res_qc_col:
            use_cols.append(res_qc_col)
        if res_etc_col:
            use_cols.append(res_etc_col)

        df_res = df_result_raw[use_cols].copy()

        # ì»¬ëŸ¼ëª… í†µì¼
        rename_map = {}
        if res_jisi_col:
            rename_map[res_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
        if res_suju_col:
            rename_map[res_suju_col] = "ìˆ˜ì£¼ë²ˆí˜¸"
        if res_good_col:
            rename_map[res_good_col] = "ìƒì‚°ìˆ˜ëŸ‰"
        if res_qc_col:
            rename_map[res_qc_col] = "QCìƒ˜í”Œ"
        if res_etc_col:
            rename_map[res_etc_col] = "ê¸°íƒ€ìƒ˜í”Œ"

        df_res = df_res.rename(columns=rename_map)

        # NaN â†’ 0 ì²˜ë¦¬
        for col in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
            if col in df_res.columns:
                df_res[col] = df_res[col].apply(safe_num)

        # âœ… ê¸°ì¤€ í‚¤: ì§€ì‹œë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì§€ì‹œë²ˆí˜¸ë¡œ, ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ìˆ˜ì£¼ë²ˆí˜¸ë¡œ
        group_keys = []
        if "ì§€ì‹œë²ˆí˜¸" in df_res.columns:
            group_keys.append("ì§€ì‹œë²ˆí˜¸")
        elif "ìˆ˜ì£¼ë²ˆí˜¸" in df_res.columns:
            group_keys.append("ìˆ˜ì£¼ë²ˆí˜¸")

        # ì§‘ê³„ ë°©ì‹ ì •ì˜
        agg_dict = {}
        for col in df_res.columns:
            if col in group_keys:
                continue
            if col in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
                agg_dict[col] = "sum"
            elif col == "ìˆ˜ì£¼ë²ˆí˜¸" and "ì§€ì‹œë²ˆí˜¸" in group_keys:
                # ì§€ì‹œë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì„ ë•Œ ìˆ˜ì£¼ë²ˆí˜¸ëŠ” ëŒ€í‘œê°’ í•˜ë‚˜ë§Œ
                agg_dict[col] = "first"
            else:
                agg_dict[col] = "first"

        agg_res = df_res.groupby(group_keys, as_index=False).agg(agg_dict)
        aggregates["result"] = agg_res
    else:
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ DF
        aggregates["result"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "ìˆ˜ì£¼ë²ˆí˜¸", "ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]
        )


    # === 4) ë¶ˆëŸ‰ ì§‘ê³„: [ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ]ë³„ ì›ë¶ˆ/ì‘ë¶ˆ ìˆ˜ëŸ‰ ===
    def_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_defect_raw.columns
        else pick_col(df_defect_raw, "C", ["ì‘ì§€ë²ˆí˜¸"])
    )
    def_part_col = (
        "íˆ¬ì…í’ˆë²ˆ"
        if "íˆ¬ì…í’ˆë²ˆ" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Q", ["íˆ¬ì…í’ˆë²ˆ"])
    )
    def_qty_col = (
        "ë¶ˆëŸ‰ìˆ˜ëŸ‰"
        if "ë¶ˆëŸ‰ìˆ˜ëŸ‰" in df_defect_raw.columns
        else pick_col(df_defect_raw, "W", ["ë¶ˆëŸ‰ìˆ˜ëŸ‰"])
    )
    def_type_col = (
        "ë¶ˆëŸ‰ìœ í˜•.1"
        if "ë¶ˆëŸ‰ìœ í˜•.1" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Z", ["ë¶ˆëŸ‰ìœ í˜•.1", "ë¶ˆëŸ‰ìœ í˜•"])
    )

    if def_jisi_col and def_part_col and def_qty_col and def_type_col:
        df_def = df_defect_raw[
            [def_jisi_col, def_part_col, def_qty_col, def_type_col]
        ].copy()
        df_def.columns = ["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¶ˆëŸ‰ìˆ˜ëŸ‰", "ë¶ˆëŸ‰ìœ í˜•"]
        df_def["ë¶ˆëŸ‰ìœ í˜•"] = df_def["ë¶ˆëŸ‰ìœ í˜•"].astype(str)

        # ì›ë¶ˆ
        df_orig = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì›)")].copy()
        agg_orig = (
            df_orig.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì›ë¶ˆ"})
        )

        # ì‘ë¶ˆ
        df_proc = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì‘)")].copy()
        agg_proc = (
            df_proc.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì‘ë¶ˆ"})
        )

        # ë‘˜ í•©ì¹˜ê¸°
        agg_def = pd.merge(agg_orig, agg_proc, on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], how="outer")
        aggregates["defect"] = agg_def
    else:
        aggregates["defect"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ì›ë¶ˆ", "ì‘ë¶ˆ"]
        )

    # === 5) ì¬ê³  ì§‘ê³„: í’ˆë²ˆë³„ ERPì¬ê³  (ì‘ì—…ì¥ WC501~WC504) ===
    stock_wc_col = pick_col(df_stock_raw, "A", ["ì‘ì—…ì¥"])
    stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])

    # ERPì¬ê³ ëŠ” ë°˜ë“œì‹œ "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" ì»¬ëŸ¼ì„ ì‚¬ìš© (ì—†ìœ¼ë©´ Nì—´ fallback)
    if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in df_stock_raw.columns:
        stock_qty_col = "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"
    else:
        stock_qty_col = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

    if stock_wc_col and stock_part_col and stock_qty_col:
        df_stock = df_stock_raw[
            [stock_wc_col, stock_part_col, stock_qty_col]
        ].copy()
        df_stock.columns = ["ì‘ì—…ì¥", "í’ˆë²ˆ", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
        df_stock = df_stock[df_stock["ì‘ì—…ì¥"].isin(["WC501", "WC502", "WC503", "WC504"])]
        if not df_stock.empty:
            agg_stock = (
                df_stock.groupby("í’ˆë²ˆ", as_index=False)["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
                .sum()
                .rename(columns={"ì‹¤ì¬ê³ ìˆ˜ëŸ‰": "ERPì¬ê³ "})
            )
            aggregates["stock"] = agg_stock
        else:
            aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])
    else:
        aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])

    return aggregates


# -----------------------------
# í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚° (merge ê¸°ë°˜)
# -----------------------------
def recalc_return_expectation(df_return, aggs):
    """
    df_return(í™˜ì…ê´€ë¦¬ í…Œì´ë¸”)ì— ì§‘ê³„ ë°ì´í„°(aggs)ë¥¼ mergeë¡œ ë¶™ì—¬ì„œ
    ERPë¶ˆì¶œìˆ˜ëŸ‰, í˜„ì¥ì‹¤ë¬¼ì…ê³ , ì§€ì‹œìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰, QCìƒ˜í”Œ, ê¸°íƒ€ìƒ˜í”Œ, ì›ë¶ˆ, ì‘ë¶ˆ, ERPì¬ê³ , ì˜ˆìƒì¬ê³ ë¥¼ ê³„ì‚°

    ì˜ˆìƒì¬ê³  = í˜„ì¥ì‹¤ë¬¼ì…ê³  - (ìƒì‚°ìˆ˜ëŸ‰ + QCìƒ˜í”Œ + ê¸°íƒ€ìƒ˜í”Œ) * ë‹¨ìœ„ìˆ˜ëŸ‰ - ì‘ë¶ˆ
    """
    if df_return.empty:
        return pd.DataFrame(columns=CSV_COLS)

    # [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    df = df_return.drop_duplicates(
        subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
    ).copy()

    # 1) ì…ê³  ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["in"],
        how="left",
        on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
        suffixes=("", "_in"),
    )

    # 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["job"],
        how="left",
        on="ì§€ì‹œë²ˆí˜¸",
    )

    # 3) ìƒì‚°ì‹¤ì  ì§‘ê³„ ë¶™ì´ê¸°
    res_tbl = aggs["result"]

    # ìƒˆ ë°©ì‹: ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸) ê¸°ì¤€ ì§‘ê³„ê°€ ë˜ì–´ ìˆëŠ” ê²½ìš°
    if isinstance(res_tbl, pd.DataFrame) and not res_tbl.empty and "ì§€ì‹œë²ˆí˜¸" in res_tbl.columns:
        merge_cols = ["ì§€ì‹œë²ˆí˜¸"]
        for c in ["ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]:
            if c in res_tbl.columns:
                merge_cols.append(c)

        df = df.merge(
            res_tbl[merge_cols],
            how="left",
            on="ì§€ì‹œë²ˆí˜¸",
        )
    else:
        # í˜¹ì‹œë¼ë„ ì§€ì‹œë²ˆí˜¸ ì§‘ê³„ê°€ ì•ˆ ë˜ì–´ ìˆëŠ” êµ¬ë²„ì „ êµ¬ì¡°ì¼ ë•ŒëŠ”
        # ê¸°ì¡´ëŒ€ë¡œ ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¶™ì´ë„ë¡ fallback
        df = df.merge(
            res_tbl,
            how="left",
            on="ìˆ˜ì£¼ë²ˆí˜¸",
        )

    # 4) ë¶ˆëŸ‰ ì§‘ê³„ ë¶™ì´ê¸°
    df = df.merge(
        aggs["defect"],
        how="left",
        on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
    )

    # 5) ì¬ê³  ì§‘ê³„ ë¶™ì´ê¸°
    if "ERPì¬ê³ " in df.columns:
        df = df.drop(columns=["ERPì¬ê³ "])
    df = df.merge(
        aggs["stock"],
        how="left",
        on="í’ˆë²ˆ",
    )

    # ìˆ«ì ì»¬ëŸ¼ë“¤ NaN -> 0
    num_cols = [
        "ERPë¶ˆì¶œìˆ˜ëŸ‰",
        "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
        "ì§€ì‹œìˆ˜ëŸ‰",
        "ìƒì‚°ìˆ˜ëŸ‰",
        "QCìƒ˜í”Œ",
        "ê¸°íƒ€ìƒ˜í”Œ",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ì›ë¶ˆ",
        "ì‘ë¶ˆ",
        "ERPì¬ê³ ",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = df[col].apply(safe_num)
        else:
            df[col] = 0.0

    # âœ… ë„¤ê°€ ë§í•œ ê³µì‹ ê·¸ëŒ€ë¡œ
    df["ì˜ˆìƒì¬ê³ "] = (
        df["í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        - (df["ìƒì‚°ìˆ˜ëŸ‰"] + df["QCìƒ˜í”Œ"] + df["ê¸°íƒ€ìƒ˜í”Œ"]) * df["ë‹¨ìœ„ìˆ˜ëŸ‰"]
        - df["ì›ë¶ˆ"]
        - df["ì‘ë¶ˆ"]
    )

    # ì™„ì„±í’ˆëª…ì€ ì œí’ˆëª… ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    df["ì™„ì„±í’ˆëª…"] = df.get("ì œí’ˆëª…", None)

    # CSVìš© ì „ì²´ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    for col in CSV_COLS:
        if col not in df.columns:
            df[col] = None

    out = df[CSV_COLS].copy()
    return out

# -----------------------------
# PDF ìƒì„± í•¨ìˆ˜
# -----------------------------
if REPORTLAB_AVAILABLE:
    from xml.sax.saxutils import escape
    from reportlab.graphics.barcode import code128
    from reportlab.graphics.shapes import Drawing
    from reportlab.lib.units import mm
    from reportlab.platypus import PageBreak

    def generate_pdf(
        df_export: pd.DataFrame,
        uploaded_image=None,
        pasted_text: str | None = None,
    ) -> bytes:
        """
        - ì œëª© / í‘œ ëª¨ë‘ ì™¼ìª½ ì •ë ¬
        - pasted_textê°€ ìˆìœ¼ë©´ ì œëª© ì•„ë˜ì— ê·¸ëŒ€ë¡œ ì¶œë ¥
        - uploaded_imageëŠ” ì§€ê¸ˆì€ ì•ˆ ì¨ë„ ë¨(ì°¨í›„ í™•ì¥ìš©)
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Table,
            TableStyle,
            Paragraph,
            Spacer,
            Image,
        )
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors

        buffer = io.BytesIO()

        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=20,
            rightMargin=20,
            topMargin=20,
            bottomMargin=20,
        )

        styles = getSampleStyleSheet()

        title_style = ParagraphStyle(
            "TitleStyle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=15,
            alignment=0,   # LEFT
        )

        text_style = ParagraphStyle(
            "TextStyle",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=10,
            leading=14,
            alignment=0,   # LEFT
        )

        table_style = TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                ("ALIGN", (0, 0), (-1, -1), "LEFT"),  # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
                ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                ("FONTSIZE", (0, 0), (-1, -1), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                ("BOTTOMPADDING", (0, 0), (-1, -1), 20),
                ("TOPPADDING",    (0, 0), (-1, -1), 20),
                ("MINROWHEIGHT",  (0, 0), (-1, -1), 35),
            ]
        )

        story = []

        # 1) ì œëª©
        suju_list = df_export["ìˆ˜ì£¼ë²ˆí˜¸"].dropna().astype(str).unique()
        name_list = df_export["ì™„ì„±í’ˆëª…"].dropna().astype(str).unique()
        title_text = f"{suju_list[0] if len(suju_list) else ''} {name_list[0] if len(name_list) else ''}".strip()

        story.append(Paragraph(title_text, title_style))
        story.append(Spacer(1, 12))

        # 2) ìƒë‹¨ ë©”ëª¨ (í…ìŠ¤íŠ¸)
        if pasted_text is not None and pasted_text.strip() != "":
            # <, >, & ë“± ì´ìŠ¤ì¼€ì´í”„ + ì¤„ë°”ê¿ˆì„ <br/>ë¡œ ë³€í™˜
            safe_text = escape(pasted_text).replace("\n", "<br/>")
            story.append(Paragraph(safe_text, text_style))
            story.append(Spacer(1, 12))

        # 3) (ì›í•˜ë©´ ì´ë¯¸ì§€ë„ ì—¬ê¸°ì—)
        if uploaded_image:
            try:
                img = Image(uploaded_image, width=400, height=300)
                story.append(img)
                story.append(Spacer(1, 12))
            except Exception:
                pass

        # í‘œ êµ¬ì„±: ê¸°ì¡´ + 1P, 2P, 3P, 4P 4ì¹¸ ì¶”ê°€
        base_cols = ["í’ˆë²ˆ", "í’ˆëª…", "ì‘ë¶ˆ", "ì˜ˆìƒì¬ê³ ", "ERPì¬ê³ "]
        table_cols = base_cols + ["1P", "2P", "3P", "4P"]
        table_data = [table_cols]

        for _, row in df_export.iterrows():
            # df_export ì—ëŠ” 1P~4P ì»¬ëŸ¼ì´ ì—†ìœ¼ë‹ˆê¹Œ, ê¸°ì¡´ ë°ì´í„°ë§Œ ë„£ê³  4ì¹¸ì€ ê³µë°±ìœ¼ë¡œ ì±„ì›€
            base_values = [str(row.get(c, "")) for c in base_cols]
            extra_values = ["", "", "", ""]  # 1P, 2P, 3P, 4P
            table_data.append(base_values + extra_values)

        # í–‰ ë†’ì´ (í—¤ë”ëŠ” ê¸°ë³¸, ë°ì´í„° í–‰ë§Œ ë†’ê²Œ)
        default_height = None        # í—¤ë”
        data_height = 40             # ë°ì´í„° í–‰
        row_heights = [default_height] + [data_height] * (len(table_data) - 1)

        # ì»¬ëŸ¼ í­ ì„¤ì •
        #  - ì•ì˜ 5ê°œ ì»¬ëŸ¼ì€ None(ìë™)
        #  - 1P~4P 4ì¹¸ë§Œ ë„“ê²Œ
        col_widths = [None, None, None, None, None, 130, 130, 80, 80]

        table = Table(
            table_data,
            repeatRows=1,
            rowHeights=row_heights,
            colWidths=col_widths,
            hAlign="LEFT",   # í‘œ ì „ì²´ ì™¼ìª½ ì •ë ¬
        )

        table.setStyle(
            TableStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                    ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                    ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                    ("FONTSIZE", (0, 0), (-1, -1), 8),
                    ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),

                    ("LEFTPADDING", (0, 0), (-1, -1), 0),
                    ("RIGHTPADDING", (0, 0), (-1, -1), 4),

                    # ë°ì´í„° í–‰ë§Œ ìœ„/ì•„ë˜ ì—¬ë°± í¬ê²Œ
                    ("TOPPADDING",    (0, 1), (-1, -1), 12),
                    ("BOTTOMPADDING", (0, 1), (-1, -1), 12),
                ]
            )
        )

        story.append(table)

        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

    # ğŸ”¹ ì†Œí˜• ë¼ë²¨í”„ë¦°í„°(100Ã—120mm)ìš© ë¶€ìì¬ë°˜ì… ë¼ë²¨ PDF
    def generate_label_pdf(df_labels: pd.DataFrame, barcode_value: str, unit_value: str) -> bytes:
        """
        df_labels: 'í’ˆëª…', 'í’ˆë²ˆ', 'í™˜ì…ì¼' ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame
        barcode_value: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë°”ì½”ë“œ ê°’ (ì˜ˆ: B202511-00120001)
        unit_value: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‹¨ìœ„ìˆ˜ëŸ‰
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Paragraph,
            Spacer,
            PageBreak,
            Flowable,
            Table,
            TableStyle,
        )
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_CENTER, TA_LEFT
        from reportlab.lib.units import mm
        from reportlab.lib import colors
        from reportlab.graphics.barcode import code128
        from xml.sax.saxutils import escape

        buffer = io.BytesIO()

        # ë¼ë²¨ í¬ê¸°: 100mm * 120mm
        LABEL_WIDTH = 100 * mm
        LABEL_HEIGHT = 120 * mm

        doc = SimpleDocTemplate(
            buffer,
            pagesize=(LABEL_WIDTH, LABEL_HEIGHT),
            leftMargin=5 * mm,
            rightMargin=5 * mm,
            topMargin=5 * mm,
            bottomMargin=5 * mm,
        )

        styles = getSampleStyleSheet()

        # ì œëª© ìŠ¤íƒ€ì¼ (25pt, ì¤‘ì•™ì •ë ¬)
        title_style = ParagraphStyle(
            "LabelTitle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=25,
            alignment=TA_CENTER,
        )

        # ì™¼ìª½ í•„ë“œëª… ìŠ¤íƒ€ì¼ (êµµê²Œ)
        field_label_style = ParagraphStyle(
            "FieldLabel",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=13,
            leading=16,
            alignment=TA_LEFT,
        )

        # ì˜¤ë¥¸ìª½ ê°’ ìŠ¤íƒ€ì¼ (êµµê²Œ â€” ì›í•˜ë©´ ì–‡ê²Œë„ ë°”ê¿€ ìˆ˜ ìˆìŒ)
        field_value_style = ParagraphStyle(
            "FieldValue",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=13,
            leading=16,
            alignment=TA_LEFT,
        )

        # ë°”ì½”ë“œ í•˜ë‹¨ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ (ì¤‘ì•™ì •ë ¬)
        barcode_text_style = ParagraphStyle(
            "BarcodeText",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=12,
            alignment=TA_CENTER,
        )

        # âœ… ë°”ì½”ë“œë¥¼ ê°€ë¡œ ì¤‘ì•™ ì •ë ¬í•˜ê¸° ìœ„í•œ Flowable
        class CenteredBarcode(Flowable):
            def __init__(self, barcode):
                super().__init__()
                self.barcode = barcode
                self._avail_width = None
                self.width = barcode.width
                self.height = barcode.height

            def wrap(self, availWidth, availHeight):
                self._avail_width = availWidth
                return availWidth, self.height

            def draw(self):
                if self._avail_width is None:
                    x = 0
                else:
                    x = (self._avail_width - self.barcode.width) / 2.0
                self.barcode.drawOn(self.canv, x, 0)

        story = []

        # ğŸ”² í˜ì´ì§€ë§ˆë‹¤ ë³´ë”ë¼ì¸ ê·¸ë¦¬ê¸°ìš© ì½œë°±
        def draw_border(canvas, doc_obj):
            canvas.saveState()
            # 3px â‰ˆ 0.8mm ì •ë„ ì•ˆìª½ìœ¼ë¡œ
            inset = 0.8 * mm
            x = inset
            y = inset
            w = LABEL_WIDTH - 2 * inset
            h = LABEL_HEIGHT - 2 * inset
            canvas.setLineWidth(0.75)  # â‰ˆ 1px
            canvas.rect(x, y, w, h)
            canvas.restoreState()

        for idx, row in df_labels.iterrows():
            í’ˆëª… = str(row.get("í’ˆëª…", ""))
            í’ˆë²ˆ = str(row.get("í’ˆë²ˆ", ""))
            í™˜ì…ì¼ = row.get("í™˜ì…ì¼", "")

            # í™˜ì…ì¼ ì •ë¦¬
            try:
                if pd.notna(í™˜ì…ì¼):
                    í™˜ì…ì¼_str = pd.to_datetime(í™˜ì…ì¼).strftime("%Y-%m-%d")
                else:
                    í™˜ì…ì¼_str = ""
            except Exception:
                í™˜ì…ì¼_str = str(í™˜ì…ì¼)

            # ----- ì œëª© -----
            story.append(Paragraph("ë¶€ìì¬ë°˜ì…", title_style))
            # ê³µë°± 3ì¤„ ì •ë„
            story.append(Spacer(1, field_label_style.leading * 3))

            # ----- í•„ë“œ 4ì¤„ì„ 2ì—´ í…Œì´ë¸”ë¡œ êµ¬ì„± (ì™¼ìª½ ì—´ ë„ˆë¹„ ê³ ì •) -----
            # ì™¼ìª½ ì—´ ë„ˆë¹„ë¥¼ ê³ ì •í•˜ë©´ ì˜¤ë¥¸ìª½ ê°’ ì‹œì‘ ìœ„ì¹˜ê°€ ëª¨ë‘ ë™ì¼í•´ì§
            first_col_width = 28 * mm  # í•„ìš”í•˜ë©´ mm ê°’ ì¡°ì ˆí•´ì„œ ë§ì¶”ë©´ ë¨
            second_col_width = doc.width - first_col_width

            data = [
                [
                    Paragraph("<b>í’ˆëª…</b>", field_label_style),
                    Paragraph(f"<b>{escape(í’ˆëª…)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>í’ˆëª©ì½”ë“œ</b>", field_label_style),
                    Paragraph(f"<b>{escape(í’ˆë²ˆ)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>ë‹¨ìœ„ìˆ˜ëŸ‰</b>", field_label_style),
                    Paragraph(f"<b>{escape(unit_value)}</b>", field_value_style),
                ],
                [
                    Paragraph("<b>ë°˜ì…ì¼ì</b>", field_label_style),
                    Paragraph(f"<b>{escape(í™˜ì…ì¼_str)}</b>", field_value_style),
                ],
            ]

            row_height = field_label_style.leading * 2  # í•œ ì¤„ + ê³µë°± 1ì¤„ ëŠë‚Œ
            row_heights = [row_height] * len(data)

            tbl = Table(
                data,
                colWidths=[first_col_width, second_col_width],
                rowHeights=row_heights,
            )
            tbl.setStyle(
                TableStyle(
                    [
                        ("ALIGN", (0, 0), (-1, -1), "LEFT"),
                        ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                        ("LEFTPADDING", (0, 0), (-1, -1), 0),
                        ("RIGHTPADDING", (0, 0), (-1, -1), 0),
                        ("TOPPADDING", (0, 0), (-1, -1), 0),
                        ("BOTTOMPADDING", (0, 0), (-1, -1), 0),
                    ]
                )
            )

            story.append(tbl)
            story.append(Spacer(1, 8))

            # ğŸ”¥ ë°”ì½”ë“œ ìƒì„± (ì „ì²´ ë„ˆë¹„ ì•½ 90px ê¸°ì¤€)
            bar_width_px = 30
            bar_width_pt = bar_width_px * 0.75  # px â†’ pt
            char_count = max(len(barcode_value), 1)
            bar_width = bar_width_pt / char_count

            bc = code128.Code128(
                barcode_value,
                barHeight=15 * mm,
                barWidth=bar_width,
            )

            # ì¤‘ì•™ì •ë ¬ Flowableë¡œ ê°ì‹¸ê¸°
            center_bc = CenteredBarcode(bc)

            story.append(Spacer(1, 5))
            story.append(center_bc)
            story.append(Spacer(1, 5))

            # ë°”ì½”ë“œ ê°’ í…ìŠ¤íŠ¸ (ì¤‘ì•™ì •ë ¬)
            story.append(Paragraph(barcode_value, barcode_text_style))

            # ì—¬ëŸ¬ ì¥ì¼ ê²½ìš° ë‹¤ìŒ í˜ì´ì§€
            if idx != len(df_labels) - 1:
                story.append(PageBreak())

        # ë³´ë”ë¼ì¸ ì½œë°± ì ìš©
        doc.build(story, onFirstPage=draw_border, onLaterPages=draw_border)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes


# -----------------------------
# ë©”ì¸ í™”ë©´
# -----------------------------
st.title("ë¶€ìì¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

menu = st.radio(
    "ë©”ë‰´ ì„ íƒ",
    [
        "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ",
        "ğŸ“¦ ì…ê³  ì¡°íšŒ",
        "â†©ï¸ í™˜ì… ê´€ë¦¬",
        "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°",
        "ğŸ§© ê³µí†µìì¬",
        "ğŸ· ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚°",  
    ],
    horizontal=True,
)

# ==========================================
# ğŸ“¤ 1. íŒŒì¼ ì—…ë¡œë“œ íƒ­ (S3ì— ì—‘ì…€ + DB ì €ì¥)
# ==========================================
if menu == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    st.subheader("ğŸ“¤ 2025ë…„ ë¶€ìì¬ ê´€ë¦¬ëŒ€ì¥ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xlsm", "xlsx"])

    if uploaded_file and s3_client is not None:
        try:
            # 1) ì—…ë¡œë“œëœ íŒŒì¼ ì „ì²´ë¥¼ bytesë¡œ ì½ê¸°
            file_bytes = uploaded_file.read()

            # 2) ì—‘ì…€ ì›ë³¸ì„ S3ì— ì €ì¥ (ë°±ì—…/ì›ë³¸ ìš©ë„)
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=S3_KEY_EXCEL,
                Body=file_bytes,
            )

            # 3) ì—‘ì…€ â†’ SQLite DB ë³€í™˜
            db_bytes = excel_bytes_to_sqlite_bytes(file_bytes)

            # 4) ë³€í™˜ëœ DBë¥¼ S3ì— ì €ì¥
            s3_client.put_object(
                Bucket=S3_BUCKET,
                Key=S3_KEY_DB,
                Body=db_bytes,
            )

            # 5) ìºì‹œ ì´ˆê¸°í™”
            load_db_from_s3.clear()
            load_file_from_s3.clear()
            # (load_excelì€ ì´ì œ ì•ˆ ì¨ë„ ë˜ì§€ë§Œ í˜¹ì‹œ ëª°ë¼ ê°™ì´ ë¹„ì›Œ ë‘ )
            load_excel.clear()

            st.success("ì—‘ì…€ê³¼ DBë¥¼ S3ì— ëª¨ë‘ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íƒ­ì—ì„œ ë¹ ë¥´ê²Œ ì¡°íšŒí•  ìˆ˜ ìˆì–´ìš”.")
        except Exception as e:
            st.error(f"S3 ì—…ë¡œë“œ/DB ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    elif uploaded_file and s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.stop()  # ì—…ë¡œë“œ íƒ­ì—ì„œëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ



# ==========================================
# ë‚˜ë¨¸ì§€ íƒ­: S3ì—ì„œ DB ë¡œë”©
# ==========================================
db_bytes = load_db_from_s3()
if db_bytes is None:
    st.warning("S3ì— ì—…ë¡œë“œëœ DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ] íƒ­ì—ì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    st.stop()

# S3ì—ì„œ ë°›ì€ DB bytesë¡œ SQLite ì—°ê²°
conn = get_db_connection(db_bytes)

# í•„ìˆ˜ í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ ì²´í¬
required_tables = ["ì…ê³ ", "ì‘ì—…ì§€ì‹œ", "ìˆ˜ì£¼", "BOM", "ì¬ê³ ", "ìƒì‚°ì‹¤ì ", "ë¶ˆëŸ‰"]
tables_df = pd.read_sql(
    "SELECT name FROM sqlite_master WHERE type='table';",
    conn,
)
existing_tables = set(tables_df["name"].tolist())
missing = [t for t in required_tables if t not in existing_tables]
if missing:
    st.error(f"SQLite DBì— ë‹¤ìŒ í…Œì´ë¸”(ì‹œíŠ¸)ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
    st.stop()

# ê° ì‹œíŠ¸ì— í•´ë‹¹í•˜ëŠ” í…Œì´ë¸” ì½ê¸°
df_in_raw     = pd.read_sql("SELECT * FROM ì…ê³ ", conn)
df_job_raw    = pd.read_sql("SELECT * FROM ì‘ì—…ì§€ì‹œ", conn)
df_suju_raw   = pd.read_sql("SELECT * FROM ìˆ˜ì£¼", conn)
df_bom_raw    = pd.read_sql("SELECT * FROM BOM", conn)
df_stock_raw  = pd.read_sql("SELECT * FROM ì¬ê³ ", conn)
df_result_raw = pd.read_sql("SELECT * FROM ìƒì‚°ì‹¤ì ", conn)
df_defect_raw = pd.read_sql("SELECT * FROM ë¶ˆëŸ‰", conn)

# ì§‘ê³„ëŠ” í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹œ ìµœì´ˆ 1íšŒ
if "aggregates" not in st.session_state:
    st.session_state["aggregates"] = None



# ============================
# 2. ì…ê³  ì¡°íšŒ íƒ­
# ============================
if menu == "ğŸ“¦ ì…ê³  ì¡°íšŒ":
    st.header("ğŸ“¦ ì…ê³  ì¡°íšŒ")
    st.caption("ìš”ì²­ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì…ê³  ë‚´ì—­ì„ ì¡°íšŒí•©ë‹ˆë‹¤.")

    # ì…ê³  ì‹œíŠ¸ ì›ë³¸
    df_in = df_in_raw.copy()

    # ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ ì°¾ê¸°
    req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    if req_date_col is None:
        st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜
        df_in[req_date_col] = pd.to_datetime(df_in[req_date_col], errors="coerce").dt.date

        # ğŸ”¹ ê¸°ë³¸ ë²”ìœ„: ì–´ì œ ~ ì˜¤ëŠ˜
        today = date.today()
        default_start = today - timedelta(days=1)

        # ë‚ ì§œ ì„ íƒ + í’ˆëª… ê²€ìƒ‰ì„ ê°™ì€ ì¤„(col) ì— ë°°ì¹˜
        col_date, col_name = st.columns([1, 2])

        with col_date:
            date_range = st.date_input(
                "ìš”ì²­ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
                (default_start, today),
                key="in_date_range",
            )

        with col_name:
            name_filter = st.text_input(
                "í’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰",
                key="in_name_filter",
                placeholder="ë¶€ë¶„ ê²€ìƒ‰ (ì˜ˆ: í¬ë¦¼, ì•°í”Œ ë“±)",
            )

        # Streamlit ë²„ì „ì— ë”°ë¼ tuple ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ì„œ ë°©ì–´ ì½”ë“œ
        if isinstance(date_range, (tuple, list)):
            start_date, end_date = date_range
        else:
            start_date = date_range
            end_date = date_range

        # ë‚ ì§œ í•„í„° ë§ˆìŠ¤í¬
        mask = (df_in[req_date_col] >= start_date) & (df_in[req_date_col] <= end_date)

        # ê° ì—´ ì»¬ëŸ¼ ì°¾ê¸°
        col_process  = pick_col(df_in, "J", ["ìƒì‚°ê³µì •"])
        col_req_no   = pick_col(df_in, "L", ["ìš”ì²­ë²ˆí˜¸"])
        col_part     = pick_col(df_in, "M", ["í’ˆë²ˆ"])
        col_name     = pick_col(df_in, "O", ["í’ˆëª…"])
        col_req_qty  = pick_col(df_in, "P", ["ìš”ì²­ìˆ˜ëŸ‰"])
        col_erp_out  = pick_col(df_in, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "ë¶ˆì¶œìˆ˜ëŸ‰"])
        col_real_in  = pick_col(df_in, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

        # ğŸ‘‰ í™”ë©´ì— ë³´ì—¬ì¤„ ì»¬ëŸ¼ ìˆœì„œ: ìƒì‚°ê³µì • â†’ ìš”ì²­ë‚ ì§œ â†’ ë‚˜ë¨¸ì§€
        raw_cols = [c for c in [
            col_process,
            req_date_col,
            col_req_no,
            col_part,
            col_name,
            col_req_qty,
            col_erp_out,
            col_real_in,
        ] if c is not None]

        if not raw_cols:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_filtered = df_in.loc[mask, raw_cols].copy()

            # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë§ì¶”ê¸°
            rename_map = {}
            rename_map[req_date_col] = "ìš”ì²­ë‚ ì§œ"
            if col_process: rename_map[col_process] = "ìƒì‚°ê³µì •"
            if col_req_no:  rename_map[col_req_no]  = "ìš”ì²­ë²ˆí˜¸"
            if col_part:    rename_map[col_part]    = "í’ˆë²ˆ"
            if col_name:    rename_map[col_name]    = "í’ˆëª…"
            if col_req_qty: rename_map[col_req_qty] = "ìš”ì²­ìˆ˜ëŸ‰"
            if col_erp_out: rename_map[col_erp_out] = "ERPë¶ˆì¶œìˆ˜ëŸ‰"
            if col_real_in: rename_map[col_real_in] = "í˜„ì¥ì‹¤ë¬¼ì…ê³ "

            df_filtered.rename(columns=rename_map, inplace=True)

            # ğŸ” í’ˆëª… í•„í„° ì¶”ê°€ (ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²½ìš°ë§Œ)
            if name_filter:
                if "í’ˆëª…" in df_filtered.columns:
                    df_filtered = df_filtered[
                        df_filtered["í’ˆëª…"].astype(str).str.contains(
                            name_filter, case=False, na=False
                        )
                    ]

            # ğŸ”¥ ì—‘ì…€ì—ì„œ "ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰"ì´ ìœ„ë¡œ ì˜¤ë„ë¡: ì¸ë±ìŠ¤ ì—­ìˆœ ì •ë ¬
            df_filtered = df_filtered.iloc[::-1].reset_index(drop=True)

            if df_filtered.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(df_filtered, use_container_width=True)

# ============================================================
# ğŸ” 3. ìˆ˜ì£¼ ì°¾ê¸° í™”ë©´
# ============================================================
if menu == "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°":
    st.subheader("ğŸ” ìˆ˜ì£¼ ì°¾ê¸°")

    st.markdown(
        """
        **ë™ì‘ ë°©ì‹**

        1. ê¸°ì¤€ í’ˆë²ˆì„ ì…ë ¥í•œë‹¤.  
        2. BOM ì‹œíŠ¸ì˜ **Cì—´ í’ˆë²ˆ**ì—ì„œ ê¸°ì¤€ í’ˆë²ˆê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ê³ , ê·¸ í–‰ì˜ **í’ˆëª©ì½”ë“œ(Aì—´)** ê°’ì„ êµ¬í•œë‹¤.  
        3. ì´ í’ˆëª©ì½”ë“œë¥¼ **ìˆ˜ì£¼ ì‹œíŠ¸ì˜ í’ˆë²ˆ(Jì—´)**ì—ì„œ ê²€ìƒ‰í•œë‹¤.  
        4. ì—†ìœ¼ë©´ 2ë‹¨ê³„ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•œë‹¤.  
        5. ì˜¤ëŠ˜(today) ê¸°ì¤€ìœ¼ë¡œ **1ê°œì›” ì´ë‚´ â†’ 1ë…„ ì´ë‚´ â†’ ê³¼ê±° 3ê°œì›” â†’ 6ê°œì›” â†’ 12ê°œì›”** ìˆœìœ¼ë¡œ ìœ íš¨í•œ ìˆ˜ì£¼ë¥¼ ì°¾ëŠ”ë‹¤.  
        """
    )

    base_part = st.text_input("ê¸°ì¤€ í’ˆë²ˆ ì…ë ¥", key="suju_find_part")

    if base_part:
        today = date.today()

        df_bom = df_bom_raw.copy()
        bom_cols = list(df_bom.columns)

        # Aì—´ = í’ˆëª©ì½”ë“œ, Bì—´ = í’ˆëª…, Cì—´ = í’ˆë²ˆ
        bom_item_col = pick_col(df_bom, "A", ["í’ˆëª©ì½”ë“œ"])
        bom_name_col = pick_col(df_bom, "B", ["í’ˆëª…"])
        bom_component_col = pick_col(df_bom, "C", ["í’ˆë²ˆ"])

        if not all([bom_item_col, bom_name_col, bom_component_col]):
            st.error("BOM ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(A), í’ˆëª…(B), í’ˆë²ˆ(C)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ê¸°ì¤€ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” BOM í–‰ ê²€ìƒ‰
            df_bom_hit = df_bom[df_bom[bom_component_col] == base_part]

            if df_bom_hit.empty:
                st.info("BOMì—ì„œ í•´ë‹¹ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” ì™„ì„±í’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                # 1ì°¨ í’ˆëª©ì½”ë“œ ëª©ë¡
                item_codes = df_bom_hit[bom_item_col].dropna().unique().tolist()
                st.write("1ì°¨ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ):", item_codes)

                df_suju = df_suju_raw.copy()

                suju_part_col = pick_col(df_suju, "J", ["í’ˆë²ˆ"])
                suju_due_col = pick_col(df_suju, "G", ["ì¡°ì •ë‚©ê¸°ì¼ì"])

                if suju_part_col is None or suju_due_col is None:
                    st.error("ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(Jì—´) ë˜ëŠ” ì¡°ì •ë‚©ê¸°ì¼ì(Gì—´)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    df_suju[suju_due_col] = pd.to_datetime(
                        df_suju[suju_due_col], errors="coerce"
                    ).dt.date

                    # 1ì°¨ í’ˆëª©ì½”ë“œë¡œ ê²€ìƒ‰
                    df_suju_hit = df_suju[
                        df_suju[suju_part_col].isin(item_codes)
                    ].copy()

                    # ğŸ” 2ì°¨ BOM ê²½ë¡œë¥¼ ì¼ëŠ”ì§€ ì—¬ë¶€ í”Œë˜ê·¸
                    used_bom2_flow = False

                    # ì—†ìœ¼ë©´ ìƒìœ„(2ì°¨) í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰
                    if df_suju_hit.empty:
                        fallback_item_codes = set()
                        for code in item_codes:
                            df_bom_lvl2 = df_bom[df_bom[bom_component_col] == code]
                            if not df_bom_lvl2.empty:
                                lvl2 = (
                                    df_bom_lvl2[bom_item_col]
                                    .dropna()
                                    .unique()
                                    .tolist()
                                )
                                fallback_item_codes.update(lvl2)

                        fallback_item_codes = list(fallback_item_codes)

                        if fallback_item_codes:
                            st.info("1ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ì—†ì–´, 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                            st.write("2ì°¨ í’ˆëª©ì½”ë“œ:", fallback_item_codes)

                            df_suju_hit = df_suju[
                                df_suju[suju_part_col].isin(fallback_item_codes)
                            ].copy()

                        # âœ… 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œë„ ìˆ˜ì£¼ê°€ ì—†ìœ¼ë©´
                        #    â†’ ê·¸ 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ë‹¤ì‹œ BOM Cì—´(í’ˆë²ˆ)ì„ ë’¤ì ¸ì„œ
                        #       ê±°ê¸°ì„œ ë‚˜ì˜¨ ì™„ì„±í’ˆ í’ˆëª©ì½”ë“œ(Aì—´)ë¡œ ìˆ˜ì£¼ë¥¼ ì¬ê²€ìƒ‰
                        if df_suju_hit.empty and fallback_item_codes:
                            df_bom_from_lvl2 = df_bom[
                                df_bom[bom_component_col].isin(fallback_item_codes)
                            ].copy()

                            if df_bom_from_lvl2.empty:
                                st.warning(
                                    "1ì°¨Â·2ì°¨ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ë¥¼ ì°¾ì§€ ëª»í–ˆê³ , "
                                    "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ BOM í’ˆë²ˆ(Cì—´)ì„ ì¬ê²€ìƒ‰í•´ë„ "
                                    "ê´€ë ¨ í’ˆëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                )
                                df_show = pd.DataFrame()
                            else:
                                # 3ì°¨(ë” ìƒìœ„) ì™„ì„±í’ˆ í’ˆëª©ì½”ë“œ ëª©ë¡
                                third_item_codes = (
                                    df_bom_from_lvl2[bom_item_col]
                                    .dropna()
                                    .unique()
                                    .tolist()
                                )

                                st.info(
                                    "1ì°¨Â·2ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ìˆ˜ì£¼ê°€ ì—†ì–´ì„œ, "
                                    "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì—°ê²°ëœ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ) ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ìˆ˜ì£¼ë¥¼ ì°¾ìŠµë‹ˆë‹¤."
                                )
                                st.write("3ì°¨(ìƒìœ„) í’ˆëª©ì½”ë“œ:", third_item_codes)

                                # 3ì°¨ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ ì‹œíŠ¸ ì¬ê²€ìƒ‰
                                df_suju_bom2 = df_suju[
                                    df_suju[suju_part_col].isin(third_item_codes)
                                ].copy()

                                if df_suju_bom2.empty:
                                    st.warning(
                                        "2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œë¡œ ì—°ê²°ëœ ì™„ì„±í’ˆ ê¸°ì¤€ìœ¼ë¡œë„ "
                                        "ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                    )
                                    df_show = pd.DataFrame()
                                else:
                                    used_bom2_flow = True

                                    # -------------------------------
                                    # 1ï¸âƒ£ ìœ„ìª½ í‘œ: ìˆ˜ì£¼ ì‹œíŠ¸ ìš”ì•½
                                    #    (í’ˆë²ˆ, í’ˆëª…, ìˆ˜ì£¼ë²ˆí˜¸, ì¡°ì •ë‚©ê¸°ì¼ì, ìˆ˜ëŸ‰, ë§¤ì¶œì²˜)
                                    # -------------------------------
                                    # ì›í•˜ëŠ” í‘œì‹œ ìˆœì„œ ì •ì˜
                                    desired_cols = [
                                        suju_part_col,   # í’ˆë²ˆ (Jì—´)
                                        "í’ˆëª…",
                                        "ìˆ˜ì£¼ë²ˆí˜¸",
                                        suju_due_col,    # ì¡°ì •ë‚©ê¸°ì¼ì (Gì—´)
                                        "ìˆ˜ëŸ‰",
                                        "ë§¤ì¶œì²˜",
                                    ]

                                    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•´ì„œ ìˆœì„œ ìœ ì§€
                                    suju_disp_cols = [
                                        c for c in desired_cols if c in df_suju_bom2.columns
                                    ]

                                    # ë‚©ê¸°ì¼ì ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                                    if suju_due_col in df_suju_bom2.columns:
                                        df_suju_bom2 = df_suju_bom2.sort_values(
                                            by=suju_due_col, ascending=False
                                        )

                                    st.markdown("#### 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê¸°ì¤€ ìˆ˜ì£¼ ì •ë³´")
                                    if suju_disp_cols:
                                        st.dataframe(
                                            df_suju_bom2[suju_disp_cols],
                                            use_container_width=True,
                                        )
                                    else:
                                        # í˜¹ì‹œë¼ë„ ì»¬ëŸ¼ëª…ì„ ëª» ì°¾ì•˜ì„ ë•ŒëŠ” ì „ì²´ ë³´ì—¬ì£¼ê¸°
                                        st.dataframe(
                                            df_suju_bom2,
                                            use_container_width=True,
                                        )


                                    # -------------------------------
                                    # 2ï¸âƒ£ ì•„ë˜ í‘œ: ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ ì—°ê³„
                                    #    (ìˆ˜ì£¼ë²ˆí˜¸ A â†’ ì§€ì‹œë²ˆí˜¸ B, ì§€ì‹œì¼ì I, í’ˆëª… L)
                                    # -------------------------------
                                    if "ìˆ˜ì£¼ë²ˆí˜¸" in df_suju_bom2.columns:
                                        suju_values_bom2 = (
                                            df_suju_bom2["ìˆ˜ì£¼ë²ˆí˜¸"]
                                            .dropna()
                                            .astype(str)
                                            .unique()
                                            .tolist()
                                        )

                                        job_suju_col = pick_col(
                                            df_job_raw, "A", ["ìˆ˜ì£¼ë²ˆí˜¸"]
                                        )
                                        job_jisi_col = pick_col(
                                            df_job_raw, "B", ["ì§€ì‹œë²ˆí˜¸"]
                                        )
                                        job_date_col = pick_col(
                                            df_job_raw, "I", ["ì§€ì‹œì¼ì", "ì‘ì§€ì¼ì"]
                                        )
                                        job_name_col = pick_col(
                                            df_job_raw, "L", ["í’ˆëª…", "ì™„ì„±í’ˆëª…"]
                                        )

                                        if not all(
                                            [job_suju_col, job_jisi_col, job_name_col]
                                        ):
                                            st.info(
                                                "ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸(A), ì§€ì‹œë²ˆí˜¸(B), í’ˆëª…(L)ì„ ëª¨ë‘ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                            )
                                        else:
                                            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë½‘ê¸°
                                            use_cols = [job_suju_col, job_jisi_col]
                                            if job_date_col:
                                                use_cols.append(job_date_col)
                                            use_cols.append(job_name_col)

                                            df_job_map2 = df_job_raw[use_cols].copy()

                                            # ì»¬ëŸ¼ëª… í†µì¼
                                            new_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                            if job_date_col:
                                                new_cols.append("ì§€ì‹œì¼ì")
                                            new_cols.append("í’ˆëª…")
                                            df_job_map2.columns = new_cols

                                            # ë¬¸ìì—´ ë¹„êµìš©
                                            df_job_map2["ìˆ˜ì£¼ë²ˆí˜¸_str"] = df_job_map2[
                                                "ìˆ˜ì£¼ë²ˆí˜¸"
                                            ].astype(str)

                                            df_job_filtered2 = df_job_map2[
                                                df_job_map2["ìˆ˜ì£¼ë²ˆí˜¸_str"].isin(
                                                    suju_values_bom2
                                                )
                                            ].drop(columns=["ìˆ˜ì£¼ë²ˆí˜¸_str"])

                                            if not df_job_filtered2.empty:
                                                subset_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    subset_cols = [
                                                        "ìˆ˜ì£¼ë²ˆí˜¸",
                                                        "ì§€ì‹œë²ˆí˜¸",
                                                        "ì§€ì‹œì¼ì",
                                                        "í’ˆëª…",
                                                    ]

                                                df_job_filtered2 = df_job_filtered2.drop_duplicates(
                                                    subset=subset_cols
                                                )

                                                # ì§€ì‹œì¼ì ìµœì‹ ìˆœ + ì§€ì‹œë²ˆí˜¸ ì •ë ¬
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    df_job_filtered2["_ì§€ì‹œì¼ì_sort"] = pd.to_datetime(
                                                        df_job_filtered2["ì§€ì‹œì¼ì"],
                                                        errors="coerce",
                                                    )
                                                    df_job_filtered2 = df_job_filtered2.sort_values(
                                                        by=["_ì§€ì‹œì¼ì_sort", "ì§€ì‹œë²ˆí˜¸"],
                                                        ascending=[False, True],
                                                    ).drop(columns=["_ì§€ì‹œì¼ì_sort"])
                                                else:
                                                    df_job_filtered2 = df_job_filtered2.sort_values(
                                                        by=["ì§€ì‹œë²ˆí˜¸"]
                                                    )

                                                st.markdown(
                                                    "#### 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê¸°ì¤€ ìˆ˜ì£¼ â†’ ì‘ì—…ì§€ì‹œ ë§¤í•‘"
                                                )

                                                disp_cols2 = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                                if "ì§€ì‹œì¼ì" in df_job_filtered2.columns:
                                                    disp_cols2.append("ì§€ì‹œì¼ì")
                                                disp_cols2.append("í’ˆëª…")

                                                st.dataframe(
                                                    df_job_filtered2[disp_cols2],
                                                    use_container_width=True,
                                                )
                                            else:
                                                st.info(
                                                    "í•´ë‹¹ ìˆ˜ì£¼ë²ˆí˜¸ë¡œ ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì§€ì‹œë²ˆí˜¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                                )

                                    # ì´ ê²½ë¡œì—ì„œëŠ” ì•„ë˜ ì¼ë°˜ df_show ë¡œì§ì„ íƒ€ì§€ ì•Šë„ë¡ ë¹„ì›Œë‘ 
                                    df_show = pd.DataFrame()

                    # ğŸ” BOM 2ì°¨ ìƒìœ„ í’ˆëª©ì½”ë“œ ê²½ë¡œë¥¼ ì“°ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ
                    #    ê¸°ì¡´ ë‚ ì§œ ë²”ìœ„(1ê°œì›”/1ë…„/ê³¼ê±°) ë¡œì§ ìˆ˜í–‰
                    if not used_bom2_flow:
                        if df_suju_hit.empty:
                            st.warning("í•´ë‹¹ í’ˆëª©ì½”ë“œë¡œ ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ ê²€ìƒ‰ëœ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            df_show = pd.DataFrame()
                        else:
                            # === ê²€ìƒ‰ ë²”ìœ„ ì„¤ì • ===
                            one_month_after = today + timedelta(days=30)
                            one_year_after = today + timedelta(days=365)

                            # 1) ì˜¤ëŠ˜ â†’ 1ê°œì›” ì´ë‚´
                            df_1m = df_suju_hit[
                                df_suju_hit[suju_due_col].between(today, one_month_after)
                            ].copy()

                            if not df_1m.empty:
                                st.success("ì˜¤ëŠ˜ ê¸°ì¤€ 1ê°œì›” ì´ë‚´ ìˆ˜ì£¼ ë°œê²¬!")
                                df_show = df_1m
                            else:
                                # 2) ì˜¤ëŠ˜ â†’ 1ë…„ ì´ë‚´
                                df_1y = df_suju_hit[
                                    df_suju_hit[suju_due_col].between(
                                        today, one_year_after
                                    )
                                ].copy()

                                if not df_1y.empty:
                                    st.info("1ê°œì›” ì´ë‚´ëŠ” ì—†ê³ , 1ë…„ ì´ë‚´ ìˆ˜ì£¼ê°€ ìˆìŠµë‹ˆë‹¤.")
                                    df_1y.sort_values(
                                        by=suju_due_col, ascending=False, inplace=True
                                    )
                                    df_show = df_1y
                                else:
                                    # 3) ê³¼ê±° íƒìƒ‰: 3ê°œì›”Â·6ê°œì›”Â·12ê°œì›”
                                    back_3m = today - timedelta(days=90)
                                    back_6m = today - timedelta(days=180)
                                    back_12m = today - timedelta(days=365)

                                    df_back3 = df_suju_hit[
                                        df_suju_hit[suju_due_col].between(
                                            back_3m, today
                                        )
                                    ].copy()

                                    if not df_back3.empty:
                                        st.info(
                                            "1ë…„ ì´ë‚´ ìˆ˜ì£¼ëŠ” ì—†ì–´ì„œ, ê³¼ê±° 3ê°œì›” ìˆ˜ì£¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
                                        )
                                        df_back3.sort_values(
                                            by=suju_due_col,
                                            ascending=False,
                                            inplace=True,
                                        )
                                        df_show = df_back3
                                    else:
                                        df_back6 = df_suju_hit[
                                            df_suju_hit[suju_due_col].between(
                                                back_6m, today
                                            )
                                        ].copy()

                                        if not df_back6.empty:
                                            st.info(
                                                "3ê°œì›” ì´ë‚´ ì—†ìŒ â†’ ê³¼ê±° 6ê°œì›” ìˆ˜ì£¼ í‘œì‹œ."
                                            )
                                            df_back6.sort_values(
                                                by=suju_due_col,
                                                ascending=False,
                                                inplace=True,
                                            )
                                            df_show = df_back6
                                        else:
                                            df_back12 = df_suju_hit[
                                                df_suju_hit[suju_due_col].between(
                                                    back_12m, today
                                                )
                                            ].copy()

                                            if not df_back12.empty:
                                                st.info(
                                                    "6ê°œì›” ì´ë‚´ ì—†ìŒ â†’ ê³¼ê±° 12ê°œì›” ìˆ˜ì£¼ í‘œì‹œ."
                                                )
                                                df_back12.sort_values(
                                                    by=suju_due_col,
                                                    ascending=False,
                                                    inplace=True,
                                                )
                                                df_show = df_back12
                                            else:
                                                st.warning(
                                                    "ê³¼ê±° 12ê°œì›”ê¹Œì§€ë„ í•´ë‹¹ í’ˆëª©ì½”ë“œì˜ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                                                )
                                                df_show = pd.DataFrame()



                        # ===== ê²°ê³¼ í‘œì‹œ =====
                        if not df_show.empty:
                            display_cols = []
                            for c in [
                                suju_part_col,
                                "í’ˆëª…",
                                "ìˆ˜ì£¼ë²ˆí˜¸",
                                suju_due_col,
                                "ìˆ˜ëŸ‰",
                                "ë§¤ì¶œì²˜",
                            ]:
                                if c in df_show.columns:
                                    display_cols.append(c)

                            st.dataframe(
                                df_show[display_cols],
                                use_container_width=True,
                            )

                        # =======================================================
                        # ğŸ” ìˆ˜ì£¼ë²ˆí˜¸ â†’ ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì§€ì‹œë²ˆí˜¸ / í’ˆëª… ê°€ì ¸ì˜¤ê¸°
                        # =======================================================
                        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_show.columns:
                            # 1) ìˆ˜ì£¼ ì°¾ê¸° ê²°ê³¼ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸ ëª©ë¡ ì¶”ì¶œ
                            suju_values = (
                                df_show["ìˆ˜ì£¼ë²ˆí˜¸"]
                                .dropna()
                                .astype(str)
                                .unique()
                                .tolist()
                            )

                            # 2) ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ì»¬ëŸ¼ ì°¾ê¸°
                            job_suju_col = pick_col(
                                df_job_raw, "A", ["ìˆ˜ì£¼ë²ˆí˜¸"]
                            )
                            job_jisi_col = pick_col(
                                df_job_raw, "B", ["ì§€ì‹œë²ˆí˜¸"]
                            )
                            job_date_col = pick_col(
                                df_job_raw, "I", ["ì§€ì‹œì¼ì", "ì‘ì§€ì¼ì"]
                            )
                            job_name_col = pick_col(
                                df_job_raw, "L", ["í’ˆëª…", "ì™„ì„±í’ˆëª…"]
                            )

                            if not all(
                                [job_suju_col, job_jisi_col, job_name_col]
                            ):
                                st.info(
                                    "ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸(A), ì§€ì‹œë²ˆí˜¸(B), í’ˆëª…(L)ì„ ëª¨ë‘ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                )
                            else:
                                # 3) í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ê°€ì ¸ì˜¤ê¸°
                                use_cols = [job_suju_col, job_jisi_col]
                                if job_date_col:
                                    use_cols.append(job_date_col)
                                use_cols.append(job_name_col)

                                df_job_map = df_job_raw[use_cols].copy()
                                
                                # ì»¬ëŸ¼ëª… í†µì¼
                                new_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                if job_date_col:
                                    new_cols.append("ì§€ì‹œì¼ì")
                                new_cols.append("í’ˆëª…")
                                df_job_map.columns = new_cols

                                # ğŸ”¥ í•„ìˆ˜: ë¬¸ìì—´ ë¹„êµë¥¼ ìœ„í•œ ì»¬ëŸ¼ ìƒì„±
                                df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"] = df_job_map["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str)

                                # 4) ìˆ˜ì£¼ì°¾ê¸°ì—ì„œ ë‚˜ì˜¨ ìˆ˜ì£¼ë²ˆí˜¸ ëª©ë¡ê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ í•„í„°ë§
                                df_job_filtered = df_job_map[
                                    df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"].isin(
                                        suju_values
                                    )
                                ].drop(columns=["ìˆ˜ì£¼ë²ˆí˜¸_str"])

                                if df_job_filtered.empty:
                                    ...
                                else:
                                    # ì¤‘ë³µ ì œê±°
                                    subset_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆëª…"]
                                    if "ì§€ì‹œì¼ì" in df_job_filtered.columns:
                                        subset_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œì¼ì", "í’ˆëª…"]

                                    df_job_filtered = df_job_filtered.drop_duplicates(
                                        subset=subset_cols
                                    )

                                    # ğŸ”½ ì§€ì‹œì¼ìê°€ ìµœê·¼ì¼ìˆ˜ë¡ ìœ„ìª½ì— ì˜¤ë„ë¡ ì •ë ¬
                                    if "ì§€ì‹œì¼ì" in df_job_filtered.columns:
                                        df_job_filtered["_ì§€ì‹œì¼ì_sort"] = pd.to_datetime(
                                            df_job_filtered["ì§€ì‹œì¼ì"], errors="coerce"
                                        )
                                        df_job_filtered = df_job_filtered.sort_values(
                                            by=["_ì§€ì‹œì¼ì_sort", "ì§€ì‹œë²ˆí˜¸"],
                                            ascending=[False, True],
                                        ).drop(columns=["_ì§€ì‹œì¼ì_sort"])
                                    else:
                                        # ì§€ì‹œì¼ìê°€ ì—†ìœ¼ë©´ ì§€ì‹œë²ˆí˜¸ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ
                                        df_job_filtered = df_job_filtered.sort_values(
                                            by=["ì§€ì‹œë²ˆí˜¸"]
                                        )

                                    st.markdown(
                                        "#### ìˆ˜ì£¼ë²ˆí˜¸ë³„ ì§€ì‹œë²ˆí˜¸ / í’ˆëª… (ì‘ì—…ì§€ì‹œ ê¸°ì¤€)"
                                    )

                                    display_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"]
                                    if "ì§€ì‹œì¼ì" in df_job_filtered.columns:
                                        display_cols.append("ì§€ì‹œì¼ì")
                                    display_cols.append("í’ˆëª…")

                                    st.dataframe(
                                        df_job_filtered[display_cols],
                                        use_container_width=True,
                                    )


# ============================================================
# â†©ï¸ 4. í™˜ì… ê´€ë¦¬ í™”ë©´ (+ í™˜ì… ì˜ˆìƒì¬ê³ )
# ============================================================
if menu == "â†©ï¸ í™˜ì… ê´€ë¦¬":
    st.subheader("â†©ï¸ í™˜ì… ê´€ë¦¬")

    # í™˜ì… ê´€ë¦¬ í…Œì´ë¸” êµ¬ì¡° (ë‚´ë¶€ ê³„ì‚°ìš©)
    return_cols = [
        "ìˆ˜ì£¼ë²ˆí˜¸",
        "ì§€ì‹œë²ˆí˜¸",
        "ìƒì‚°ê³µì •",
        "ìƒì‚°ì‹œì‘ì¼",
        "ìƒì‚°ì¢…ë£Œì¼",
        "ì¢…ë£Œì¡°ê±´",
        "í™˜ì…ì¼",
        "í™˜ì…ì£¼ì°¨",
        "ì™„ì„±í’ˆë²ˆ",
        "ì œí’ˆëª…",  # ì™„ì„±í’ˆëª…
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ERPì¬ê³ ",
        "ì‹¤ì¬ê³ ì˜ˆìƒ",
        "í™˜ì…ê²°ì •ìˆ˜",
        "ì°¨ì´",
        "ë¹„ê³ ",
    ]
    df_return = ensure_session_df("í™˜ì…ê´€ë¦¬", return_cols)
    df_full = ensure_session_df("í™˜ì…ì¬ê³ ì˜ˆìƒ", CSV_COLS)

    # ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)
    st.markdown("### ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)")

    search_keyword = st.text_input(
        "ì œí’ˆëª…ìœ¼ë¡œ ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ Eì—´, ë¶€ë¶„ ì¼ì¹˜)",
        key="return_search_product",
        placeholder="ì˜ˆ: ì•°í”Œ, í¬ë¦¼, ë§ˆìŠ¤í¬íŒ© ë“±",
    )

    if search_keyword:
        df_in_search = df_in_raw.copy()

        # ìš”ì²­ë‚ ì§œ(Kì—´), ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ ì°¾ê¸°
        in_req_date_col = pick_col(df_in_search, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
        in_prod_name_col = pick_col(df_in_search, "E", ["ì œí’ˆëª…", "í’ˆëª…"])

        if in_req_date_col is None or in_prod_name_col is None:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ë˜ëŠ” ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ë‚ ì§œí˜• ë³€í™˜
            df_in_search[in_req_date_col] = pd.to_datetime(
                df_in_search[in_req_date_col], errors="coerce"
            ).dt.date

            today = date.today()
            start_date = today - timedelta(days=30)  # ìµœê·¼ 1ê°œì›”

            # ë‚ ì§œ í•„í„°: í˜„ì¬ë¡œë¶€í„° 1ë‹¬ ì´ë‚´
            mask_date = df_in_search[in_req_date_col].between(start_date, today)

            # ì œí’ˆëª… ë¶€ë¶„ ì¼ì¹˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            mask_name = df_in_search[in_prod_name_col].astype(str).str.contains(
                search_keyword, case=False, na=False
            )

            df_hit = df_in_search[mask_date & mask_name].copy()

            if df_hit.empty:
                st.info("ìµœê·¼ 1ê°œì›” ì´ë‚´ì— í•´ë‹¹ ì œí’ˆëª…ì´ í¬í•¨ëœ ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¶”ê°€ë¡œ ë³´ì—¬ì¤„ ì»¬ëŸ¼ë“¤: ìˆ˜ì£¼ë²ˆí˜¸(B), ì§€ì‹œë²ˆí˜¸(C), í’ˆë²ˆ(M)
                in_suju_col = pick_col(df_hit, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
                in_jisi_col = pick_col(df_hit, "C", ["ì§€ì‹œë²ˆí˜¸"])
                in_part_col = pick_col(df_hit, "M", ["í’ˆë²ˆ"])

                show_cols = []
                for c in [
                    in_req_date_col,
                    in_suju_col,
                    in_jisi_col,
                    in_prod_name_col,
                    in_part_col,
                ]:
                    if c and c in df_hit.columns:
                        show_cols.append(c)

                df_show = df_hit[show_cols].copy()

                # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ì •ë¦¬
                rename_map = {}
                rename_map[in_req_date_col] = "ìš”ì²­ë‚ ì§œ"
                if in_suju_col:
                    rename_map[in_suju_col] = "ìˆ˜ì£¼ë²ˆí˜¸"
                if in_jisi_col:
                    rename_map[in_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
                if in_prod_name_col:
                    rename_map[in_prod_name_col] = "ì œí’ˆëª…"
                if in_part_col:
                    rename_map[in_part_col] = "í’ˆë²ˆ"

                df_show.rename(columns=rename_map, inplace=True)

                # í’ˆë²ˆ ì œê±° (ê²€ìƒ‰ìš©ì—ì„œë§Œ í‘œì‹œí–ˆë‹¤ ì§€ìš°ê¸°)
                if "í’ˆë²ˆ" in df_show.columns:
                    df_show = df_show.drop(columns=["í’ˆë²ˆ"])

                # ìš”ì²­ë‚ ì§œëŠ” ì¤‘ë³µ ì œê±° ê¸°ì¤€ ì œì™¸, ìˆ˜ì£¼ë²ˆí˜¸+ì§€ì‹œë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ìœ ì¼í•˜ê²Œ
                uniq_cols = [c for c in ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"] if c in df_show.columns]
                df_show = df_show.drop_duplicates(subset=uniq_cols)

                st.dataframe(df_show, use_container_width=True)

                # ğŸ”½ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒí•˜ë©´ ì•„ë˜ ìˆ˜ì£¼ë²ˆí˜¸/ì§€ì‹œë²ˆí˜¸ ìë™ ì±„ìš°ê¸°
                if "ìˆ˜ì£¼ë²ˆí˜¸" in df_show.columns:
                    df_select = df_show.reset_index(drop=True)

                    option_labels = []
                    option_map = {}

                    for _, row in df_select.iterrows():
                        suju_val = str(row.get("ìˆ˜ì£¼ë²ˆí˜¸", ""))
                        jisi_val = str(row.get("ì§€ì‹œë²ˆí˜¸", ""))
                        prod_val = str(row.get("ì œí’ˆëª…", ""))

                        label = f"{prod_val} | ìˆ˜ì£¼:{suju_val}"
                        if jisi_val:
                            label += f" / ì§€ì‹œ:{jisi_val}"

                        option_labels.append(label)
                        option_map[label] = (suju_val, jisi_val)

                    selected_label = st.selectbox(
                        "ğŸ‘‡ ì´ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ë©´ ì•„ë˜ ìˆ˜ì£¼ë²ˆí˜¸/ì§€ì‹œë²ˆí˜¸ê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.",
                        ["ì„ íƒ ì•ˆ í•¨"] + option_labels,
                        key="return_suju_autofill",
                    )

                    if selected_label != "ì„ íƒ ì•ˆ í•¨":
                        sel_suju, sel_jisi = option_map[selected_label]
                        st.session_state["return_suju_no"] = sel_suju
                        if sel_jisi:
                            st.session_state["return_jisi"] = sel_jisi

    # ----- ì…ë ¥ 1ì¤„ (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, ìƒì‚°ê³µì •, ì¢…ë£Œì¡°ê±´) -----
    col_suju, col_jisi, col_proc, col_reason = st.columns(4)
    with col_suju:
        suju_no = st.text_input("ìˆ˜ì£¼ë²ˆí˜¸", key="return_suju_no")
    with col_jisi:
        selected_jisi = None  # ì•„ë˜ì—ì„œ selectboxë¡œ ì±„ì›€
    with col_proc:
        process_options = [
            "4ì¸µ ë•ìš©",
            "4ì¸µ ë¡œí„°ë¦¬",
            "4ì¸µ ë¸”ë¦¬ìŠ¤í„°",
            "5ì¸µ ë•ìš©",
            "5ì¸µ ê¸°ì´ˆ",
            "6ì¸µ ìŠ¤í‹±",
            "6ì¸µ íŒŒìš°ì¹˜",
            "6ì¸µ ìŠ¤í‚¨íŒ©",
        ]
        process_value = st.selectbox("ìƒì‚°ê³µì •", process_options, key="return_process")
    with col_reason:
        finish_reason = st.text_input("ì¢…ë£Œì¡°ê±´", key="return_finish_reason")

    # ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ë°˜ ì§€ì‹œë²ˆí˜¸/ì™„ì„±í’ˆë²ˆ í›„ë³´ ì°¾ê¸°
    jisi_options = []
    finished_part_selected = None

    # ğŸ”¹ ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì˜ ì‘ì—…ì¥ ì»¬ëŸ¼(Xì—´) ì°¾ê¸°
    job_wc_col = pick_col(df_job_raw, "X", ["ì‘ì—…ì¥"])

    if suju_no:
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_job_raw.columns:
            # 1ì°¨: ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€ í•„í„°
            df_job_suju = df_job_raw[df_job_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()

            # ğŸ”¹ 2ì°¨: ì‘ì—…ì¥ WC501~WC504 ì¡°ê±´ ì¶”ê°€
            if job_wc_col and job_wc_col in df_job_suju.columns:
                df_job_suju = df_job_suju[
                    df_job_suju[job_wc_col].astype(str).isin(
                        ["WC501", "WC502", "WC503", "WC504"]
                    )
                ]

            # ğŸ‘‰ í•„í„° í›„ ì•„ë¬´ ê²ƒë„ ì—†ìœ¼ë©´ ì•ˆë‚´
            if df_job_suju.empty:
                st.warning("í•´ë‹¹ ìˆ˜ì£¼ë²ˆí˜¸ì— ëŒ€í•´ ì‘ì—…ì¥ WC401~WC404 ì‘ì—…ì§€ì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì™„ì„±í’ˆë²ˆ í›„ë³´
                finished_parts = (
                    df_job_suju["í’ˆë²ˆ"].dropna().unique().tolist()
                    if "í’ˆë²ˆ" in df_job_suju.columns
                    else []
                )

                if len(finished_parts) > 1:
                    finished_part_selected = st.selectbox(
                        "ì™„ì„±í’ˆë²ˆ", finished_parts, key="return_finished_part"
                    )
                    df_job_suju = df_job_suju[
                        df_job_suju["í’ˆë²ˆ"] == finished_part_selected
                    ]
                elif len(finished_parts) == 1:
                    finished_part_selected = finished_parts[0]

                # ì§€ì‹œë²ˆí˜¸ í›„ë³´
                if "ì§€ì‹œë²ˆí˜¸" in df_job_suju.columns:
                    jisi_options = (
                        df_job_suju["ì§€ì‹œë²ˆí˜¸"].dropna().unique().tolist()
                    )
                else:
                    st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ì§€ì‹œë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ìˆ˜ì£¼ë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")


    # ì§€ì‹œë²ˆí˜¸ ì„ íƒ (ìˆ˜ì£¼ë²ˆí˜¸ ì…ë ¥ í›„)
    if jisi_options:
        selected_jisi = col_jisi.selectbox(
            "ì§€ì‹œë²ˆí˜¸", jisi_options, key="return_jisi"
        )
    else:
        with col_jisi:
            st.write("ì§€ì‹œë²ˆí˜¸: ì„ íƒ ì—†ìŒ")

    # ----- ìƒì‚° ì‹œì‘/ì¢…ë£Œì¼ -----
    production_start_date = None
    production_end_date = None
    if (
        suju_no
        and "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        and "ìƒì‚°ì¼ì" in df_result_raw.columns
    ):
        df_res_suju = df_result_raw[df_result_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()
        df_res_suju["ìƒì‚°ì¼ì"] = pd.to_datetime(
            df_res_suju["ìƒì‚°ì¼ì"], errors="coerce"
        )
        if not df_res_suju["ìƒì‚°ì¼ì"].isna().all():
            production_start_date = df_res_suju["ìƒì‚°ì¼ì"].min().date()
            production_end_date = df_res_suju["ìƒì‚°ì¼ì"].max().date()

    st.write(f"ìƒì‚°ì‹œì‘ì¼: {production_start_date or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ìƒì‚°ì¢…ë£Œì¼: {production_end_date or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- í™˜ì…ì¼/í™˜ì…ì£¼ì°¨ -----
    return_date = date.today()
    return_week = get_week_of_month(return_date)
    st.write(f"í™˜ì…ì¼: {return_date}")
    st.write(f"í™˜ì…ì£¼ì°¨: {return_week}")

    # ----- ì™„ì„±í’ˆë²ˆ / ì™„ì„±í’ˆëª… (BOMì—ì„œ í’ˆëª… ê°€ì ¸ì˜¤ê¸°) -----
    finished_part = finished_part_selected
    finished_name = None

    # 1ì°¨: ì§€ì‹œë²ˆí˜¸ì—ì„œ ì™„ì„±í’ˆë²ˆ ìœ ì¶” (ì—†ì„ ë•Œë§Œ)
    if not finished_part and selected_jisi and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns:
        df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
        if not df_job_jisi.empty and "í’ˆë²ˆ" in df_job_jisi.columns:
            finished_part = df_job_jisi["í’ˆë²ˆ"].iloc[0]

    # BOMì—ì„œ ì™„ì„±í’ˆëª… ì°¾ê¸° (í’ˆëª©ì½”ë“œ=Aì—´, í’ˆëª…=Bì—´)
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        name_col = (
            "í’ˆëª…"
            if "í’ˆëª…" in bom_cols
            else (bom_cols[1] if len(bom_cols) > 1 else bom_cols[0])
        )

        df_bom_match = df_bom_raw[df_bom_raw[item_col] == finished_part]
        if not df_bom_match.empty:
            finished_name = df_bom_match[name_col].iloc[0]
        else:
            if (
                selected_jisi
                and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
                and "í’ˆëª…" in df_job_raw.columns
            ):
                df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
                if not df_job_jisi.empty:
                    finished_name = df_job_jisi["í’ˆëª…"].iloc[0]

    st.write(f"ì™„ì„±í’ˆë²ˆ: {finished_part or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ì™„ì„±í’ˆëª…: {finished_name or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- BOM ìì¬ ëª©ë¡ -----
    bom_component_df = pd.DataFrame()
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        bom_part_cols = [c for c in bom_cols if "í’ˆë²ˆ" in c]
        bom_name_cols = [c for c in bom_cols if "í’ˆëª…" in c]

        bom_component_col2 = (
            bom_part_cols[1]
            if len(bom_part_cols) >= 2
            else (bom_part_cols[0] if bom_part_cols else None)
        )
        bom_name_col2 = (
            bom_name_cols[1]
            if len(bom_name_cols) >= 2
            else (bom_name_cols[0] if len(bom_name_cols) > 0 else None)
        )

        df_bom_finished = df_bom_raw[df_bom_raw[item_col] == finished_part].copy()
        if df_bom_finished.empty:
            st.warning("BOMì—ì„œ í•´ë‹¹ ì™„ì„±í’ˆë²ˆ(í’ˆëª©ì½”ë“œ)ì„ ì‚¬ìš©í•˜ëŠ” ìì¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            subset_cols = []
            if bom_component_col2 and bom_component_col2 in df_bom_finished.columns:
                subset_cols.append(bom_component_col2)
            if bom_name_col2 and bom_name_col2 in df_bom_finished.columns:
                subset_cols.append(bom_name_col2)
            if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_finished.columns:
                subset_cols.append("ë‹¨ìœ„ìˆ˜ëŸ‰")

            if subset_cols:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates(subset=subset_cols)
            else:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates()

            bom_component_df = pd.DataFrame(
                {
                    "ì„ íƒ": True,
                    "ì™„ì„±í’ˆë²ˆ": df_bom_fin_uniq[item_col],
                    "í’ˆë²ˆ": df_bom_fin_uniq[bom_component_col2]
                    if bom_component_col2 in df_bom_fin_uniq.columns
                    else "",
                    "í’ˆëª…": df_bom_fin_uniq[bom_name_col2]
                    if bom_name_col2 in df_bom_fin_uniq.columns
                    else "",
                    "ë‹¨ìœ„ìˆ˜ëŸ‰": df_bom_fin_uniq["ë‹¨ìœ„ìˆ˜ëŸ‰"]
                    if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_fin_uniq.columns
                    else "",
                }
            )

            st.markdown("BOM ìì¬ ëª©ë¡ì—ì„œ í™˜ì… ëŒ€ìƒ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            bom_component_df = st.data_editor(
                bom_component_df,
                use_container_width=True,
                num_rows="dynamic",
                key="bom_component_editor",
            )

            # ===============================
            # ğŸ”˜ (ì—¬ê¸°!) í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° / ì´ˆê¸°í™” ë²„íŠ¼ (ê°€ìš´ë° ì •ë ¬)
            #  â†’ BOM ìì¬ í‘œê°€ ëœ¬ ë’¤ì—ë§Œ ë³´ì´ë„ë¡
            # ===============================
            col_left, col_center, col_right = st.columns([1, 2, 1])

            with col_center:
                col_btn1, col_btn2 = st.columns([1, 1])

                with col_btn1:
                    load_clicked = st.button("âœ… í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", key="btn_return_load")

                with col_btn2:
                    clear_clicked = st.button(
                        "ğŸ§¹ í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™”", key="btn_clear_expect"
                    )

            # ğŸ” í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰ ë¡œì§
            if load_clicked:
                if not suju_no:
                    st.error("ìˆ˜ì£¼ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif not selected_jisi:
                    st.error("ì§€ì‹œë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                elif bom_component_df.empty:
                    st.error("BOM ìì¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    selected_rows = bom_component_df[
                        bom_component_df["ì„ íƒ"] == True
                    ].copy()
                    if selected_rows.empty:
                        st.warning("ì„ íƒëœ ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        new_rows = []
                        for _, row in selected_rows.iterrows():
                            part = row["í’ˆë²ˆ"]
                            name = row["í’ˆëª…"]
                            unit = row["ë‹¨ìœ„ìˆ˜ëŸ‰"]

                            new_rows.append(
                                {
                                    "ìˆ˜ì£¼ë²ˆí˜¸": suju_no,
                                    "ì§€ì‹œë²ˆí˜¸": selected_jisi,
                                    "ìƒì‚°ê³µì •": process_value,
                                    "ìƒì‚°ì‹œì‘ì¼": production_start_date,
                                    "ìƒì‚°ì¢…ë£Œì¼": production_end_date,
                                    "ì¢…ë£Œì¡°ê±´": finish_reason,
                                    "í™˜ì…ì¼": return_date,
                                    "í™˜ì…ì£¼ì°¨": return_week,
                                    "ì™„ì„±í’ˆë²ˆ": finished_part,
                                    "ì œí’ˆëª…": finished_name,
                                    "í’ˆë²ˆ": part,
                                    "í’ˆëª…": name,
                                    "ë‹¨ìœ„ìˆ˜ëŸ‰": unit,
                                    "ERPì¬ê³ ": None,
                                    "ì‹¤ì¬ê³ ì˜ˆìƒ": None,
                                    "í™˜ì…ê²°ì •ìˆ˜": None,
                                    "ì°¨ì´": None,
                                    "ë¹„ê³ ": "",
                                }
                            )

                        df_new = pd.DataFrame(new_rows)

                        # âœ… ì´ì „ í™˜ì…ê´€ë¦¬ ë‚´ìš©ì€ ë²„ë¦¬ê³ ,
                        #    ì´ë²ˆì— ì„ íƒí•œ ìì¬(df_new)ë§Œ í™˜ì…ê´€ë¦¬ë¡œ ì‚¬ìš©
                        df_return = df_new.copy()
                        st.session_state["í™˜ì…ê´€ë¦¬"] = df_return


                        # ì§‘ê³„ ìµœì´ˆ ìƒì„±
                        if st.session_state["aggregates"] is None:
                            st.session_state["aggregates"] = build_aggregates(
                                df_in_raw,
                                df_job_raw,
                                df_result_raw,
                                df_defect_raw,
                                df_stock_raw,
                            )

                        aggs = st.session_state["aggregates"]

                        # ì˜ˆìƒì¬ê³  ê³„ì‚°
                        df_full = recalc_return_expectation(df_return, aggs)
                        st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

                        # ERPì¬ê³  ë§¤ì¹­
                        stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])
                        stock_qty_col = (
                            "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"
                            if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in df_stock_raw.columns
                            else pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])
                        )

                        if stock_part_col and stock_qty_col:
                            stock_map = dict(
                                zip(
                                    df_stock_raw[stock_part_col].astype(str),
                                    df_stock_raw[stock_qty_col].apply(safe_num),
                                )
                            )
                            df_full["ERPì¬ê³ "] = (
                                df_full["í’ˆë²ˆ"].astype(str).map(stock_map).fillna(0)
                            )
                        else:
                            st.warning(
                                "ì¬ê³  ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ ë˜ëŠ” ì‹¤ì¬ê³ ìˆ˜ëŸ‰ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            )

                        st.success(
                            f"ì„ íƒëœ ìì¬ {len(df_new)}ê°œì— ëŒ€í•´ í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤."
                        )

            # ğŸ§¹ í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™” ì‹¤í–‰ ë¡œì§
            if clear_clicked:
                # âœ… í™˜ì…ê´€ë¦¬ë„ í•¨ê»˜ ì´ˆê¸°í™”
                st.session_state["í™˜ì…ê´€ë¦¬"] = pd.DataFrame(columns=return_cols)
                df_return = st.session_state["í™˜ì…ê´€ë¦¬"]

                st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = pd.DataFrame(columns=CSV_COLS)
                df_full = st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"]

                st.success("í™˜ì… ê´€ë¦¬ / í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ëª¨ë‘ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")


    # ----- í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„° í‘œì‹œ + CSV + PDF + ë¼ë²¨ -----
    st.markdown("### í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°")

    df_full = st.session_state.get(
        "í™˜ì…ì¬ê³ ì˜ˆìƒ", pd.DataFrame(columns=CSV_COLS)
    )

    if df_full.empty:
        st.write("í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹¤í–‰í•˜ë©´ ì´ê³³ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        # -------------------------------------------------
        # 0) df_full ê¸°ë³¸ ì„¸íŒ…
        # -------------------------------------------------
        df_full = df_full.copy().reset_index(drop=True)

        col_defaults = {
            "ì¶”ê°€ìˆ˜ì£¼": "",
            "ë¼ë²¨ì„ íƒ": False,
            "ê³µí†µë¶€ìì¬": False,
        }
        for col, default in col_defaults.items():
            if col not in df_full.columns:
                df_full[col] = default

        for bcol in ["ë¼ë²¨ì„ íƒ", "ê³µí†µë¶€ìì¬"]:
            df_full[bcol] = df_full[bcol].fillna(False).astype(bool)

        st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

        # -------------------------------------------------
        # 1) ì¶”ê°€ìˆ˜ì£¼ ìë™ ì±„ìš°ê¸°ìš© ê³µí†µ ì…ê³ ê¸°ê°„ ì„ íƒ
        # -------------------------------------------------
        today = date.today()
        default_start = today - timedelta(days=30)
        date_range = st.date_input(
            "ì¶”ê°€ìˆ˜ì£¼ ìë™ìƒì„±ìš© ì…ê³ ê¸°ê°„ ì„ íƒ",
            (default_start, today),
            key="extra_order_range",
        )
        if isinstance(date_range, (tuple, list)):
            start_date, end_date = date_range
        else:
            start_date = end_date = date_range

        # -------------------------------------------------
        # 2) data_editor ì—ì„œ ì“¸ í‘œì‹œ ì»¬ëŸ¼ êµ¬ì„±
        #    - ê³µí†µë¶€ìì¬: ë§¨ ì•
        #    - ìˆ˜ì£¼ë²ˆí˜¸ ë’¤ì— ì¶”ê°€ìˆ˜ì£¼
        #    - ë¼ë²¨ì„ íƒ: ì—¬ê¸°ì„œëŠ” ìˆ¨ê¹€
        # -------------------------------------------------
        base_cols = [c for c in VISIBLE_COLS if c in df_full.columns]

        display_cols = []

        # ë§¨ ì• ê³µí†µë¶€ìì¬
        display_cols.append("ê³µí†µë¶€ìì¬")

        # ìˆ˜ì£¼ë²ˆí˜¸ / ì¶”ê°€ìˆ˜ì£¼ / ë‚˜ë¨¸ì§€
        if "ìˆ˜ì£¼ë²ˆí˜¸" in base_cols:
            display_cols.append("ìˆ˜ì£¼ë²ˆí˜¸")
            display_cols.append("ì¶”ê°€ìˆ˜ì£¼")
            for c in base_cols:
                if c != "ìˆ˜ì£¼ë²ˆí˜¸":
                    display_cols.append(c)
        else:
            display_cols.extend(base_cols)
            if "ì¶”ê°€ìˆ˜ì£¼" not in display_cols:
                display_cols.append("ì¶”ê°€ìˆ˜ì£¼")

        # ë¼ë²¨ì„ íƒì€ ì—¬ê¸°ì„œëŠ” ìˆ¨ê¹€
        if "ë¼ë²¨ì„ íƒ" in display_cols:
            display_cols.remove("ë¼ë²¨ì„ íƒ")

        # í™”ë©´ìš© DF
        df_visible = pd.DataFrame(index=df_full.index)
        for c in display_cols:
            if c in df_full.columns:
                df_visible[c] = df_full[c]

        if "ê³µí†µë¶€ìì¬" in df_visible.columns:
            df_visible["ê³µí†µë¶€ìì¬"] = df_visible["ê³µí†µë¶€ìì¬"].fillna(False).astype(bool)
        if "ì¶”ê°€ìˆ˜ì£¼" in df_visible.columns:
            df_visible["ì¶”ê°€ìˆ˜ì£¼"] = df_visible["ì¶”ê°€ìˆ˜ì£¼"].astype(str)

        # -------------------------------------------------
        # 2-1) form ì•ˆì— data_editor + ë‘ ê°œ ë²„íŠ¼(ì €ì¥ / ìë™ì±„ìš°ê¸°)
        #      â†’ ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ëˆŒëŸ¬ë„ í•œ ë²ˆì— ì²˜ë¦¬
        # -------------------------------------------------
        with st.form("return_editor_form"):

            df_edit = st.data_editor(
                df_visible,
                use_container_width=True,
                num_rows="fixed",
                hide_index=True,
                column_config={
                    "ê³µí†µë¶€ìì¬": st.column_config.CheckboxColumn(
                        "ê³µí†µë¶€ìì¬",
                        default=False,
                    )
                },
                key="return_editor",
            )

            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                save_clicked = st.form_submit_button("ğŸ’¾ ê³µí†µë¶€ìì¬ / ì¶”ê°€ìˆ˜ì£¼ ì €ì¥")
            with col_btn2:
                auto_clicked = st.form_submit_button("ğŸ”„ ì…ê³ ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ ì¶”ê°€ìˆ˜ì£¼ ìë™ ì±„ìš°ê¸°")

        # ğŸ”¹ í˜¹ì‹œ ë°ì´í„°ê°€ ë¹„ì •ìƒ íƒ€ì…ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš° ë°©ì§€
        if not isinstance(df_edit, pd.DataFrame):
            df_edit = pd.DataFrame(df_edit)

        # -------------------------------------------------
        # 3) í¼ì´ ì œì¶œë˜ì—ˆì„ ë•Œ(df_edit â†’ df_full ë°˜ì˜)
        #    - ì €ì¥ ë²„íŠ¼ë§Œ ëˆŒë €ì„ ë•Œ: ì„¸ì…˜ì—ë§Œ ì €ì¥
        #    - ìë™ì±„ìš°ê¸° ë²„íŠ¼ ëˆŒë €ì„ ë•Œ: ì €ì¥ + ìë™ì±„ìš°ê¸° + ì¬ê³„ì‚°
        # -------------------------------------------------
        if save_clicked or auto_clicked:
            # 3-1) ì—ë””í„° ê°’ â†’ df_full ë°˜ì˜
            for col in ["ê³µí†µë¶€ìì¬", "ì¶”ê°€ìˆ˜ì£¼"]:
                if col in df_edit.columns:
                    df_full[col] = df_edit[col].reindex(df_full.index).values

            df_full["ê³µí†µë¶€ìì¬"] = df_full["ê³µí†µë¶€ìì¬"].fillna(False).astype(bool)
            st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

            # 3-2) ìë™ì±„ìš°ê¸° ë²„íŠ¼ì´ ëˆŒë¦° ê²½ìš°ì—ë§Œ ì¶”ê°€ ì‘ì—…
            if auto_clicked:
                df_full = df_full.copy()

                # ê³µí†µë¶€ìì¬ ì²´í¬ëœ í–‰ë§Œ ëŒ€ìƒ
                if "ê³µí†µë¶€ìì¬" in df_full.columns:
                    target_idx = df_full.index[df_full["ê³µí†µë¶€ìì¬"] == True]
                else:
                    target_idx = df_full.index

                # ---------- (1) ì¶”ê°€ìˆ˜ì£¼ ìë™ ì±„ìš°ê¸° ----------
                for idx in target_idx:
                    row = df_full.loc[idx]
                    part = row.get("í’ˆë²ˆ", None)
                    base_suju = row.get("ìˆ˜ì£¼ë²ˆí˜¸", None)

                    if part is None or pd.isna(part) or base_suju is None or pd.isna(base_suju):
                        continue

                    extra = get_extra_orders_by_period(
                        part_code=str(part),
                        base_suju=str(base_suju),
                        start_date=start_date,
                        end_date=end_date,
                    )

                    if not extra:
                        continue

                    current = str(row.get("ì¶”ê°€ìˆ˜ì£¼", "")).strip()
                    if current:
                        current_list = [s.strip() for s in current.split(",") if s.strip()]
                        extra_list   = [s.strip() for s in extra.split(",") if s.strip()]
                        merged = sorted(set(current_list + extra_list))
                        df_full.at[idx, "ì¶”ê°€ìˆ˜ì£¼"] = ", ".join(merged)
                    else:
                        df_full.at[idx, "ì¶”ê°€ìˆ˜ì£¼"] = extra

                # ---------- (2) ê³µí†µë¶€ìì¬ í–‰ ì¬ê³„ì‚° ----------
                aggs = st.session_state.get("aggregates", None)

                if aggs is None:
                    st.warning("ê³µí†µë¶€ìì¬ í•©ì‚°ì„ ìœ„í•´ì„œëŠ” ë¨¼ì € 'í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°' ë²„íŠ¼ìœ¼ë¡œ ì§‘ê³„ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    import re

                    def recompute_row_with_extra_orders(row):
                        part = str(row.get("í’ˆë²ˆ", "")).strip()
                        base_suju = str(row.get("ìˆ˜ì£¼ë²ˆí˜¸", "")).strip()
                        extra_text = str(row.get("ì¶”ê°€ìˆ˜ì£¼", "")).strip()

                        if not part or not base_suju:
                            return row

                        suju_list = [base_suju]
                        if extra_text:
                            extra_ids = [
                                s.strip()
                                for s in re.split(r"[ ,;/]+", extra_text)
                                if s.strip()
                            ]
                            suju_list.extend(extra_ids)

                        in_tbl = aggs.get("in")
                        res_tbl = aggs.get("result")

                        # 1) ì…ê³  í•©ê³„ (í’ˆë²ˆ + ìˆ˜ì£¼ë²ˆí˜¸)
                        erp_out = 0.0
                        real_in = safe_num(row.get("í˜„ì¥ì‹¤ë¬¼ì…ê³ ", 0))
                        if isinstance(in_tbl, pd.DataFrame) and not in_tbl.empty:
                            mask_in = (
                                in_tbl["í’ˆë²ˆ"].astype(str) == part
                            ) & (
                                in_tbl["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str).isin(suju_list)
                            )
                            tmp_in = in_tbl.loc[mask_in]
                            if not tmp_in.empty:
                                erp_out = tmp_in["ERPë¶ˆì¶œìˆ˜ëŸ‰"].apply(safe_num).sum()
                                real_in = tmp_in["í˜„ì¥ì‹¤ë¬¼ì…ê³ "].apply(safe_num).sum()

                        # 2) ìƒì‚°/ìƒ˜í”Œ í•©ê³„ (ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ì¤€)
                        prod = safe_num(row.get("ìƒì‚°ìˆ˜ëŸ‰", 0))
                        qc   = safe_num(row.get("QCìƒ˜í”Œ", 0))
                        etc  = safe_num(row.get("ê¸°íƒ€ìƒ˜í”Œ", 0))

                        if (
                            isinstance(res_tbl, pd.DataFrame)
                            and not res_tbl.empty
                            and "ìˆ˜ì£¼ë²ˆí˜¸" in res_tbl.columns
                        ):
                            mask_res = res_tbl["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str).isin(suju_list)
                            tmp_res = res_tbl.loc[mask_res]
                            if not tmp_res.empty:
                                if "ìƒì‚°ìˆ˜ëŸ‰" in tmp_res.columns:
                                    prod = tmp_res["ìƒì‚°ìˆ˜ëŸ‰"].apply(safe_num).sum()
                                if "QCìƒ˜í”Œ" in tmp_res.columns:
                                    qc = tmp_res["QCìƒ˜í”Œ"].apply(safe_num).sum()
                                if "ê¸°íƒ€ìƒ˜í”Œ" in tmp_res.columns:
                                    etc = tmp_res["ê¸°íƒ€ìƒ˜í”Œ"].apply(safe_num).sum()

                        orig_def = safe_num(row.get("ì›ë¶ˆ", 0))
                        proc_def = safe_num(row.get("ì‘ë¶ˆ", 0))
                        unit = safe_num(row.get("ë‹¨ìœ„ìˆ˜ëŸ‰", 0))

                        row["ERPë¶ˆì¶œìˆ˜ëŸ‰"] = erp_out
                        row["í˜„ì¥ì‹¤ë¬¼ì…ê³ "] = real_in
                        row["ìƒì‚°ìˆ˜ëŸ‰"] = prod
                        row["QCìƒ˜í”Œ"] = qc
                        row["ê¸°íƒ€ìƒ˜í”Œ"] = etc

                        row["ì˜ˆìƒì¬ê³ "] = (
                            real_in
                            - (prod + qc + etc) * unit
                            - orig_def
                            - proc_def
                        )

                        return row

                    df_full.loc[target_idx] = df_full.loc[target_idx].apply(
                        recompute_row_with_extra_orders, axis=1
                    )

                # ğŸ”š ìµœì¢…ê°’ ì €ì¥ í›„ ì¦‰ì‹œ ë‹¤ì‹œ ë Œë” â†’ 1ë²ˆ í´ë¦­ì—ë„ ê²°ê³¼ ë³´ì´ê²Œ
                st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full
                import streamlit as st  # ì´ë¯¸ ìœ„ì— ìˆìœ¼ë©´ ìƒëµ
                st.rerun()

            else:
                # ì €ì¥ ë²„íŠ¼ë§Œ ëˆŒë €ì„ ë•Œ
                st.success("ê³µí†µë¶€ìì¬ / ì¶”ê°€ìˆ˜ì£¼ ë³€ê²½ ë‚´ìš©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        # -------------------------------------------------
        # 4) ê³„ì‚° ê²°ê³¼ (ë³´ê¸°ìš©) - ì—¬ê¸°ì—ì„œë§Œ ë¼ë²¨ì„ íƒ ë…¸ì¶œ
        #    (ì—¬ê¸° ì•„ë˜ëŠ” ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì¨ë„ ë¨)
        # -------------------------------------------------
        df_full = st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"].copy()

        visible_cols = [c for c in VISIBLE_COLS if c in df_full.columns]
        result_cols = visible_cols.copy()
        if "ë¼ë²¨ì„ íƒ" in df_full.columns:
            result_cols.append("ë¼ë²¨ì„ íƒ")

        df_result_view = df_full[result_cols].copy()
        if "ë¼ë²¨ì„ íƒ" in df_result_view.columns:
            df_result_view["ë¼ë²¨ì„ íƒ"] = (
                df_result_view["ë¼ë²¨ì„ íƒ"].fillna(False).astype(bool)
            )

        st.markdown("#### ê³„ì‚° ê²°ê³¼ (ë³´ê¸°ìš©)")
        df_result_edit = st.data_editor(
            df_result_view,
            use_container_width=True,
            num_rows="fixed",
            hide_index=True,
            column_config={
                "ë¼ë²¨ì„ íƒ": st.column_config.CheckboxColumn("ë¼ë²¨ì„ íƒ", default=False)
            },
            key="return_result_editor",
        )

        if "ë¼ë²¨ì„ íƒ" in df_result_edit.columns:
            df_full["ë¼ë²¨ì„ íƒ"] = (
                df_result_edit["ë¼ë²¨ì„ íƒ"].fillna(False).astype(bool)
            )

        st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

        # ----------------------------------------------------
        # ğŸ”½ ì—¬ê¸°ë¶€í„°ëŠ” ê¸°ì¡´ CSV / PDF / ë¼ë²¨ ë¡œì§ (df_full ê¸°ë°˜)
        # ----------------------------------------------------
        
        # ---------- í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©) ----------
        merge_choices = {}
        work = df_full.copy()

        if "í’ˆë²ˆ" in work.columns and "ìˆ˜ì£¼ë²ˆí˜¸" in work.columns:
            suju_counts = work.groupby("í’ˆë²ˆ")["ìˆ˜ì£¼ë²ˆí˜¸"].nunique()
            dup_parts = suju_counts[suju_counts > 1].index.tolist()

            if dup_parts:
                st.markdown("#### í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©)")
                for part in dup_parts:
                    sub = work[work["í’ˆë²ˆ"] == part]
                    combos = sub[["ìˆ˜ì£¼ë²ˆí˜¸", "ì™„ì„±í’ˆëª…"]].drop_duplicates()

                    options = [
                        f"{str(row['ìˆ˜ì£¼ë²ˆí˜¸'])} {str(row['ì™„ì„±í’ˆëª…'])}"
                        for _, row in combos.iterrows()
                    ]
                    if not options:
                        continue

                    key = f"merge_choice_{part}"
                    default = st.session_state.get(key, options[0])
                    try:
                        default_index = options.index(default)
                    except ValueError:
                        default_index = 0

                    choice = st.selectbox(
                        f"í’ˆë²ˆ {part} - ìˆ˜ì£¼/ì™„ì„±í’ˆëª… ì„ íƒ",
                        options,
                        index=default_index,
                        key=key,
                    )
                    merge_choices[part] = choice

        # ---------- 1ë‹¨ê³„: (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ) ë™ì¼í•œ í–‰ ë¨¼ì € í†µí•© ----------
        key_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"]
        key_cols = [c for c in key_cols if c in work.columns]

        if key_cols:
            agg_dict_step1 = {}
            for col in work.columns:
                if col in key_cols:
                    continue
                if col in ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]:
                    agg_dict_step1[col] = "sum"
                else:
                    agg_dict_step1[col] = "first"

            work = work.groupby(key_cols, as_index=False).agg(agg_dict_step1)

        # ---------- 2ë‹¨ê³„: í’ˆë²ˆ ë‹¨ìœ„ë¡œ ìµœì¢… í†µí•© ----------
        result_rows = []

        header_cols = [
            "ìˆ˜ì£¼ë²ˆí˜¸",
            "ì§€ì‹œë²ˆí˜¸",
            "ìƒì‚°ê³µì •",
            "ìƒì‚°ì‹œì‘ì¼",
            "ìƒì‚°ì¢…ë£Œì¼",
            "ì¢…ë£Œì¡°ê±´",
            "í™˜ì…ì¼",
            "í™˜ì…ì£¼ì°¨",
            "ì™„ì„±í’ˆë²ˆ",
            "ì™„ì„±í’ˆëª…",
            "í’ˆëª…",
        ]

        sum_cols = [
            "ERPë¶ˆì¶œìˆ˜ëŸ‰",
            "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
            "ì§€ì‹œìˆ˜ëŸ‰",
            "ìƒì‚°ìˆ˜ëŸ‰",
            "QCìƒ˜í”Œ",
            "ê¸°íƒ€ìƒ˜í”Œ",
            "ì›ë¶ˆ",
            "ì‘ë¶ˆ",
            "ì˜ˆìƒì¬ê³ ",
        ]

        unit_col = "ë‹¨ìœ„ìˆ˜ëŸ‰"

        if "í’ˆë²ˆ" in work.columns:
            for part, part_df in work.groupby("í’ˆë²ˆ"):
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëŒ€í‘œ ìˆ˜ì£¼ë²ˆí˜¸ ì ìš©
                if part in merge_choices:
                    sel_suju, _, _ = merge_choices[part].partition(" ")
                    base = part_df[part_df["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str) == sel_suju]
                    header_row = base.iloc[0] if not base.empty else part_df.iloc[0]
                else:
                    header_row = part_df.iloc[0]

                row = {}
                row["í’ˆë²ˆ"] = part

                # í—¤ë” ê³„ì—´: ëŒ€í‘œ ìˆ˜ì£¼/ì§€ì‹œì˜ ê°’ ìœ ì§€
                for col in header_cols:
                    row[col] = header_row.get(col, None)

                # ìˆ˜ëŸ‰ ê³„ì—´: ëª¨ë‘ í•©ê³„
                for col in sum_cols:
                    if col in part_df.columns:
                        row[col] = part_df[col].apply(safe_num).sum()
                    else:
                        row[col] = 0

                # ë‹¨ìœ„ìˆ˜ëŸ‰: ëŒ€í‘œê°’ë§Œ
                row[unit_col] = safe_num(header_row.get(unit_col, 0))

                # ERPì¬ê³ : ê°™ì€ í’ˆë²ˆì´ë©´ ë™ì¼ â†’ ëŒ€í‘œê°’ë§Œ
                if "ERPì¬ê³ " in part_df.columns:
                    non_na = part_df["ERPì¬ê³ "].dropna()
                    row["ERPì¬ê³ "] = (
                        safe_num(non_na.iloc[0]) if not non_na.empty else 0
                    )
                else:
                    row["ERPì¬ê³ "] = 0

                result_rows.append(row)

        grouped = pd.DataFrame(result_rows) if result_rows else work.copy()

        # CSV ì»¬ëŸ¼ ì •ë¦¬
        for col in CSV_COLS:
            if col not in grouped.columns:
                grouped[col] = None

        csv_export_df = grouped[CSV_COLS].copy()

        # ---------- CSV ë°›ê¸° ë²„íŠ¼ ----------
        csv_data = csv_export_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ CSV ë°›ê¸°",
            data=csv_data,
            file_name="í™˜ì…_ì˜ˆìƒì¬ê³ _í†µí•©.csv",
            mime="text/csv",
        )

        # ğŸ”¹ PDF / ë¹„ê³ ì½”ë©˜íŠ¸ / ë°”ì½”ë“œ ë¼ë²¨ì„ ì¢ŒÂ·ìš° 2ì—´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë°°ì¹˜
        col_left, col_right = st.columns(2)

        # =========================
        # â¬…ï¸ ì™¼ìª½ ì»¬ëŸ¼: PDF + ì…ê³  ë¹„ê³  ì½”ë©˜íŠ¸
        # =========================
        with col_left:
            if REPORTLAB_AVAILABLE and not csv_export_df.empty:
                st.markdown("### ğŸ“‘ PDF ìƒë‹¨ ë©”ëª¨")

                pasted_text = st.text_area(
                    "PDF ë©”ëª¨",
                    height=100,
                    key="pdf_note_text",
                    placeholder="ì—¬ê¸°ì— ë©”ëª¨ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ì…ë ¥/ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”.",
                )

                pdf_bytes = generate_pdf(csv_export_df, pasted_text=pasted_text)

                st.download_button(
                    "ğŸ“„ PDF ë°›ê¸°",
                    data=pdf_bytes,
                    file_name="í™˜ì…_ì˜ˆìƒì¬ê³ .pdf",
                    mime="application/pdf",
                )
            elif not REPORTLAB_AVAILABLE:
                st.info("PDF ì €ì¥ ê¸°ëŠ¥ì„ ì“°ë ¤ë©´ `pip install reportlab` ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

            # ----- ì…ê³  ì‹œíŠ¸ ë¹„ê³  ì½”ë©˜íŠ¸ -----
            st.markdown("### ğŸ“ ì…ê³  ë¹„ê³  ì½”ë©˜íŠ¸")

            in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
            in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
            in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
            in_cmt_col = pick_col(df_in_raw, "V", ["ë¹„ê³ ", "ë¹„ê³ 2"])

            if in_suju_col and in_jisi_col and in_part_col and in_cmt_col:
                df_in_comment = df_in_raw[
                    [in_suju_col, in_jisi_col, in_part_col, in_cmt_col]
                ].copy()
                df_in_comment.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¹„ê³ 2"]
                df_in_comment = df_in_comment.dropna(subset=["ë¹„ê³ 2"])

                if not df_in_comment.empty:
                    df_comment_merge = df_full.merge(
                        df_in_comment,
                        how="left",
                        on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
                    )

                    df_comment_show = df_comment_merge.dropna(subset=["ë¹„ê³ 2"])[
                        ["í’ˆë²ˆ", "í’ˆëª…", "ë¹„ê³ 2"]
                    ].drop_duplicates()

                    if not df_comment_show.empty:
                        for _, row in df_comment_show.iterrows():
                            st.markdown(
                                f"- **{row['í’ˆë²ˆ']} / {row['í’ˆëª…']}** : {row['ë¹„ê³ 2']}"
                            )
                    else:
                        st.caption("í‘œì‹œí•  ë¹„ê³  ì½”ë©˜íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.caption("ì…ê³  ì‹œíŠ¸ì— ë¹„ê³  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.caption("ì…ê³  ì‹œíŠ¸ì—ì„œ ë¹„ê³  ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # =========================
        # â¡ï¸ ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: ë°”ì½”ë“œ ì…ë ¥ + ë¼ë²¨ PDF
        # =========================
        with col_right:
            st.markdown("### ğŸ· ë¶€ìì¬ë°˜ì…ë¼ë²¨ ì¶œë ¥")

            col_bc, col_unit = st.columns([3, 1])

            with col_bc:
                barcode_value = st.text_input(
                    "ë¶€ìì¬ë°˜ì…ìš”ì²­ë²ˆí˜¸",
                    placeholder="ì˜ˆ: B202511-00120001",
                    key="barcode_input",
                )

            with col_unit:
                unit_value = st.text_input(
                    "ë‹¨ìœ„ìˆ˜ëŸ‰",
                    key="unit_input",
                )

            pdf_labels = None
            download_disabled = True
            download_help = ""

            if "ë¼ë²¨ì„ íƒ" not in df_full.columns:
                st.error("ë¼ë²¨ì„ íƒ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            elif "í’ˆë²ˆ" not in df_full.columns:
                st.error("í’ˆë²ˆ ì»¬ëŸ¼ì´ ì—†ì–´ ë¼ë²¨ ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_parts = (
                    df_full.loc[df_full["ë¼ë²¨ì„ íƒ"] == True, "í’ˆë²ˆ"]
                    .astype(str)
                    .tolist()
                )

                required_cols = ["í’ˆëª…", "í’ˆë²ˆ", "í™˜ì…ì¼"]
                if not all(col in df_full.columns for col in required_cols):
                    st.error("ë¼ë²¨ ìƒì„±ì— í•„ìš”í•œ ì»¬ëŸ¼(í’ˆëª…, í’ˆë²ˆ, í™˜ì…ì¼)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    if not barcode_value:
                        download_help = "ë¶€ìì¬ë°˜ì…ìš”ì²­ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ë©´ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
                    elif not unit_value:
                        download_help = "ë‹¨ìœ„ìˆ˜ëŸ‰ì„ ì…ë ¥í•˜ë©´ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
                    elif not selected_parts:
                        download_help = "ë¼ë²¨ì„ ì¶œë ¥í•  ìì¬ë¥¼ í•œ ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”."
                    else:
                        df_labels = df_full[
                            df_full["í’ˆë²ˆ"].astype(str).isin(selected_parts)
                        ][required_cols].copy()

                        if df_labels.empty:
                            download_help = "ì„ íƒí•œ ìì¬ì—ì„œ ë¼ë²¨ì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                        else:
                            try:
                                pdf_labels = generate_label_pdf(
                                    df_labels,
                                    barcode_value,
                                    unit_value,
                                )
                                download_disabled = False
                            except Exception as e:
                                st.error(f"ë¼ë²¨ PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                                download_help = "ë¼ë²¨ PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

            if download_help:
                st.caption(download_help)

            st.download_button(
                "ğŸ· ì„ íƒí•œ ìì¬ ë°”ì½”ë“œ ë¼ë²¨ PDF ë§Œë“¤ê¸°",
                data=pdf_labels if pdf_labels is not None else b"",
                file_name="ë¶€ìì¬ë°˜ì…ë¼ë²¨.pdf",
                mime="application/pdf",
                disabled=download_disabled,
                key="btn_make_labels",
            )

# ============================================================
# ğŸ§© 5. ê³µí†µìì¬ íƒ­
# ============================================================
if menu == "ğŸ§© ê³µí†µìì¬":
    st.subheader("ğŸ§© ê³µí†µìì¬ í™•ì¸")

    search_part = st.text_input(
        "ì°¾ì„ ìì¬ í’ˆë²ˆì„ ì…ë ¥í•˜ì„¸ìš”",
        key="common_part_search",
        placeholder="ì˜ˆ: ìì¬ í’ˆë²ˆ ì…ë ¥"
    )

    if search_part:
        df_bom = df_bom_raw.copy()

        bom_item_col = pick_col(df_bom, "A", ["í’ˆëª©ì½”ë“œ"])
        bom_name_col = pick_col(df_bom, "B", ["í’ˆëª…"])
        bom_part_col = pick_col(df_bom, "C", ["í’ˆë²ˆ"])

        if not all([bom_item_col, bom_name_col, bom_part_col]):
            st.error("BOM ì‹œíŠ¸ì—ì„œ í’ˆëª©ì½”ë“œ(A), í’ˆëª…(B), í’ˆë²ˆ(C) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_bom_hit = df_bom[df_bom[bom_part_col] == search_part].copy()

            if df_bom_hit.empty:
                st.info("í•´ë‹¹ ìì¬ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” í’ˆëª©ì½”ë“œë¥¼ BOMì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                df_bom_hit = df_bom_hit[[bom_item_col, bom_name_col]].drop_duplicates()
                df_bom_hit.columns = ["ì™„ì„±í’ˆë²ˆ", "í’ˆëª…"]

                df_in = df_in_raw.copy()
                in_fin_col = pick_col(df_in, "D", ["ì™„ì„±í’ˆë²ˆ", "í’ˆëª©ì½”ë“œ", "í’ˆë²ˆ"])
                in_req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])

                if in_fin_col is None or in_req_date_col is None:
                    st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ì™„ì„±í’ˆë²ˆ(Dì—´) ë˜ëŠ” ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    df_in[in_req_date_col] = pd.to_datetime(
                        df_in[in_req_date_col], errors="coerce"
                    ).dt.date

                    today = date.today()
                    result_rows = []

                    for _, r in df_bom_hit.iterrows():
                        item_code = r["ì™„ì„±í’ˆë²ˆ"]
                        name = r["í’ˆëª…"]

                        sub = df_in[df_in[in_fin_col] == item_code].copy()
                        sub = sub.dropna(subset=[in_req_date_col])

                        if sub.empty:
                            last_date = None
                            days_diff = None
                            mark_1w = ""
                            mark_2w = ""
                        else:
                            # ê°€ì¥ ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰ ê¸°ì¤€ ìš”ì²­ë‚ ì§œ
                            sub = sub.sort_values(in_req_date_col)
                            last_date = sub[in_req_date_col].iloc[-1]
                            days_diff = (today - last_date).days

                            if days_diff <= 7:
                                mark_1w = "V"
                                mark_2w = ""
                            elif days_diff <= 14:
                                mark_1w = ""
                                mark_2w = "V"
                            else:
                                mark_1w = ""
                                mark_2w = ""

                        result_rows.append(
                            {
                                "ì™„ì„±í’ˆë²ˆ": item_code,
                                "í’ˆëª…": name,
                                "ë¶ˆì¶œìš”ì²­ì¼": last_date,
                                "1ì£¼ ì´ë‚´": mark_1w,
                                "2ì£¼ ì´ë‚´": mark_2w,
                            }
                        )

                    df_result = pd.DataFrame(result_rows)

                    if df_result.empty:
                        st.info("ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ìµœì‹  ë¶ˆì¶œìš”ì²­ì¼ì´ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬ (ì„ íƒì‚¬í•­)
                        df_result = df_result.sort_values(
                            by="ë¶ˆì¶œìš”ì²­ì¼", ascending=False, na_position="last"
                        ).reset_index(drop=True)

                        df_result_styled = df_result.style.set_properties(
                            subset=["1ì£¼ ì´ë‚´", "2ì£¼ ì´ë‚´"],
                            **{"text-align": "center"}
                        )

                        st.dataframe(df_result, use_container_width=True)

# ============================================================
# ğŸ· 6. ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚° íƒ­
# ============================================================
if menu == "ğŸ· ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚°":
    st.subheader("ğŸ· ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚°ê¸°")

    # -----------------------------
    # 0) S3 / ì„¸ì…˜ì—ì„œ ë¼ë²¨ DB ë¡œë”©
    # -----------------------------
    if "label_db" not in st.session_state:
        df_label_s3 = load_label_db_from_s3()
        if df_label_s3.empty:
            st.info("ë¼ë²¨ DBê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ê¸°ì¡´ ë¼ë²¨ ì—‘ì…€ íŒŒì¼ì„ í•œ ë²ˆ ì—…ë¡œë“œí•´ ì´ˆê¸°í™”í•˜ì„¸ìš”.")

            label_file = st.file_uploader(
                "ë¼ë²¨ DB ì´ˆê¸° ì—‘ì…€ ì—…ë¡œë“œ (ë¼ë²¨ ë° ìŠ¤í‹°ì»¤ ì§€ê´€ë¬´ê²Œ+ìˆ˜ëŸ‰ ê³„ì‚°ê¸°_*.xlsx)",
                type=["xlsx", "xlsm"],
                key="label_db_init_upload",
            )

            if label_file is not None:
                df_init = parse_label_db(label_file)
                if df_init.empty:
                    st.error("ì—‘ì…€ì—ì„œ ì½ì–´ì˜¨ ë¼ë²¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸/í—¤ë” ìœ„ì¹˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    save_label_db_to_s3(df_init)
                    st.session_state["label_db"] = df_init
                    st.success(
                        f"ë¼ë²¨ DBë¥¼ {len(df_init)}í–‰ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. "
                        "(ì´ì œë¶€í„°ëŠ” ì—‘ì…€ ì—…ë¡œë“œ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.)"
                    )
                    st.dataframe(
                        df_init[["ìƒ˜í”Œë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "êµ¬ë¶„"]].head(20),
                        use_container_width=True,
                    )
            st.stop()
        else:
            st.session_state["label_db"] = df_label_s3

    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ df_label ì¡´ì¬
    df_label: pd.DataFrame = st.session_state["label_db"]
    df_label = normalize_label_df(df_label)  # í˜¹ì‹œ ëª¨ë¥¼ ì»¬ëŸ¼ ì •ë¦¬
    st.session_state["label_db"] = df_label

    # -----------------------------
    # 1) ë¼ë²¨ ìˆ˜ëŸ‰ ê³„ì‚°ê¸°
    # -----------------------------
    st.markdown("### ğŸ”¢ ìˆ˜ëŸ‰ ê³„ì‚°")

    col_calc_left, col_calc_right = st.columns([2, 1])

    with col_calc_left:
        calc_search = st.text_input(
            "ë¼ë²¨ í’ˆë²ˆ ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜, '-' ë’¤ ê¸°ì¤€)",
            key="label_calc_search",
            placeholder="ì˜ˆ: 027A14 â†’ 2KKMMSK-027A14-xxx ë“±ì„ ì°¾ìŒ",
        )

        selected_row = None

        if calc_search:
            search_key = calc_search.split("-")[-1].strip()
            if search_key:
                mask_label = df_label["í’ˆë²ˆ"].astype(str).str.contains(search_key, na=False)
                df_hit_calc = df_label.loc[mask_label].copy()

                if df_hit_calc.empty:
                    st.info("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¼ë²¨ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    df_hit_calc = df_hit_calc.reset_index().rename(columns={"index": "_orig_index"})
                    options = [
                        f"{row['í’ˆë²ˆ']} | {row['í’ˆëª…']} ({row.get('êµ¬ë¶„', '')})"
                        for _, row in df_hit_calc.iterrows()
                    ]
                    selected_opt = st.selectbox(
                        "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ìš©í•  ë¼ë²¨ ì„ íƒ",
                        options=options,
                        key="label_calc_select",
                    )
                    sel_idx = options.index(selected_opt)
                    selected_row = df_hit_calc.iloc[sel_idx]

        film_weight = st.number_input(
            "í•„ë¦„ë¬´ê²Œ (g)",
            min_value=0.0,
            step=0.1,
            key="label_calc_film_weight",
        )

    with col_calc_right:
        core_weight_db = 0.0
        est_core_db = 0.0
        sample_weight_db = 0.0
        sample_count_db = 0.0
        label_info_text = "ë¼ë²¨ ì •ë³´ë¥¼ ì„ íƒí•˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."

        if selected_row is not None:
            part = str(selected_row.get("í’ˆë²ˆ", ""))
            name = str(selected_row.get("í’ˆëª…", ""))
            gubun = str(selected_row.get("êµ¬ë¶„", ""))

            core_weight_db = safe_num(selected_row.get("ì§€ê´€ë¬´ê²Œ", 0.0))
            est_core_db = safe_num(selected_row.get("ì¶”ì •ê°’", 0.0))

            # âœ… ì§€ê´€ë¬´ê²Œê°€ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ì‚¬ìš©
            if core_weight_db <= 0 and est_core_db > 0:
                core_weight_default = est_core_db
                core_source = "ì¶”ì •ê°’ ì‚¬ìš©"
            else:
                core_weight_default = core_weight_db
                core_source = "ì‹¤ì¸¡ ì§€ê´€ë¬´ê²Œ ì‚¬ìš©"

            sample_weight_db = safe_num(selected_row.get("ìƒ˜í”Œë¬´ê²Œ", 0.0))
            sample_count_db = parse_label_sample_count(selected_row.get("ê¸°ì¤€ìƒ˜í”Œ", ""))

            label_info_text = (
                f"**í’ˆë²ˆ**: {part}\n\n"
                f"**í’ˆëª…**: {name}\n\n"
                f"**êµ¬ë¶„**: {gubun}\n\n"
                f"**ì§€ê´€ë¬´ê²Œ(ì‹¤ì¸¡)**: {core_weight_db:.2f} g\n"
                f"**ì§€ê´€ë¬´ê²Œ(ì¶”ì •ê°’)**: {est_core_db:.2f} g\n"
                f"â†’ í˜„ì¬ ê³„ì‚°ì— ì‚¬ìš©í•  ê°’: **{core_weight_default:.2f} g** ({core_source})\n\n"
                f"**ê¸°ì¤€ìƒ˜í”Œ**: {selected_row.get('ê¸°ì¤€ìƒ˜í”Œ', '')} "
                f"(ì•½ {sample_count_db:g} ë§¤)\n"
                f"**ìƒ˜í”Œë¬´ê²Œ**: {sample_weight_db:.2f} g"
            )

        st.markdown(label_info_text)

    # ì‹¤ì œ ê³„ì‚° ì…ë ¥ (ì§€ê´€ë¬´ê²ŒëŠ” ê¸°ë³¸ê°’ = DBì˜ ì‹¤ì¸¡ or ì¶”ì •ê°’)
    col_calc2_1, col_calc2_2, col_calc2_3 = st.columns(3)
    with col_calc2_1:
        core_weight_input = st.number_input(
            "ì§€ê´€ë¬´ê²Œ (g, í•„ìš”í•˜ë©´ ìˆ˜ì •)",
            min_value=0.0,
            step=0.1,
            value=float(core_weight_db if core_weight_db > 0 else est_core_db),
            key="label_calc_core_weight",
        )
    with col_calc2_2:
        sample_weight_input = st.number_input(
            "ìƒ˜í”Œë¬´ê²Œ (g, í•„ìš”ì‹œ ìˆ˜ì •)",
            min_value=0.0,
            step=0.01,
            value=float(sample_weight_db),
            key="label_calc_sample_weight",
        )
    with col_calc2_3:
        sample_count_input = st.number_input(
            "ê¸°ì¤€ìƒ˜í”Œ ë§¤ìˆ˜ (ìˆ«ìë§Œ)",
            min_value=0.0,
            step=1.0,
            value=float(sample_count_db),
            key="label_calc_sample_count",
        )

    # ê²°ê³¼ ê³„ì‚°
    if film_weight > 0 and sample_weight_input > 0 and sample_count_input > 0:
        net_film = film_weight - core_weight_input
        if net_film <= 0:
            st.error("í•„ë¦„ë¬´ê²Œê°€ ì§€ê´€ë¬´ê²Œë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤. ê°’ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            qty = net_film / sample_weight_input * sample_count_input
            st.metric("ê³„ì‚° ê²°ê³¼ (ì¥ìˆ˜ ê¸°ì¤€)", f"{qty:,.1f} ë§¤")
            st.caption(f"ì •ìˆ˜ë¡œ ë‚´ë¦¬ë©´: **{int(qty):,} ë§¤**")
    else:
        st.caption("í•„ë¦„ë¬´ê²Œ, ìƒ˜í”Œë¬´ê²Œ, ê¸°ì¤€ìƒ˜í”Œ ë§¤ìˆ˜ë¥¼ ëª¨ë‘ ì…ë ¥í•˜ë©´ ê²°ê³¼ê°€ ê³„ì‚°ë©ë‹ˆë‹¤.")

    # -----------------------------
    # 2) ìƒˆ ë¼ë²¨ í’ˆëª© ì¶”ê°€í•˜ê¸° (ê³„ì‚°ê¸° ë°”ë¡œ ì•„ë˜)
    # -----------------------------
    with st.expander("â• ìƒˆ ë¼ë²¨ í’ˆëª© ì¶”ê°€í•˜ê¸°", expanded=False):
        st.caption("BOM ì‹œíŠ¸ì˜ í’ˆë²ˆ(Cì—´)ì„ ë¶€ë¶„ì¼ì¹˜ë¡œ ê²€ìƒ‰í•´ì„œ í’ˆëª…ì„ í™•ì¸í•œ ë’¤, ìƒˆ ë¼ë²¨ í’ˆëª©ì„ DBì— ì¶”ê°€í•©ë‹ˆë‹¤.")

        # --- BOM ê²€ìƒ‰ (ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ) ---
        selected_part_from_bom = None
        selected_name_from_bom = None

        if "df_bom_raw" in globals():
            df_bom_for_label = df_bom_raw.copy()

            # âœ… í’ˆë²ˆì€ Cì—´ ê¸°ì¤€
            bom_part_col = pick_col(df_bom_for_label, "C", ["í’ˆë²ˆ"])
            # BOMì˜ í’ˆëª… ì»¬ëŸ¼ (Dì—´ ìš°ì„ , ì—†ìœ¼ë©´ Bì—´)
            bom_name_col = pick_col(df_bom_for_label, "D", ["í’ˆëª…"])
            if bom_name_col is None:
                bom_name_col = pick_col(df_bom_for_label, "B", ["í’ˆëª…"])

            new_bom_search = st.text_input(
                "BOM ìì¬ í’ˆë²ˆ ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜, Cì—´ ê¸°ì¤€)",
                key="label_new_bom_search",
                placeholder="ì˜ˆ: 027A14, 038B12 ë“±",
            )

            if new_bom_search and bom_part_col and bom_name_col:
                mask_part = df_bom_for_label[bom_part_col].astype(str).str.contains(
                    new_bom_search, na=False
                )

                # âœ… í’ˆëª…ì˜ ëë¶€ë¶„ì— '_ë¼ë²¨' ë˜ëŠ” '_ì— ë¸”ëŸ¼' ì´ í¬í•¨ëœ ê²ƒë§Œ
                name_series = df_bom_for_label[bom_name_col].astype(str)
                mask_name = (
                    name_series.str.contains(r"_.*ë¼ë²¨", na=False)
                    | name_series.str.contains(r"_.*ì— ë¸”ëŸ¼", na=False)
                )

                mask_bom = mask_part & mask_name

                df_bom_hit = (
                    df_bom_for_label.loc[mask_bom, [bom_part_col, bom_name_col]]
                    .drop_duplicates()
                    .head(50)
                )
                if not df_bom_hit.empty:
                    df_bom_hit = df_bom_hit.rename(
                        columns={bom_part_col: "BOM_í’ˆë²ˆ", bom_name_col: "BOM_í’ˆëª…"}
                    ).reset_index(drop=True)

                    st.dataframe(
                        df_bom_hit,
                        use_container_width=True,
                        height=200,
                    )

                    # ğŸ”½ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•˜ë‚˜ ì„ íƒ â†’ ì•„ë˜ ì…ë ¥ì¹¸ì— ìë™ ë°˜ì˜
                    options_bom = [
                        f"{row['BOM_í’ˆë²ˆ']} | {row['BOM_í’ˆëª…']}"
                        for _, row in df_bom_hit.iterrows()
                    ]
                    selected_bom_opt = st.selectbox(
                        "ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¼ë²¨/ì— ë¸”ëŸ¼ í’ˆëª© ì„ íƒ",
                        ["ì„ íƒ ì•ˆ í•¨"] + options_bom,
                        key="label_new_bom_select",
                    )

                    if selected_bom_opt != "ì„ íƒ ì•ˆ í•¨":
                        idx_sel = options_bom.index(selected_bom_opt)
                        row_sel = df_bom_hit.iloc[idx_sel]
                        selected_part_from_bom = str(row_sel["BOM_í’ˆë²ˆ"])
                        selected_name_from_bom = str(row_sel["BOM_í’ˆëª…"])

                        # ğŸ‘‰ í…ìŠ¤íŠ¸ ì…ë ¥ ê¸°ë³¸ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ê¸°
                        st.session_state["label_new_part"] = selected_part_from_bom
                        st.session_state["label_new_name"] = selected_name_from_bom
                else:
                    st.caption("ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” BOM í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (ë¼ë²¨/ì— ë¸”ëŸ¼ í’ˆëª©ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.)")
            elif not bom_part_col or not bom_name_col:
                st.warning("BOM ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(Cì—´) ë˜ëŠ” í’ˆëª…(Dì—´/Bì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("BOM ì‹œíŠ¸ ê²€ìƒ‰ì€ ë©”ì¸ ë¶€ìì¬ DB ì—…ë¡œë“œ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        st.markdown("#### ì‹¤ì œë¡œ DBì— ì €ì¥í•  ë¼ë²¨ ì •ë³´ ì…ë ¥")

        # ì„ íƒ ê°€ëŠ¥í•œ êµ¬ë¶„ ëª©ë¡
        if "LABEL_TYPES" in globals():
            gubun_choices = LABEL_TYPES
        elif "êµ¬ë¶„" in df_label.columns:
            gubun_choices = sorted(df_label["êµ¬ë¶„"].dropna().unique().tolist())
        else:
            gubun_choices = []

        new_part = st.text_input(
            "ë¼ë²¨ í’ˆë²ˆ (DBì— ì €ì¥í•  ì‹¤ì œ í’ˆë²ˆ)",
            key="label_new_part",
            placeholder="ì˜ˆ: 2KKMMSK-027A14-xxx",
        )
        new_name = st.text_input(
            "í’ˆëª…",
            key="label_new_name",
        )
        new_gubun = st.selectbox(
            "êµ¬ë¶„",
            options=gubun_choices if gubun_choices else ["(ì§ì ‘ ì…ë ¥)"],
            key="label_new_gubun",
        )

        col_dim1, col_dim2, col_dim3 = st.columns(3)
        with col_dim1:
            new_od = st.number_input(
                "ì™¸ê²½ (mm)",
                min_value=0.0,
                step=0.1,
                key="label_new_od",
            )
        with col_dim2:
            new_id = st.number_input(
                "ë‚´ê²½ (mm)",
                min_value=0.0,
                step=0.1,
                key="label_new_id",
            )
        with col_dim3:
            new_h = st.number_input(
                "ë†’ì´ (mm)",
                min_value=0.0,
                step=0.1,
                key="label_new_h",
            )

        # ğŸ” ì™¸ê²½/ë‚´ê²½/ë†’ì´ë¡œ ì¸¡ì •ê°’(ì¶”ì •ê°’) ë¯¸ë¦¬ ë³´ê¸°
        est_val_preview = 0.0
        if new_od > 0 and new_id > 0 and new_h > 0:
            est_val_preview = 3.14 * new_h * ((new_od ** 2 - new_id ** 2) / 4.0) * 0.78
            est_val_preview = round(est_val_preview, 2)
        st.metric("ì¸¡ì •ê°’ (ì¶”ì • ì§€ê´€ë¬´ê²Œ, g)", f"{est_val_preview:.2f}")

        col_sample1, col_sample2 = st.columns(2)
        with col_sample1:
            new_base_str = st.text_input(
                "ê¸°ì¤€ìƒ˜í”Œ (ì˜ˆ: '4ë§¤', '2ë§¤(ì•„ì´ë§ˆí¬)')",
                key="label_new_base_str",
                placeholder="ì˜ˆ: 4ë§¤",
            )
        with col_sample2:
            new_sample_weight = st.number_input(
                "ìƒ˜í”Œë¬´ê²Œ (g)",
                min_value=0.0,
                step=0.01,
                key="label_new_sample_weight",
            )

        new_core_weight = st.number_input(
            "ì‹¤ì¸¡ ì§€ê´€ë¬´ê²Œ (g, ì„ íƒì…ë ¥)",
            min_value=0.0,
            step=0.1,
            key="label_new_core_weight",
        )

        if st.button("âœ… ì…ë ¥ ì™„ë£Œ (DBì— ì €ì¥)", key="label_new_save_btn"):
            # í•„ìˆ˜ê°’ ì²´í¬
            if not new_part or not new_name:
                st.error("í’ˆë²ˆê³¼ í’ˆëª…ì€ ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            elif new_od <= 0 or new_id <= 0 or new_h <= 0:
                st.error("ì™¸ê²½, ë‚´ê²½, ë†’ì´ëŠ” ëª¨ë‘ 0ë³´ë‹¤ í° ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            elif new_sample_weight <= 0:
                st.error("ìƒ˜í”Œë¬´ê²Œ(g)ëŠ” 0ë³´ë‹¤ í° ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                # ì¶”ì •ê°’ ê³„ì‚°
                est_val = 3.14 * new_h * ((new_od ** 2 - new_id ** 2) / 4.0) * 0.78
                est_val = round(est_val, 2)

                # ì˜¤ì°¨: ì‹¤ì¸¡ ì§€ê´€ë¬´ê²Œê°€ ìˆìœ¼ë©´ (ì¶”ì •ê°’ - ì‹¤ë¬´ê²Œ), ì—†ìœ¼ë©´ 0
                if new_core_weight > 0:
                    err_val = est_val - new_core_weight
                else:
                    err_val = 0.0

                new_row = {
                    "ìƒ˜í”Œë²ˆí˜¸": None,
                    "í’ˆë²ˆ": new_part,
                    "í’ˆëª…": new_name,
                    "êµ¬ë¶„": new_gubun if new_gubun != "(ì§ì ‘ ì…ë ¥)" else "",
                    "ì§€ê´€ë¬´ê²Œ": new_core_weight if new_core_weight > 0 else 0.0,
                    "ì¶”ì •ê°’": est_val,
                    "ì˜¤ì°¨": err_val,
                    "ì™¸ê²½": new_od,
                    "ë‚´ê²½": new_id,
                    "ë†’ì´": new_h,
                    "1Rë¬´ê²Œ": None,
                    "ê¸°ì¤€ìƒ˜í”Œ": new_base_str,
                    "ìƒ˜í”Œë¬´ê²Œ": new_sample_weight,
                }

                df_label_new = pd.concat(
                    [df_label, pd.DataFrame([new_row])],
                    ignore_index=True,
                )
                df_label_new = normalize_label_df(df_label_new)

                st.session_state["label_db"] = df_label_new
                save_label_db_to_s3(df_label_new)

                st.success(f"ìƒˆ ë¼ë²¨ í’ˆëª©ì´ DBì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (í’ˆë²ˆ: {new_part})")

    # -----------------------------
    # 3) ë¼ë²¨ ê²€ìƒ‰ + ì‚­ì œ
    # -----------------------------
    st.markdown("### ğŸ” ë¼ë²¨ ê²€ìƒ‰ / ì‚­ì œ")

    label_search = st.text_input(
        "í’ˆë²ˆ ë˜ëŠ” í’ˆëª… ê²€ìƒ‰ (ë¶€ë¶„ì¼ì¹˜)",
        key="label_search",
        placeholder="ì˜ˆ: í’ˆë²ˆ ì¼ë¶€ ë˜ëŠ” í’ˆëª… ì¼ë¶€",
    )

    if label_search:
        mask_search = (
            df_label["í’ˆë²ˆ"].astype(str).str.contains(label_search, na=False)
            | df_label["í’ˆëª…"].astype(str).str.contains(label_search, na=False)
        )
        df_search = df_label.loc[mask_search].copy()

        if df_search.empty:
            st.info("ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë¼ë²¨ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df_search = df_search.reset_index().rename(columns={"index": "_orig_index"})
            df_search["ì‚­ì œ"] = False

            display_cols = [
                "ì‚­ì œ",
                "í’ˆë²ˆ",
                "í’ˆëª…",
                "êµ¬ë¶„",
                "ì§€ê´€ë¬´ê²Œ",
                "ì¶”ì •ê°’",
                "ê¸°ì¤€ìƒ˜í”Œ",
                "ìƒ˜í”Œë¬´ê²Œ",
            ]
            display_cols = [c for c in display_cols if c in df_search.columns]

            df_search_view = df_search[display_cols + ["_orig_index"]]

            df_search_edit = st.data_editor(
                df_search_view,
                use_container_width=True,
                num_rows="fixed",
                hide_index=True,
                column_config={
                    "ì‚­ì œ": st.column_config.CheckboxColumn("ì‚­ì œ", default=False)
                },
                key="label_search_editor",
            )

            if st.button("ğŸ—‘ ì„ íƒí•œ ë¼ë²¨ ì‚­ì œ", key="label_delete_btn"):
                to_delete_idx = df_search_edit.loc[
                    df_search_edit["ì‚­ì œ"] == True, "_orig_index"
                ].tolist()

                if not to_delete_idx:
                    st.warning("ì‚­ì œí•  ë¼ë²¨ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                else:
                    df_label_after = df_label.drop(index=to_delete_idx).reset_index(drop=True)
                    df_label_after = normalize_label_df(df_label_after)
                    st.session_state["label_db"] = df_label_after
                    save_label_db_to_s3(df_label_after)
                    st.success(f"ì„ íƒí•œ ë¼ë²¨ {len(to_delete_idx)}ê°œë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
                    st.experimental_rerun()

    # -----------------------------
    # 4) ë¼ë²¨ DB ë¯¸ë¦¬ë³´ê¸° / (ì„ íƒì ) ì „ì²´ í¸ì§‘
    # -----------------------------
    with st.expander("ğŸ“‹ ë¼ë²¨ DB ë¯¸ë¦¬ë³´ê¸° / ì €ì¥", expanded=False):
        cols_preview = [
            c
            for c in ["ìƒ˜í”Œë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "êµ¬ë¶„", "ì§€ê´€ë¬´ê²Œ", "ì¶”ì •ê°’", "ê¸°ì¤€ìƒ˜í”Œ", "ìƒ˜í”Œë¬´ê²Œ"]
            if c in df_label.columns
        ]
        st.dataframe(df_label[cols_preview], use_container_width=True, height=300)

        edit_mode = st.checkbox(
            "âœï¸ ë¼ë²¨ DB ì „ì²´ í¸ì§‘ ëª¨ë“œ ì¼œê¸° (ëŠë ¤ì§ˆ ìˆ˜ ìˆì–´ìš”)",
            key="label_db_edit_mode",
            value=False,
        )

        if edit_mode:
            df_edit = st.data_editor(
                df_label,
                use_container_width=True,
                num_rows="dynamic",
                key="label_db_editor",
            )

            if st.button("ğŸ’¾ ë¼ë²¨ DB ì €ì¥ (S3 ë°˜ì˜)", key="label_db_save_btn"):
                df_edit_norm = normalize_label_df(df_edit.copy())
                st.session_state["label_db"] = df_edit_norm
                save_label_db_to_s3(df_edit_norm)
                st.success("ë¼ë²¨ DBë¥¼ S3ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        # ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê¸°
        excel_buf = io.BytesIO()
        df_label.to_excel(excel_buf, index=False, sheet_name="ë¼ë²¨DB")
        excel_buf.seek(0)
        st.download_button(
            "ğŸ“¥ í˜„ì¬ ë¼ë²¨ DB ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=excel_buf,
            file_name="ë¼ë²¨_DB_í˜„ì¬ë²„ì „.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="label_db_download_btn",
        )

