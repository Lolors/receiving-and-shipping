import streamlit as st
import pandas as pd
from datetime import date, timedelta
import io
import os

# ============ S3 ì—°ë™ ============

import boto3
from botocore.exceptions import ClientError

S3_BUCKET = "rec-and-ship"
S3_KEY = "bulk-ledger.xlsx"  # í•­ìƒ ì´ ì´ë¦„ìœ¼ë¡œ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°

def get_s3_client():
    try:
        return boto3.client(
            "s3",
            aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
            aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
            region_name="ap-northeast-2",
        )
    except Exception as e:
        st.error(f"S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

s3_client = get_s3_client()

@st.cache_data(show_spinner=True)
def load_file_from_s3():
    """S3ì— íŒŒì¼ì´ ìˆìœ¼ë©´ bytesë¡œ ì½ì–´ì˜¨ë‹¤."""
    if s3_client is None:
        return None
    try:
        obj = s3_client.get_object(Bucket=S3_BUCKET, Key=S3_KEY)
        return obj["Body"].read()
    except ClientError as e:
        code = e.response["Error"]["Code"]
        if code in ("NoSuchKey", "404"):
            return None
        st.error(f"S3ì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# PDF ìƒì„±ìš© (reportlab ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ì²˜ë¦¬)
try:
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib import colors
    from reportlab.platypus import (
        SimpleDocTemplate,
        Table,
        TableStyle,
        Paragraph,
        Spacer,
    )
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    KOREAN_FONT_NAME = "MalgunGothic"

    # app.py ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê¸°
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    FONT_PATH = os.path.join(BASE_DIR, "font", "malgun.ttf")

    try:
        pdfmetrics.registerFont(TTFont(KOREAN_FONT_NAME, FONT_PATH))
        print("í°íŠ¸ ë¡œë”© ì„±ê³µ:", FONT_PATH)
    except Exception as e:
        print("í°íŠ¸ ë¡œë”© ì‹¤íŒ¨:", e)
        KOREAN_FONT_NAME = "Helvetica"


    REPORTLAB_AVAILABLE = True
except ModuleNotFoundError:
    REPORTLAB_AVAILABLE = False
    KOREAN_FONT_NAME = "Helvetica"

st.set_page_config(page_title="ë¶€ìì¬ ì…ê³  / í™˜ì… ê´€ë¦¬", layout="wide")

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_data
def load_excel(file_bytes: bytes):
    """bytes ë˜ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ë°›ì•„ ì „ì²´ ì‹œíŠ¸ë¥¼ dictë¡œ ë°˜í™˜"""
    xls = pd.ExcelFile(file_bytes)
    sheets = {}
    for sheet_name in xls.sheet_names:
        try:
            sheets[sheet_name] = pd.read_excel(xls, sheet_name)
        except Exception:
            pass
    return sheets


def get_week_of_month(d: date) -> str:
    """ê°„ë‹¨íˆ: 1~7ì¼=1ì£¼ì°¨, 8~14=2ì£¼ì°¨, ..."""
    week_no = (d.day - 1) // 7 + 1
    return f"{d.month}ì›”{week_no}ì£¼ì°¨"


def ensure_session_df(key: str, columns: list):
    if key not in st.session_state:
        st.session_state[key] = pd.DataFrame(columns=columns)
    return st.session_state[key]


def excel_col_to_index(col_letter: str) -> int:
    """ì—‘ì…€ ì—´ ë¬¸ì(A, B, ... AA, AB...)ë¥¼ 0-base indexë¡œ ë³€í™˜"""
    col_letter = col_letter.upper()
    result = 0
    for ch in col_letter:
        if not ("A" <= ch <= "Z"):
            continue
        result = result * 26 + (ord(ch) - ord("A") + 1)
    return result - 1  # 0-base


def pick_col(df: pd.DataFrame, letter: str, preferred_names: list):
    """
    ìš°ì„  ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ì—‘ì…€ ì—´ ìœ„ì¹˜(letter)ë¡œ ì°¾ê¸°
    (preferred_names ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©)
    """
    cols = list(df.columns)
    for name in preferred_names:
        if name in df.columns:
            return name
    idx = excel_col_to_index(letter)
    if 0 <= idx < len(cols):
        return cols[idx]
    return None


def safe_num(x):
    """ìˆ«ìê°€ ì•„ë‹ˆë©´ ìµœëŒ€í•œ floatìœ¼ë¡œ ë³€í™˜, ì•ˆ ë˜ë©´ 0"""
    try:
        if pd.isna(x):
            return 0
    except Exception:
        pass
    if isinstance(x, (int, float)):
        return float(x)
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return 0.0


# í™”ë©´ì— ë³´ì´ëŠ” í™˜ì… ì˜ˆìƒì¬ê³  í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œ
VISIBLE_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì™„ì„±í’ˆë²ˆ",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# CSVì— ë“¤ì–´ê°ˆ ì „ì²´ ì»¬ëŸ¼ (ìš”ì²­í•œ ìˆœì„œ ê·¸ëŒ€ë¡œ)
CSV_COLS = [
    "ìˆ˜ì£¼ë²ˆí˜¸",
    "ì§€ì‹œë²ˆí˜¸",
    "ìƒì‚°ê³µì •",
    "ìƒì‚°ì‹œì‘ì¼",
    "ìƒì‚°ì¢…ë£Œì¼",
    "ì¢…ë£Œì¡°ê±´",
    "í™˜ì…ì¼",
    "í™˜ì…ì£¼ì°¨",
    "ì™„ì„±í’ˆë²ˆ",
    "ì™„ì„±í’ˆëª…",
    "í’ˆë²ˆ",
    "í’ˆëª…",
    "ERPë¶ˆì¶œìˆ˜ëŸ‰",
    "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
    "ì§€ì‹œìˆ˜ëŸ‰",
    "ìƒì‚°ìˆ˜ëŸ‰",
    "QCìƒ˜í”Œ",
    "ê¸°íƒ€ìƒ˜í”Œ",
    "ë‹¨ìœ„ìˆ˜ëŸ‰",
    "ì›ë¶ˆ",
    "ì‘ë¶ˆ",
    "ì˜ˆìƒì¬ê³ ",
    "ERPì¬ê³ ",
]

# -----------------------------
# ì§‘ê³„ í…Œì´ë¸” ë¹Œë“œ
# -----------------------------
def build_aggregates(df_in_raw, df_job_raw, df_result_raw, df_defect_raw, df_stock_raw):
    """
    í° ì›ë³¸ ì‹œíŠ¸ë“¤ì„ ë¯¸ë¦¬ groupby í•´ì„œ, ë‚˜ì¤‘ì—” mergeë§Œ í•˜ë„ë¡ ë§Œë“œëŠ” ì§‘ê³„ í…Œì´ë¸”ë“¤
    """
    aggregates = {}

    # === 1) ì…ê³  ì§‘ê³„: [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ë³„ ERPë¶ˆì¶œìˆ˜ëŸ‰/í˜„ì¥ì‹¤ë¬¼ì…ê³  í•©ê³„ ===
    # ìˆ˜ì£¼ë²ˆí˜¸: Bì—´, ì§€ì‹œë²ˆí˜¸: Cì—´, í’ˆë²ˆ: Mì—´, ERPë¶ˆì¶œìˆ˜ëŸ‰: Qì—´, í˜„ì¥ì‹¤ë¬¼ì…ê³ : Rì—´
    in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
    in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
    in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
    in_erp_col = pick_col(df_in_raw, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰"])
    in_real_col = pick_col(df_in_raw, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

    if all([in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]):
        df_in = df_in_raw[
            [in_suju_col, in_jisi_col, in_part_col, in_erp_col, in_real_col]
        ].copy()
        df_in.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        agg_in = (
            df_in.groupby(["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)
            .agg({"ERPë¶ˆì¶œìˆ˜ëŸ‰": "sum", "í˜„ì¥ì‹¤ë¬¼ì…ê³ ": "sum"})
        )
        aggregates["in"] = agg_in
    else:
        aggregates["in"] = pd.DataFrame(
            columns=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        )

    # === 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„: ì§€ì‹œë²ˆí˜¸ë³„ ì§€ì‹œìˆ˜ëŸ‰ ===
    job_jisi_col = (
        "ì§€ì‹œë²ˆí˜¸"
        if "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
        else pick_col(df_job_raw, "F", ["ì§€ì‹œë²ˆí˜¸"])
    )
    job_qty_col = (
        "ìˆ˜ëŸ‰"
        if "ìˆ˜ëŸ‰" in df_job_raw.columns
        else pick_col(df_job_raw, "R", ["ìˆ˜ëŸ‰", "ì§€ì‹œìˆ˜ëŸ‰"])
    )

    if job_jisi_col and job_qty_col:
        df_job = df_job_raw[[job_jisi_col, job_qty_col]].copy()
        df_job.columns = ["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"]
        agg_job = df_job.groupby("ì§€ì‹œë²ˆí˜¸", as_index=False).agg({"ì§€ì‹œìˆ˜ëŸ‰": "sum"})
        aggregates["job"] = agg_job
    else:
        aggregates["job"] = pd.DataFrame(columns=["ì§€ì‹œë²ˆí˜¸", "ì§€ì‹œìˆ˜ëŸ‰"])

    # === 3) ìƒì‚°ì‹¤ì  ì§‘ê³„: ì§€ì‹œë²ˆí˜¸(ì‘ì§€ë²ˆí˜¸)ë³„ ìƒì‚°/ìƒ˜í”Œ ìˆ˜ëŸ‰ ===
    res_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_result_raw.columns
        else pick_col(df_result_raw, "H", ["ì‘ì§€ë²ˆí˜¸"])
    )
    res_sum_col = (
        "í•©ê³„"
        if "í•©ê³„" in df_result_raw.columns
        else pick_col(df_result_raw, "AD", ["í•©ê³„"])
    )
    res_qc_col = (
        "QCìƒ˜í”Œ"
        if "QCìƒ˜í”Œ" in df_result_raw.columns
        else pick_col(df_result_raw, "AG", ["QCìƒ˜í”Œ"])
    )
    res_etc_col = (
        "ê¸°íƒ€ìƒ˜í”Œ"
        if "ê¸°íƒ€ìƒ˜í”Œ" in df_result_raw.columns
        else pick_col(df_result_raw, "AH", ["ê¸°íƒ€ìƒ˜í”Œ"])
    )

    cols_res = [res_jisi_col, res_sum_col, res_qc_col, res_etc_col]
    if res_jisi_col and any(cols_res[1:]):
        df_res = df_result_raw[[c for c in cols_res if c is not None]].copy()
        rename_map = {}
        if res_jisi_col:
            rename_map[res_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
        if res_sum_col:
            rename_map[res_sum_col] = "ìƒì‚°ìˆ˜ëŸ‰"
        if res_qc_col:
            rename_map[res_qc_col] = "QCìƒ˜í”Œ"
        if res_etc_col:
            rename_map[res_etc_col] = "ê¸°íƒ€ìƒ˜í”Œ"
        df_res = df_res.rename(columns=rename_map)
        agg_res = df_res.groupby("ì§€ì‹œë²ˆí˜¸", as_index=False).agg("sum")
        aggregates["result"] = agg_res
    else:
        aggregates["result"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "ìƒì‚°ìˆ˜ëŸ‰", "QCìƒ˜í”Œ", "ê¸°íƒ€ìƒ˜í”Œ"]
        )

    # === 4) ë¶ˆëŸ‰ ì§‘ê³„: [ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ]ë³„ ì›ë¶ˆ/ì‘ë¶ˆ ìˆ˜ëŸ‰ ===
    def_jisi_col = (
        "ì‘ì§€ë²ˆí˜¸"
        if "ì‘ì§€ë²ˆí˜¸" in df_defect_raw.columns
        else pick_col(df_defect_raw, "C", ["ì‘ì§€ë²ˆí˜¸"])
    )
    def_part_col = (
        "íˆ¬ì…í’ˆë²ˆ"
        if "íˆ¬ì…í’ˆë²ˆ" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Q", ["íˆ¬ì…í’ˆë²ˆ"])
    )
    def_qty_col = (
        "ë¶ˆëŸ‰ìˆ˜ëŸ‰"
        if "ë¶ˆëŸ‰ìˆ˜ëŸ‰" in df_defect_raw.columns
        else pick_col(df_defect_raw, "W", ["ë¶ˆëŸ‰ìˆ˜ëŸ‰"])
    )
    def_type_col = (
        "ë¶ˆëŸ‰ìœ í˜•.1"
        if "ë¶ˆëŸ‰ìœ í˜•.1" in df_defect_raw.columns
        else pick_col(df_defect_raw, "Z", ["ë¶ˆëŸ‰ìœ í˜•.1", "ë¶ˆëŸ‰ìœ í˜•"])
    )

    if def_jisi_col and def_part_col and def_qty_col and def_type_col:
        df_def = df_defect_raw[
            [def_jisi_col, def_part_col, def_qty_col, def_type_col]
        ].copy()
        df_def.columns = ["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¶ˆëŸ‰ìˆ˜ëŸ‰", "ë¶ˆëŸ‰ìœ í˜•"]
        df_def["ë¶ˆëŸ‰ìœ í˜•"] = df_def["ë¶ˆëŸ‰ìœ í˜•"].astype(str)

        # ì›ë¶ˆ
        df_orig = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì›)")].copy()
        agg_orig = (
            df_orig.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì›ë¶ˆ"})
        )

        # ì‘ë¶ˆ
        df_proc = df_def[df_def["ë¶ˆëŸ‰ìœ í˜•"].str.startswith("(ì‘)")].copy()
        agg_proc = (
            df_proc.groupby(["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], as_index=False)["ë¶ˆëŸ‰ìˆ˜ëŸ‰"]
            .sum()
            .rename(columns={"ë¶ˆëŸ‰ìˆ˜ëŸ‰": "ì‘ë¶ˆ"})
        )

        # ë‘˜ í•©ì¹˜ê¸°
        agg_def = pd.merge(agg_orig, agg_proc, on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], how="outer")
        aggregates["defect"] = agg_def
    else:
        aggregates["defect"] = pd.DataFrame(
            columns=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ì›ë¶ˆ", "ì‘ë¶ˆ"]
        )

    # === 5) ì¬ê³  ì§‘ê³„: í’ˆë²ˆë³„ ERPì¬ê³  (ì‘ì—…ì¥ WC501~WC504) ===
    stock_wc_col = pick_col(df_stock_raw, "A", ["ì‘ì—…ì¥"])
    stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])

    # ERPì¬ê³ ëŠ” ë°˜ë“œì‹œ "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" ì»¬ëŸ¼ì„ ì‚¬ìš© (ì—†ìœ¼ë©´ Nì—´ fallback)
    if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in df_stock_raw.columns:
        stock_qty_col = "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"
    else:
        stock_qty_col = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

    if stock_wc_col and stock_part_col and stock_qty_col:
        df_stock = df_stock_raw[
            [stock_wc_col, stock_part_col, stock_qty_col]
        ].copy()
        df_stock.columns = ["ì‘ì—…ì¥", "í’ˆë²ˆ", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
        df_stock = df_stock[df_stock["ì‘ì—…ì¥"].isin(["WC501", "WC502", "WC503", "WC504"])]
        if not df_stock.empty:
            agg_stock = (
                df_stock.groupby("í’ˆë²ˆ", as_index=False)["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
                .sum()
                .rename(columns={"ì‹¤ì¬ê³ ìˆ˜ëŸ‰": "ERPì¬ê³ "})
            )
            aggregates["stock"] = agg_stock
        else:
            aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])
    else:
        aggregates["stock"] = pd.DataFrame(columns=["í’ˆë²ˆ", "ERPì¬ê³ "])

    return aggregates


# -----------------------------
# í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚° (merge ê¸°ë°˜)
# -----------------------------
def recalc_return_expectation(df_return, aggs):
    """
    df_return(í™˜ì…ê´€ë¦¬ í…Œì´ë¸”)ì— ì§‘ê³„ ë°ì´í„°(aggs)ë¥¼ mergeë¡œ ë¶™ì—¬ì„œ
    ERPë¶ˆì¶œìˆ˜ëŸ‰, í˜„ì¥ì‹¤ë¬¼ì…ê³ , ì§€ì‹œìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰, QCìƒ˜í”Œ, ê¸°íƒ€ìƒ˜í”Œ, ì›ë¶ˆ, ì‘ë¶ˆ, ERPì¬ê³ , ì˜ˆìƒì¬ê³ ë¥¼ ê³„ì‚°

    ì˜ˆìƒì¬ê³  = í˜„ì¥ì‹¤ë¬¼ì…ê³  - (ìƒì‚°ìˆ˜ëŸ‰ + QCìƒ˜í”Œ + ê¸°íƒ€ìƒ˜í”Œ) * ë‹¨ìœ„ìˆ˜ëŸ‰ - ì‘ë¶ˆ
    """
    if df_return.empty:
        return pd.DataFrame(columns=CSV_COLS)

    # [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    df = df_return.drop_duplicates(
        subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
    ).copy()

    # 1) ì…ê³  ì§‘ê³„ ë¶™ì´ê¸°: ERPë¶ˆì¶œìˆ˜ëŸ‰, í˜„ì¥ì‹¤ë¬¼ì…ê³  ([ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ])
    df = df.merge(
        aggs["in"],
        how="left",
        on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
        suffixes=("", "_in"),
    )

    # 2) ì‘ì—…ì§€ì‹œ ì§‘ê³„ ë¶™ì´ê¸°: ì§€ì‹œìˆ˜ëŸ‰ (ì§€ì‹œë²ˆí˜¸)
    df = df.merge(
        aggs["job"],
        how="left",
        on="ì§€ì‹œë²ˆí˜¸",
    )

    # 3) ìƒì‚°ì‹¤ì  ì§‘ê³„ ë¶™ì´ê¸°: ìƒì‚°ìˆ˜ëŸ‰, QCìƒ˜í”Œ, ê¸°íƒ€ìƒ˜í”Œ (ì§€ì‹œë²ˆí˜¸)
    df = df.merge(
        aggs["result"],
        how="left",
        on="ì§€ì‹œë²ˆí˜¸",
        suffixes=("", "_res"),
    )

    # 4) ë¶ˆëŸ‰ ì§‘ê³„ ë¶™ì´ê¸°: ì›ë¶ˆ, ì‘ë¶ˆ ([ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ])
    df = df.merge(
        aggs["defect"],
        how="left",
        on=["ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
    )

    # 5) ì¬ê³  ì§‘ê³„ ë¶™ì´ê¸°: ERPì¬ê³  (í’ˆë²ˆ)
    if "ERPì¬ê³ " in df.columns:
        df = df.drop(columns=["ERPì¬ê³ "])
    df = df.merge(
        aggs["stock"],
        how="left",
        on="í’ˆë²ˆ",
    )

    # ìˆ«ì ì»¬ëŸ¼ë“¤ NaN -> 0, ë¬¸ìì—´ì´ë©´ float ë³€í™˜
    num_cols = [
        "ERPë¶ˆì¶œìˆ˜ëŸ‰",
        "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
        "ì§€ì‹œìˆ˜ëŸ‰",
        "ìƒì‚°ìˆ˜ëŸ‰",
        "QCìƒ˜í”Œ",
        "ê¸°íƒ€ìƒ˜í”Œ",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ì›ë¶ˆ",
        "ì‘ë¶ˆ",
        "ERPì¬ê³ ",
    ]
    for col in num_cols:
        if col in df.columns:
            df[col] = df[col].apply(safe_num)
        else:
            df[col] = 0.0

    # ìµœì¢… ê³µì‹
    df["ì˜ˆìƒì¬ê³ "] = (
        df["í˜„ì¥ì‹¤ë¬¼ì…ê³ "]
        - (df["ìƒì‚°ìˆ˜ëŸ‰"] + df["QCìƒ˜í”Œ"] + df["ê¸°íƒ€ìƒ˜í”Œ"]) * df["ë‹¨ìœ„ìˆ˜ëŸ‰"]
        - df["ì‘ë¶ˆ"]
    )

    # ì™„ì„±í’ˆëª…: ì œí’ˆëª… ì»¬ëŸ¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    df["ì™„ì„±í’ˆëª…"] = df.get("ì œí’ˆëª…", None)

    # CSVìš© ì „ì²´ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì—†ìœ¼ë©´ ì¶”ê°€)
    for col in CSV_COLS:
        if col not in df.columns:
            df[col] = None

    out = df[CSV_COLS].copy()
    return out

# -----------------------------
# PDF ìƒì„± í•¨ìˆ˜
# -----------------------------
if REPORTLAB_AVAILABLE:
    def generate_pdf(
        df_export: pd.DataFrame,
        uploaded_image=None,
        pasted_text=None
    ) -> bytes:
        """
        - ì œëª© / í‘œ ëª¨ë‘ ì™¼ìª½ ì •ë ¬
        - ë¶™ì—¬ë„£ì€ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì œëª© ì•„ë˜ì— ì¶œë ¥
        - ë¶™ì—¬ë„£ì€ ì´ë¯¸ì§€(base64) ìˆìœ¼ë©´ ê·¸ ì•„ë˜ì— ì¶œë ¥
        """
        import io
        from reportlab.platypus import (
            SimpleDocTemplate,
            Table,
            TableStyle,
            Paragraph,
            Spacer,
            Image,
        )
        from reportlab.lib.pagesizes import A4, landscape
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors

        buffer = io.BytesIO()

        doc = SimpleDocTemplate(
            buffer,
            pagesize=landscape(A4),
            leftMargin=20,
            rightMargin=20,
            topMargin=20,
            bottomMargin=20,
        )

        styles = getSampleStyleSheet()

        title_style = ParagraphStyle(
            "TitleStyle",
            parent=styles["Heading1"],
            fontName=KOREAN_FONT_NAME,
            fontSize=15,
            alignment=0,   # LEFT
        )

        text_style = ParagraphStyle(
            "TextStyle",
            parent=styles["Normal"],
            fontName=KOREAN_FONT_NAME,
            fontSize=10,
            leading=14,
            alignment=0,   # LEFT
        )

        table_style = TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
                ("ALIGN", (0, 0), (-1, -1), "LEFT"),  # ì™¼ìª½ ì •ë ¬
                ("FONTNAME", (0, 0), (-1, -1), KOREAN_FONT_NAME),
                ("FONTSIZE", (0, 0), (-1, -1), 8),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
            ]
        )

        story = []

        # ì œëª© êµ¬ì„±
        suju_list = df_export["ìˆ˜ì£¼ë²ˆí˜¸"].dropna().astype(str).unique()
        name_list = df_export["ì™„ì„±í’ˆëª…"].dropna().astype(str).unique()
        title_text = f"{suju_list[0] if len(suju_list) else ''} {name_list[0] if len(name_list) else ''}".strip()

        story.append(Paragraph(title_text, title_style))
        story.append(Spacer(1, 12))

        # ë¶™ì—¬ë„£ì€ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì œëª© ì•„ë˜ì— ì¶œë ¥
        if pasted_text:
            story.append(Paragraph(pasted_text.replace("\n", "<br/>"), text_style))
            story.append(Spacer(1, 12))

        # í´ë¦½ë³´ë“œ ì´ë¯¸ì§€ê°€ ìˆì„ ê²½ìš° PDF ì‚½ì…
        if uploaded_image:
            try:
                img = Image(uploaded_image, width=400, height=300)
                story.append(img)
                story.append(Spacer(1, 12))
            except Exception:
                pass

        # í‘œ êµ¬ì„±
        table_cols = ["í’ˆë²ˆ", "í’ˆëª…", "ì‘ë¶ˆ", "ì˜ˆìƒì¬ê³ ", "ERPì¬ê³ "]
        table_data = [table_cols]

        for _, row in df_export.iterrows():
            table_data.append([str(row.get(c, "")) for c in table_cols])

        table = Table(table_data, repeatRows=1)
        table.setStyle(table_style)
        story.append(table)

        doc.build(story)

        # ê·¸ëƒ¥ reportlabì´ ë§Œë“  raw PDF bytes ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë”°ë¡œ ANSI ì¬ì¸ì½”ë”© X)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes

else:
    def generate_pdf(
        df_export: pd.DataFrame,
        uploaded_image=None,
        pasted_text=None
    ) -> bytes:
        raise RuntimeError("reportlab íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# -----------------------------
# ë©”ì¸ í™”ë©´
# -----------------------------
st.title("ë¶€ìì¬ ì…ê³  / í™˜ì… ê´€ë¦¬")
st.write("í˜„ì¬ PDF í°íŠ¸:", KOREAN_FONT_NAME)

menu = st.radio(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¦ ì…ê³  ì¡°íšŒ", "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°", "â†©ï¸ í™˜ì… ê´€ë¦¬"],
    horizontal=True,
)

# ==========================================
# ğŸ“¤ 1. íŒŒì¼ ì—…ë¡œë“œ íƒ­ (S3ì— ì €ì¥)
# ==========================================
if menu == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    st.subheader("ğŸ“¤ 2025ë…„ ë¶€ìì¬ ê´€ë¦¬ëŒ€ì¥ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xlsm", "xlsx"])

    if uploaded_file and s3_client is not None:
        try:
            s3_client.upload_fileobj(uploaded_file, S3_BUCKET, S3_KEY)
            # ìºì‹œ ì´ˆê¸°í™”
            load_file_from_s3.clear()
            load_excel.clear()
            st.success("S3 ì—…ë¡œë“œ ì™„ë£Œ! ë‹¤ë¥¸ íƒ­ì—ì„œ ë°ì´í„° ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    elif uploaded_file and s3_client is None:
        st.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.stop()  # ì—…ë¡œë“œ íƒ­ì—ì„œëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ


# ==========================================
# ë‚˜ë¨¸ì§€ íƒ­: S3ì—ì„œ íŒŒì¼ ë¡œë”©
# ==========================================
file_bytes = load_file_from_s3()
if file_bytes is None:
    st.warning("S3ì— ì—…ë¡œë“œëœ ê´€ë¦¬ëŒ€ì¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ] íƒ­ì—ì„œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    st.stop()

sheets = load_excel(file_bytes)

# í•„ìˆ˜ ì‹œíŠ¸ ì²´í¬
required_sheets = ["ì…ê³ ", "ì‘ì—…ì§€ì‹œ", "ìˆ˜ì£¼", "BOM", "ì¬ê³ ", "ìƒì‚°ì‹¤ì ", "ë¶ˆëŸ‰"]
missing = [s for s in required_sheets if s not in sheets]
if missing:
    st.error(f"ë‹¤ìŒ ì‹œíŠ¸ê°€ ì—‘ì…€ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
    st.stop()

df_in_raw = sheets["ì…ê³ "]
df_job_raw = sheets["ì‘ì—…ì§€ì‹œ"]
df_suju_raw = sheets["ìˆ˜ì£¼"]
df_bom_raw = sheets["BOM"]
df_stock_raw = sheets["ì¬ê³ "]
df_result_raw = sheets["ìƒì‚°ì‹¤ì "]
df_defect_raw = sheets["ë¶ˆëŸ‰"]

# ì§‘ê³„ëŠ” í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹œ ìµœì´ˆ 1íšŒ
if "aggregates" not in st.session_state:
    st.session_state["aggregates"] = None


# ============================
# 2. ì…ê³  ì¡°íšŒ íƒ­
# ============================
if menu == "ğŸ“¦ ì…ê³  ì¡°íšŒ":
    st.header("ğŸ“¦ ì…ê³  ì¡°íšŒ")
    st.caption("ìš”ì²­ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì…ê³  ë‚´ì—­ì„ ì¡°íšŒí•©ë‹ˆë‹¤.")

    # ì…ê³  ì‹œíŠ¸ ì›ë³¸
    df_in = df_in_raw.copy()

    # ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ ì°¾ê¸°
    req_date_col = pick_col(df_in, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
    if req_date_col is None:
        st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        # ë‚ ì§œ ì»¬ëŸ¼ ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜
        df_in[req_date_col] = pd.to_datetime(df_in[req_date_col], errors="coerce").dt.date

        # ğŸ”¹ ê¸°ë³¸ ë²”ìœ„: ì–´ì œ ~ ì˜¤ëŠ˜
        today = date.today()
        default_start = today - timedelta(days=1)

        start_date, end_date = st.date_input(
            "ìš”ì²­ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
            (default_start, today),
            key="in_date_range",
        )

        # Streamlit ë²„ì „ì— ë”°ë¼ tuple ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ì„œ ë°©ì–´ ì½”ë“œ
        if isinstance(start_date, (tuple, list)):
            start_date, end_date = start_date

        # í•„í„° ë§ˆìŠ¤í¬
        mask = (df_in[req_date_col] >= start_date) & (df_in[req_date_col] <= end_date)

        # ê° ì—´ ì»¬ëŸ¼ ì°¾ê¸°
        col_req_no   = pick_col(df_in, "L", ["ìš”ì²­ë²ˆí˜¸"])
        col_part     = pick_col(df_in, "M", ["í’ˆë²ˆ"])
        col_name     = pick_col(df_in, "N", ["í’ˆëª…"])
        col_req_qty  = pick_col(df_in, "P", ["ìš”ì²­ìˆ˜ëŸ‰"])
        col_erp_out  = pick_col(df_in, "Q", ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "ë¶ˆì¶œìˆ˜ëŸ‰"])
        col_real_in  = pick_col(df_in, "R", ["í˜„ì¥ì‹¤ë¬¼ì…ê³ "])

        raw_cols = [c for c in [
            req_date_col,
            col_req_no,
            col_part,
            col_name,
            col_req_qty,
            col_erp_out,
            col_real_in,
        ] if c is not None]

        if not raw_cols:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_filtered = df_in.loc[mask, raw_cols].copy()

            # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë§ì¶”ê¸°
            rename_map = {}
            rename_map[req_date_col] = "ìš”ì²­ë‚ ì§œ"
            if col_req_no:  rename_map[col_req_no]  = "ìš”ì²­ë²ˆí˜¸"
            if col_part:    rename_map[col_part]    = "í’ˆë²ˆ"
            if col_name:    rename_map[col_name]    = "í’ˆëª…"
            if col_req_qty: rename_map[col_req_qty] = "ìš”ì²­ìˆ˜ëŸ‰"
            if col_erp_out: rename_map[col_erp_out] = "ERPë¶ˆì¶œìˆ˜ëŸ‰"
            if col_real_in: rename_map[col_real_in] = "í˜„ì¥ì‹¤ë¬¼ì…ê³ "

            df_filtered.rename(columns=rename_map, inplace=True)

            # ğŸ”¥ ì—‘ì…€ì—ì„œ "ë§ˆì§€ë§‰(ë§¨ ì•„ë˜) í–‰"ì´ ìœ„ë¡œ ì˜¤ë„ë¡: ì¸ë±ìŠ¤ ì—­ìˆœ ì •ë ¬
            df_filtered = df_filtered.iloc[::-1].reset_index(drop=True)

            if df_filtered.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(df_filtered, use_container_width=True)

                # CSV ë‹¤ìš´ë¡œë“œ
                csv_inbound = df_filtered.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ì´ ì¡°íšŒ ê²°ê³¼ë¥¼ CSVë¡œ ë°›ê¸°",
                    data=csv_inbound,
                    file_name=f"ì…ê³ ì¡°íšŒ_{start_date}_{end_date}.csv",
                    mime="text/csv",
                )


# ============================================================
# ğŸ” 3. ìˆ˜ì£¼ ì°¾ê¸° í™”ë©´
# ============================================================
if menu == "ğŸ” ìˆ˜ì£¼ ì°¾ê¸°":
    st.subheader("ğŸ” ìˆ˜ì£¼ ì°¾ê¸°")

    st.markdown(
        """
        **ë™ì‘ ë°©ì‹**

        1. ìš”ì²­ë‚ ì§œ(ë‹¬ë ¥)ì™€ ê¸°ì¤€ í’ˆë²ˆì„ ì…ë ¥í•œë‹¤.  
        2. BOM ì‹œíŠ¸ì˜ **Cì—´ í’ˆë²ˆ**ì—ì„œ ê¸°ì¤€ í’ˆë²ˆê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ê³ , ê·¸ í–‰ì˜ **í’ˆëª©ì½”ë“œ(Aì—´)** ê°’ì„ êµ¬í•œë‹¤.  
        3. ì´ í’ˆëª©ì½”ë“œë¥¼ **ìˆ˜ì£¼ ì‹œíŠ¸ì˜ í’ˆë²ˆ(Jì—´)**ì—ì„œ ê²€ìƒ‰í•œë‹¤.  
        4. ë§Œì•½ ì´ ë‹¨ê³„ì—ì„œ ìˆ˜ì£¼ê°€ í•˜ë‚˜ë„ ì•ˆ ë‚˜ì˜¤ë©´  
           - ë°©ê¸ˆ ì‚¬ìš©í•œ í’ˆëª©ì½”ë“œë“¤ì„ ë‹¤ì‹œ BOMì˜ **Cì—´ í’ˆë²ˆ**ì—ì„œ ê²€ìƒ‰í•´ì„œ  
           - ê·¸ í–‰ë“¤ì˜ **í’ˆëª©ì½”ë“œ(Aì—´)**(= 2ë‹¨ê³„ ìƒìœ„ í’ˆëª©ì½”ë“œ)ë¥¼ êµ¬í•˜ê³   
           - ì´ 2ë‹¨ê³„ í’ˆëª©ì½”ë“œë¥¼ ê°€ì§€ê³  ìˆ˜ì£¼ ì‹œíŠ¸ì˜ í’ˆë²ˆ(Jì—´)ì„ ë‹¤ì‹œ ê²€ìƒ‰í•œë‹¤.  
        5. ìµœì¢…ì ìœ¼ë¡œ ì–»ì–´ì§„ ìˆ˜ì£¼ë“¤ ì¤‘ **ì¡°ì •ë‚©ê¸°ì¼ì(Gì—´)** ê¸°ì¤€ìœ¼ë¡œ  
           - ë¨¼ì €: ìš”ì²­ë‚ ì§œë¡œë¶€í„° **1ê°œì›” ì´ë‚´**  
           - ì—†ìœ¼ë©´: ìš”ì²­ë‚ ì§œë¡œë¶€í„° **1ë…„ ì´ë‚´** & **ìµœê·¼ì¼ìˆ˜ë¡ ìœ„ì—** ì˜¤ë„ë¡ ì •ë ¬í•´ ë³´ì—¬ì¤€ë‹¤.
        """
    )

    col1, col2 = st.columns(2)
    with col1:
        request_date = st.date_input(
            "ìš”ì²­ë‚ ì§œ", value=date.today(), key="suju_req_date"
        )
    with col2:
        base_part = st.text_input("ê¸°ì¤€ í’ˆë²ˆ", key="suju_find_part")

    if request_date and base_part:
        df_bom = df_bom_raw.copy()
        bom_cols = list(df_bom.columns)

        # Aì—´ = í’ˆëª©ì½”ë“œ, Bì—´ = í’ˆëª…
        bom_item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        bom_name_col = (
            "í’ˆëª…"
            if "í’ˆëª…" in bom_cols
            else (bom_cols[1] if len(bom_cols) > 1 else bom_cols[0])
        )
        # Cì—´ = ìì¬ í’ˆë²ˆ
        bom_component_col = (
            bom_cols[2]
            if len(bom_cols) > 2
            else ("í’ˆë²ˆ" if "í’ˆë²ˆ" in bom_cols else bom_cols[-1])
        )

        if bom_component_col not in df_bom.columns:
            st.error(f"BOM ì‹œíŠ¸ì—ì„œ Cì—´ í’ˆë²ˆ ì»¬ëŸ¼({bom_component_col})ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            df_bom_hit = df_bom[df_bom[bom_component_col] == base_part]

            if df_bom_hit.empty:
                st.warning("BOM ì‹œíŠ¸ì˜ Cì—´ í’ˆë²ˆì—ì„œ í•´ë‹¹ ê¸°ì¤€ í’ˆë²ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                item_codes = df_bom_hit[bom_item_col].dropna().unique().tolist()
                st.write("ê¸°ì¤€ í’ˆë²ˆì„ ì‚¬ìš©í•˜ëŠ” 1ì°¨ ì™„ì„±í’ˆ(í’ˆëª©ì½”ë“œ):", item_codes)

                df_suju = df_suju_raw.copy()
                suju_cols = list(df_suju.columns)

                suju_part_col = (
                    suju_cols[9]
                    if len(suju_cols) > 9
                    else ("í’ˆë²ˆ" if "í’ˆë²ˆ" in suju_cols else suju_cols[-1])
                )
                suju_due_col = (
                    suju_cols[6]
                    if len(suju_cols) > 6
                    else (
                        "ì¡°ì •ë‚©ê¸°ì¼ì"
                        if "ì¡°ì •ë‚©ê¸°ì¼ì" in suju_cols
                        else suju_cols[-1]
                    )
                )

                df_suju[suju_due_col] = pd.to_datetime(
                    df_suju[suju_due_col], errors="coerce"
                ).dt.date

                df_suju_hit = df_suju[df_suju[suju_part_col].isin(item_codes)].copy()

                if df_suju_hit.empty:
                    fallback_item_codes = set()
                    for code in item_codes:
                        df_bom_lvl2 = df_bom[df_bom[bom_component_col] == code]
                        if not df_bom_lvl2.empty:
                            lvl2_items = (
                                df_bom_lvl2[bom_item_col].dropna().unique().tolist()
                            )
                            fallback_item_codes.update(lvl2_items)

                    if fallback_item_codes:
                        fallback_item_codes = list(fallback_item_codes)
                        st.info(
                            "1ì°¨ í’ˆëª©ì½”ë“œë¡œëŠ” ìˆ˜ì£¼ê°€ ì—†ì–´, "
                            "ê·¸ í’ˆëª©ì½”ë“œë“¤ì„ ë‹¤ì‹œ BOM Cì—´ì—ì„œ í’ˆë²ˆìœ¼ë¡œ ë³´ê³  ì–»ì€ 2ì°¨ í’ˆëª©ì½”ë“œë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤."
                        )
                        st.write("2ì°¨ í’ˆëª©ì½”ë“œ ëª©ë¡:", fallback_item_codes)
                        df_suju_hit = df_suju[
                            df_suju[suju_part_col].isin(fallback_item_codes)
                        ].copy()

                if df_suju_hit.empty:
                    st.info(
                        "ìˆ˜ì£¼ ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(Jì—´)ì´ í•´ë‹¹(1ì°¨/2ì°¨) í’ˆëª©ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                    )
                else:
                    one_month_later = request_date + timedelta(days=30)
                    one_year_later = request_date + timedelta(days=365)

                    df_1m = df_suju_hit[
                        df_suju_hit[suju_due_col].between(request_date, one_month_later)
                    ].copy()

                    if not df_1m.empty:
                        st.success("ìš”ì²­ë‚ ì§œë¡œë¶€í„° 1ê°œì›” ì´ë‚´ì˜ ìˆ˜ì£¼ê°€ ìˆìŠµë‹ˆë‹¤.")
                        df_show = df_1m
                    else:
                        df_1y = df_suju_hit[
                            df_suju_hit[suju_due_col].between(request_date, one_year_later)
                        ].copy()

                        if df_1y.empty:
                            st.warning(
                                "ìš”ì²­ë‚ ì§œë¡œë¶€í„° 1ë…„ ì´ë‚´ì— í•´ë‹¹ í’ˆëª©ì½”ë“œì˜ ìˆ˜ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                            )
                            df_show = pd.DataFrame()
                        else:
                            st.info(
                                "1ê°œì›” ì´ë‚´ ìˆ˜ì£¼ëŠ” ì—†ê³ , 1ë…„ ì´ë‚´ ìˆ˜ì£¼ë¥¼ ì¡°ì •ë‚©ê¸°ì¼ì ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬í•´ ë³´ì—¬ì¤ë‹ˆë‹¤."
                            )
                            df_1y.sort_values(
                                by=suju_due_col, ascending=False, inplace=True
                            )
                            df_show = df_1y

                    if not df_show.empty:
                        display_cols = []
                        for c in [
                            suju_part_col,
                            "í’ˆëª…",
                            "ìˆ˜ì£¼ë²ˆí˜¸",
                            suju_due_col,
                            "ìˆ˜ëŸ‰",
                            "ë§¤ì¶œì²˜",
                        ]:
                            if c in df_show.columns:
                                display_cols.append(c)
                        st.dataframe(df_show[display_cols], use_container_width=True)

                        # ìˆ˜ì£¼ë²ˆí˜¸ë³„ ì§€ì‹œë²ˆí˜¸ / ì™„ì„±í’ˆë²ˆ / ì™„ì„±í’ˆëª… (ì‘ì—…ì§€ì‹œ ì°¸ì¡°)
                        st.markdown(
                            "#### ìˆ˜ì£¼ë²ˆí˜¸ë³„ ì§€ì‹œë²ˆí˜¸ / ì™„ì„±í’ˆë²ˆ / ì™„ì„±í’ˆëª… (ì‘ì—…ì§€ì‹œ ì°¸ì¡°)"
                        )

                        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_show.columns:
                            suju_values = (
                                df_show["ìˆ˜ì£¼ë²ˆí˜¸"]
                                .dropna()
                                .astype(str)
                                .unique()
                                .tolist()
                            )

                            job_suju_col = pick_col(df_job_raw, "A", ["ìˆ˜ì£¼ë²ˆí˜¸"])
                            job_jisi_col = pick_col(df_job_raw, "B", ["ì§€ì‹œë²ˆí˜¸"])
                            job_fin_part_col = pick_col(
                                df_job_raw, "K", ["ì™„ì„±í’ˆë²ˆ", "í’ˆë²ˆ"]
                            )
                            job_fin_name_col = pick_col(
                                df_job_raw, "L", ["ì™„ì„±í’ˆëª…", "í’ˆëª…"]
                            )

                            if all(
                                [
                                    job_suju_col,
                                    job_jisi_col,
                                    job_fin_part_col,
                                    job_fin_name_col,
                                ]
                            ):
                                df_job_map = df_job_raw[
                                    [
                                        job_suju_col,
                                        job_jisi_col,
                                        job_fin_part_col,
                                        job_fin_name_col,
                                    ]
                                ].copy()
                                df_job_map.columns = [
                                    "ìˆ˜ì£¼ë²ˆí˜¸",
                                    "ì§€ì‹œë²ˆí˜¸",
                                    "ì™„ì„±í’ˆë²ˆ",
                                    "ì™„ì„±í’ˆëª…",
                                ]
                                df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"] = df_job_map[
                                    "ìˆ˜ì£¼ë²ˆí˜¸"
                                ].astype(str)
                                df_job_filtered = df_job_map[
                                    df_job_map["ìˆ˜ì£¼ë²ˆí˜¸_str"].isin(suju_values)
                                ].drop(columns=["ìˆ˜ì£¼ë²ˆí˜¸_str"])

                                if df_job_filtered.empty:
                                    st.info(
                                        "ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ í•´ë‹¹ ìˆ˜ì£¼ë²ˆí˜¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                    )
                                else:
                                    df_job_filtered = df_job_filtered.drop_duplicates(
                                        subset=[
                                            "ìˆ˜ì£¼ë²ˆí˜¸",
                                            "ì§€ì‹œë²ˆí˜¸",
                                            "ì™„ì„±í’ˆë²ˆ",
                                            "ì™„ì„±í’ˆëª…",
                                        ]
                                    )
                                    st.dataframe(
                                        df_job_filtered[
                                            [
                                                "ìˆ˜ì£¼ë²ˆí˜¸",
                                                "ì§€ì‹œë²ˆí˜¸",
                                                "ì™„ì„±í’ˆë²ˆ",
                                                "ì™„ì„±í’ˆëª…",
                                            ]
                                        ],
                                        use_container_width=True,
                                    )
                            else:
                                st.info(
                                    "ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì—ì„œ ìˆ˜ì£¼ë²ˆí˜¸(Aì—´), ì§€ì‹œë²ˆí˜¸(Bì—´), ì™„ì„±í’ˆë²ˆ(Kì—´), ì™„ì„±í’ˆëª…(Lì—´)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                                )
                        else:
                            st.info(
                                "ìˆ˜ì£¼ ì°¾ê¸° ê²°ê³¼ì— 'ìˆ˜ì£¼ë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ì–´ ì‘ì—…ì§€ì‹œ ë§¤ì¹­ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            )

# ============================================================
# â†©ï¸ 4. í™˜ì… ê´€ë¦¬ í™”ë©´ (+ í™˜ì… ì˜ˆìƒì¬ê³ )
# ============================================================
if menu == "â†©ï¸ í™˜ì… ê´€ë¦¬":
    st.subheader("â†©ï¸ í™˜ì… ê´€ë¦¬")

    # í™˜ì… ê´€ë¦¬ í…Œì´ë¸” êµ¬ì¡° (ë‚´ë¶€ ê³„ì‚°ìš©)
    return_cols = [
        "ìˆ˜ì£¼ë²ˆí˜¸",
        "ì§€ì‹œë²ˆí˜¸",
        "ìƒì‚°ê³µì •",
        "ìƒì‚°ì‹œì‘ì¼",
        "ìƒì‚°ì¢…ë£Œì¼",
        "ì¢…ë£Œì¡°ê±´",
        "í™˜ì…ì¼",
        "í™˜ì…ì£¼ì°¨",
        "ì™„ì„±í’ˆë²ˆ",
        "ì œí’ˆëª…",  # ì™„ì„±í’ˆëª…
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë‹¨ìœ„ìˆ˜ëŸ‰",
        "ERPì¬ê³ ",
        "ì‹¤ì¬ê³ ì˜ˆìƒ",
        "í™˜ì…ê²°ì •ìˆ˜",
        "ì°¨ì´",
        "ë¹„ê³ ",
    ]
    df_return = ensure_session_df("í™˜ì…ê´€ë¦¬", return_cols)
    df_full = ensure_session_df("í™˜ì…ì¬ê³ ì˜ˆìƒ", CSV_COLS)
    # ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)
    st.markdown("### ğŸ” ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ ê¸°ì¤€)")

    search_keyword = st.text_input(
        "ì œí’ˆëª…ìœ¼ë¡œ ìˆ˜ì£¼ ê²€ìƒ‰ (ì…ê³  ì‹œíŠ¸ Eì—´, ë¶€ë¶„ ì¼ì¹˜)",
        key="return_search_product",
        placeholder="ì˜ˆ: ì•°í”Œ, í¬ë¦¼, ë§ˆìŠ¤í¬íŒ© ë“±"
    )

    if search_keyword:
        df_in_search = df_in_raw.copy()

        # ìš”ì²­ë‚ ì§œ(Kì—´), ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ ì°¾ê¸°
        in_req_date_col = pick_col(df_in_search, "K", ["ìš”ì²­ë‚ ì§œ", "ìš”ì²­ì¼"])
        in_prod_name_col = pick_col(df_in_search, "E", ["ì œí’ˆëª…", "í’ˆëª…"])

        if in_req_date_col is None or in_prod_name_col is None:
            st.error("ì…ê³  ì‹œíŠ¸ì—ì„œ ìš”ì²­ë‚ ì§œ(Kì—´) ë˜ëŠ” ì œí’ˆëª…(Eì—´) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ë‚ ì§œí˜• ë³€í™˜
            df_in_search[in_req_date_col] = pd.to_datetime(
                df_in_search[in_req_date_col], errors="coerce"
            ).dt.date

            today = date.today()
            start_date = today - timedelta(days=30)  # ìµœê·¼ 1ê°œì›”

            # ë‚ ì§œ í•„í„°: í˜„ì¬ë¡œë¶€í„° 1ë‹¬ ì´ë‚´
            mask_date = df_in_search[in_req_date_col].between(start_date, today)

            # ì œí’ˆëª… ë¶€ë¶„ ì¼ì¹˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            mask_name = df_in_search[in_prod_name_col].astype(str).str.contains(
                search_keyword, case=False, na=False
            )

            df_hit = df_in_search[mask_date & mask_name].copy()

            if df_hit.empty:
                st.info("ìµœê·¼ 1ê°œì›” ì´ë‚´ì— í•´ë‹¹ ì œí’ˆëª…ì´ í¬í•¨ëœ ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì¶”ê°€ë¡œ ë³´ì—¬ì¤„ ì»¬ëŸ¼ë“¤: ìˆ˜ì£¼ë²ˆí˜¸(B), ì§€ì‹œë²ˆí˜¸(C), í’ˆë²ˆ(M)
                in_suju_col = pick_col(df_hit, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
                in_jisi_col = pick_col(df_hit, "C", ["ì§€ì‹œë²ˆí˜¸"])
                in_part_col = pick_col(df_hit, "M", ["í’ˆë²ˆ"])

                show_cols = []
                for c in [
                    in_req_date_col,
                    in_suju_col,
                    in_jisi_col,
                    in_prod_name_col,
                    in_part_col,
                ]:
                    if c and c in df_hit.columns:
                        show_cols.append(c)

                df_show = df_hit[show_cols].copy()

                # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ì •ë¦¬
                rename_map = {}
                rename_map[in_req_date_col] = "ìš”ì²­ë‚ ì§œ"
                if in_suju_col:      rename_map[in_suju_col] = "ìˆ˜ì£¼ë²ˆí˜¸"
                if in_jisi_col:      rename_map[in_jisi_col] = "ì§€ì‹œë²ˆí˜¸"
                if in_prod_name_col: rename_map[in_prod_name_col] = "ì œí’ˆëª…"
                if in_part_col:      rename_map[in_part_col] = "í’ˆë²ˆ"

                df_show.rename(columns=rename_map, inplace=True)

                # í’ˆë²ˆ ì œê±°
                if "í’ˆë²ˆ" in df_show.columns:
                    df_show = df_show.drop(columns=["í’ˆë²ˆ"])

                # ìš”ì²­ë‚ ì§œ + ìˆ˜ì£¼ë²ˆí˜¸ + ì§€ì‹œë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œë§Œ ì¤‘ë³µ ì œê±°
                uniq_cols = [c for c in ["ìš”ì²­ë‚ ì§œ", "ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸"] if c in df_show.columns]
                df_show = df_show.drop_duplicates(subset=uniq_cols, keep="first")


                st.dataframe(df_show, use_container_width=True)

    
    # ----- ì…ë ¥ 1ì¤„ (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, ìƒì‚°ê³µì •, ì¢…ë£Œì¡°ê±´) -----
    col_suju, col_jisi, col_proc, col_reason = st.columns(4)
    with col_suju:
        suju_no = st.text_input("ìˆ˜ì£¼ë²ˆí˜¸", key="return_suju_no")
    with col_jisi:
        selected_jisi = None  # ì˜µì…˜ ìƒì„± í›„ ì±„ì›€
    with col_proc:
        process_options = [
            "4ì¸µ ë•ìš©",
            "4ì¸µ ë¡œí„°ë¦¬",
            "4ì¸µ ë¸”ë¦¬ìŠ¤í„°",
            "5ì¸µ ë•ìš©",
            "5ì¸µ ê¸°ì´ˆ",
            "6ì¸µ ìŠ¤í‹±",
            "6ì¸µ íŒŒìš°ì¹˜",
            "6ì¸µ ìŠ¤í‚¨íŒ©",
        ]
        process_value = st.selectbox(
            "ìƒì‚°ê³µì •", process_options, key="return_process"
        )
    with col_reason:
        finish_reason = st.text_input("ì¢…ë£Œì¡°ê±´", key="return_finish_reason")

    # ìˆ˜ì£¼ë²ˆí˜¸ ê¸°ë°˜ ì§€ì‹œë²ˆí˜¸/ì™„ì„±í’ˆë²ˆ í›„ë³´ ì°¾ê¸°
    jisi_options = []
    finished_part_selected = None

    if suju_no:
        if "ìˆ˜ì£¼ë²ˆí˜¸" in df_job_raw.columns:
            df_job_suju = df_job_raw[df_job_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()

            finished_parts = (
                df_job_suju["í’ˆë²ˆ"].dropna().unique().tolist()
                if "í’ˆë²ˆ" in df_job_suju.columns
                else []
            )
            if len(finished_parts) > 1:
                finished_part_selected = st.selectbox(
                    "ì™„ì„±í’ˆë²ˆ", finished_parts, key="return_finished_part"
                )
                df_job_suju = df_job_suju[
                    df_job_suju["í’ˆë²ˆ"] == finished_part_selected
                ]
            elif len(finished_parts) == 1:
                finished_part_selected = finished_parts[0]

            if "ì§€ì‹œë²ˆí˜¸" in df_job_suju.columns:
                jisi_options = df_job_suju["ì§€ì‹œë²ˆí˜¸"].dropna().unique().tolist()
            else:
                st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ì§€ì‹œë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ì‘ì—…ì§€ì‹œ ì‹œíŠ¸ì— 'ìˆ˜ì£¼ë²ˆí˜¸' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ì§€ì‹œë²ˆí˜¸ ì„ íƒ (ìˆ˜ì£¼ë²ˆí˜¸ ì…ë ¥ í›„)
    if jisi_options:
        selected_jisi = col_jisi.selectbox(
            "ì§€ì‹œë²ˆí˜¸", jisi_options, key="return_jisi"
        )
    else:
        with col_jisi:
            st.write("ì§€ì‹œë²ˆí˜¸: ì„ íƒ ì—†ìŒ")

    # ----- ìƒì‚° ì‹œì‘/ì¢…ë£Œì¼ -----
    production_start_date = None
    production_end_date = None
    if (
        suju_no
        and "ìˆ˜ì£¼ë²ˆí˜¸" in df_result_raw.columns
        and "ìƒì‚°ì¼ì" in df_result_raw.columns
    ):
        df_res_suju = df_result_raw[df_result_raw["ìˆ˜ì£¼ë²ˆí˜¸"] == suju_no].copy()
        df_res_suju["ìƒì‚°ì¼ì"] = pd.to_datetime(
            df_res_suju["ìƒì‚°ì¼ì"], errors="coerce"
        )
        if not df_res_suju["ìƒì‚°ì¼ì"].isna().all():
            production_start_date = df_res_suju["ìƒì‚°ì¼ì"].min().date()
            production_end_date = df_res_suju["ìƒì‚°ì¼ì"].max().date()

    st.write(f"ìƒì‚°ì‹œì‘ì¼: {production_start_date or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ìƒì‚°ì¢…ë£Œì¼: {production_end_date or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- í™˜ì…ì¼/í™˜ì…ì£¼ì°¨ -----
    return_date = date.today()
    return_week = get_week_of_month(return_date)
    st.write(f"í™˜ì…ì¼: {return_date}")
    st.write(f"í™˜ì…ì£¼ì°¨: {return_week}")

    # ----- ì™„ì„±í’ˆë²ˆ / ì™„ì„±í’ˆëª… (BOMì—ì„œ í’ˆëª… ê°€ì ¸ì˜¤ê¸°) -----
    finished_part = finished_part_selected
    finished_name = None

    # 1ì°¨: ì§€ì‹œë²ˆí˜¸ì—ì„œ ì™„ì„±í’ˆë²ˆ ìœ ì¶” (ì—†ì„ ë•Œë§Œ)
    if not finished_part and selected_jisi and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns:
        df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
        if not df_job_jisi.empty and "í’ˆë²ˆ" in df_job_jisi.columns:
            finished_part = df_job_jisi["í’ˆë²ˆ"].iloc[0]

    # BOMì—ì„œ ì™„ì„±í’ˆëª… ì°¾ê¸° (í’ˆëª©ì½”ë“œ=Aì—´, í’ˆëª…=Bì—´)
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        name_col = (
            "í’ˆëª…"
            if "í’ˆëª…" in bom_cols
            else (bom_cols[1] if len(bom_cols) > 1 else bom_cols[0])
        )

        df_bom_match = df_bom_raw[df_bom_raw[item_col] == finished_part]
        if not df_bom_match.empty:
            finished_name = df_bom_match[name_col].iloc[0]
        else:
            if (
                selected_jisi
                and "ì§€ì‹œë²ˆí˜¸" in df_job_raw.columns
                and "í’ˆëª…" in df_job_raw.columns
            ):
                df_job_jisi = df_job_raw[df_job_raw["ì§€ì‹œë²ˆí˜¸"] == selected_jisi]
                if not df_job_jisi.empty:
                    finished_name = df_job_jisi["í’ˆëª…"].iloc[0]

    st.write(f"ì™„ì„±í’ˆë²ˆ: {finished_part or 'ë°ì´í„° ì—†ìŒ'}")
    st.write(f"ì™„ì„±í’ˆëª…: {finished_name or 'ë°ì´í„° ì—†ìŒ'}")

    # ----- BOM ìì¬ ëª©ë¡ -----
    bom_component_df = pd.DataFrame()
    if finished_part is not None:
        bom_cols = list(df_bom_raw.columns)
        item_col = "í’ˆëª©ì½”ë“œ" if "í’ˆëª©ì½”ë“œ" in bom_cols else bom_cols[0]
        bom_part_cols = [c for c in bom_cols if "í’ˆë²ˆ" in c]
        bom_name_cols = [c for c in bom_cols if "í’ˆëª…" in c]

        bom_component_col2 = (
            bom_part_cols[1]
            if len(bom_part_cols) >= 2
            else (bom_part_cols[0] if bom_part_cols else None)
        )
        bom_name_col2 = (
            bom_name_cols[1]
            if len(bom_name_cols) >= 2
            else (bom_name_cols[0] if bom_name_cols else None)
        )

        df_bom_finished = df_bom_raw[df_bom_raw[item_col] == finished_part].copy()
        if df_bom_finished.empty:
            st.warning("BOMì—ì„œ í•´ë‹¹ ì™„ì„±í’ˆë²ˆ(í’ˆëª©ì½”ë“œ)ì„ ì‚¬ìš©í•˜ëŠ” ìì¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            subset_cols = []
            if bom_component_col2 and bom_component_col2 in df_bom_finished.columns:
                subset_cols.append(bom_component_col2)
            if bom_name_col2 and bom_name_col2 in df_bom_finished.columns:
                subset_cols.append(bom_name_col2)
            if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_finished.columns:
                subset_cols.append("ë‹¨ìœ„ìˆ˜ëŸ‰")

            if subset_cols:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates(subset=subset_cols)
            else:
                df_bom_fin_uniq = df_bom_finished.drop_duplicates()

            bom_component_df = pd.DataFrame(
                {
                    "ì„ íƒ": True,
                    "ì™„ì„±í’ˆë²ˆ": df_bom_fin_uniq[item_col],
                    "í’ˆë²ˆ": df_bom_fin_uniq[bom_component_col2]
                    if bom_component_col2 in df_bom_fin_uniq.columns
                    else "",
                    "í’ˆëª…": df_bom_fin_uniq[bom_name_col2]
                    if bom_name_col2 in df_bom_fin_uniq.columns
                    else "",
                    "ë‹¨ìœ„ìˆ˜ëŸ‰": df_bom_fin_uniq["ë‹¨ìœ„ìˆ˜ëŸ‰"]
                    if "ë‹¨ìœ„ìˆ˜ëŸ‰" in df_bom_fin_uniq.columns
                    else "",
                }
            )

            st.markdown("BOM ìì¬ ëª©ë¡ì—ì„œ í™˜ì… ëŒ€ìƒ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            bom_component_df = st.data_editor(
                bom_component_df,
                use_container_width=True,
                num_rows="dynamic",
                key="bom_component_editor",
            )

    # ----- í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼ -----
    if st.button(
        "âœ… í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì„ íƒëœ ìì¬ë¥¼ í™˜ì… ì˜ˆìƒì¬ê³ ì— ë°˜ì˜)",
        key="btn_return_load",
    ):
        if not suju_no:
            st.error("ìˆ˜ì£¼ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not selected_jisi:
            st.error("ì§€ì‹œë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif bom_component_df.empty:
            st.error("BOM ìì¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_rows = bom_component_df[bom_component_df["ì„ íƒ"] == True].copy()
            if selected_rows.empty:
                st.warning("ì„ íƒëœ ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                new_rows = []
                for _, row in selected_rows.iterrows():
                    part = row["í’ˆë²ˆ"]
                    name = row["í’ˆëª…"]
                    unit = row["ë‹¨ìœ„ìˆ˜ëŸ‰"]

                    new_rows.append(
                        {
                            "ìˆ˜ì£¼ë²ˆí˜¸": suju_no,
                            "ì§€ì‹œë²ˆí˜¸": selected_jisi,
                            "ìƒì‚°ê³µì •": process_value,
                            "ìƒì‚°ì‹œì‘ì¼": production_start_date,
                            "ìƒì‚°ì¢…ë£Œì¼": production_end_date,
                            "ì¢…ë£Œì¡°ê±´": finish_reason,
                            "í™˜ì…ì¼": return_date,
                            "í™˜ì…ì£¼ì°¨": return_week,
                            "ì™„ì„±í’ˆë²ˆ": finished_part,
                            "ì œí’ˆëª…": finished_name,  # ì™„ì„±í’ˆëª…
                            "í’ˆë²ˆ": part,
                            "í’ˆëª…": name,
                            "ë‹¨ìœ„ìˆ˜ëŸ‰": unit,
                            "ERPì¬ê³ ": None,
                            "ì‹¤ì¬ê³ ì˜ˆìƒ": None,
                            "í™˜ì…ê²°ì •ìˆ˜": None,
                            "ì°¨ì´": None,
                            "ë¹„ê³ ": "",
                        }
                    )

                df_new = pd.DataFrame(new_rows)

                # ê¸°ì¡´ + ì‹ ê·œ í•©ì³ì„œ [ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ] ê¸°ì¤€ ì¤‘ë³µ ì œê±°
                df_return = pd.concat([df_return, df_new], ignore_index=True)
                df_return = df_return.drop_duplicates(
                    subset=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"], keep="last"
                ).reset_index(drop=True)
                st.session_state["í™˜ì…ê´€ë¦¬"] = df_return

                # ì§‘ê³„ê°€ ì•„ì§ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ê³„ì‚°
                if st.session_state["aggregates"] is None:
                    st.session_state["aggregates"] = build_aggregates(
                        df_in_raw,
                        df_job_raw,
                        df_result_raw,
                        df_defect_raw,
                        df_stock_raw,
                    )

                aggs = st.session_state["aggregates"]

                # ì§‘ê³„ ì‚¬ìš©í•´ì„œ í™˜ì… ì˜ˆìƒì¬ê³  ê³„ì‚°
                df_full = recalc_return_expectation(df_return, aggs)
                st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = df_full

                # ===== ERPì¬ê³  ì§ì ‘ ë§¤ì¹­ íŒ¨ì¹˜ =====
                stock_part_col = pick_col(df_stock_raw, "D", ["í’ˆë²ˆ"])
                stock_qty_col  = pick_col(df_stock_raw, "N", ["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"])

                if stock_part_col and stock_qty_col:
                    stock_map = dict(
                        zip(
                            df_stock_raw[stock_part_col].astype(str),
                            df_stock_raw[stock_qty_col].apply(safe_num)
                        )
                    )
                    df_full["ERPì¬ê³ "] = df_full["í’ˆë²ˆ"].astype(str).map(stock_map).fillna(0)
                else:
                    st.warning("ì¬ê³  ì‹œíŠ¸ì—ì„œ í’ˆë²ˆ(D) ë˜ëŠ” ì‹¤ì¬ê³ ìˆ˜ëŸ‰(N) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.success(
                    f"ì„ íƒëœ ìì¬ {len(df_new)}ê°œì— ëŒ€í•´ í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤."
                )

    # ----- í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™” -----
    if st.button("ğŸ§¹ í™˜ì… ì˜ˆìƒì¬ê³  ì´ˆê¸°í™”", key="btn_clear_expect"):
        st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"] = pd.DataFrame(columns=CSV_COLS)
        df_full = st.session_state["í™˜ì…ì¬ê³ ì˜ˆìƒ"]
        st.success("í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ----- í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„° í‘œì‹œ + CSV + PDF + ì½”ë©˜íŠ¸ -----
    st.markdown("### í™˜ì… ì˜ˆìƒì¬ê³  ë°ì´í„°")

    df_full = st.session_state.get(
        "í™˜ì…ì¬ê³ ì˜ˆìƒ", pd.DataFrame(columns=CSV_COLS)
    )

    if df_full.empty:
        st.write("í™˜ì… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹¤í–‰í•˜ë©´ ì´ê³³ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        # í™”ë©´ìš©: ê³„ì‚°ëœ df_full ê·¸ëŒ€ë¡œ VISIBLE_COLS ê¸°ì¤€ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°
        df_visible = df_full[[c for c in VISIBLE_COLS if c in df_full.columns]].copy()
        st.dataframe(df_visible, use_container_width=True)

        # ---------- í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©) ----------
        merge_choices = {}
        work = df_full.copy()

        if "í’ˆë²ˆ" in work.columns and "ìˆ˜ì£¼ë²ˆí˜¸" in work.columns:
            suju_counts = work.groupby("í’ˆë²ˆ")["ìˆ˜ì£¼ë²ˆí˜¸"].nunique()
            dup_parts = suju_counts[suju_counts > 1].index.tolist()

            if dup_parts:
                st.markdown("#### í’ˆë²ˆë³„ ìˆ˜ì£¼ë²ˆí˜¸ ì„ íƒ (CSV í†µí•©ìš©)")
                for part in dup_parts:
                    sub = work[work["í’ˆë²ˆ"] == part]
                    combos = sub[["ìˆ˜ì£¼ë²ˆí˜¸", "ì™„ì„±í’ˆëª…"]].drop_duplicates()

                    options = [
                        f"{str(row['ìˆ˜ì£¼ë²ˆí˜¸'])} {str(row['ì™„ì„±í’ˆëª…'])}"
                        for _, row in combos.iterrows()
                    ]
                    if not options:
                        continue

                    key = f"merge_choice_{part}"
                    default = st.session_state.get(key, options[0])
                    try:
                        default_index = options.index(default)
                    except ValueError:
                        default_index = 0

                    choice = st.selectbox(
                        f"í’ˆë²ˆ {part} - ìˆ˜ì£¼/ì™„ì„±í’ˆëª… ì„ íƒ",
                        options,
                        index=default_index,
                        key=key,
                    )
                    merge_choices[part] = choice

        # ---------- 1ë‹¨ê³„: (ìˆ˜ì£¼ë²ˆí˜¸, ì§€ì‹œë²ˆí˜¸, í’ˆë²ˆ) ë™ì¼í•œ í–‰ ë¨¼ì € í†µí•© ----------
        key_cols = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"]
        key_cols = [c for c in key_cols if c in work.columns]

        if key_cols:
            agg_dict_step1 = {}
            for col in work.columns:
                if col in key_cols:
                    continue
                if col in ["ERPë¶ˆì¶œìˆ˜ëŸ‰", "í˜„ì¥ì‹¤ë¬¼ì…ê³ "]:
                    agg_dict_step1[col] = "sum"
                else:
                    agg_dict_step1[col] = "first"

            work = work.groupby(key_cols, as_index=False).agg(agg_dict_step1)

        # ---------- 2ë‹¨ê³„: í’ˆë²ˆ ë‹¨ìœ„ë¡œ ìµœì¢… í†µí•© ----------
        result_rows = []

        header_cols = [
            "ìˆ˜ì£¼ë²ˆí˜¸",
            "ì§€ì‹œë²ˆí˜¸",
            "ìƒì‚°ê³µì •",
            "ìƒì‚°ì‹œì‘ì¼",
            "ìƒì‚°ì¢…ë£Œì¼",
            "ì¢…ë£Œì¡°ê±´",
            "í™˜ì…ì¼",
            "í™˜ì…ì£¼ì°¨",
            "ì™„ì„±í’ˆë²ˆ",
            "ì™„ì„±í’ˆëª…",
            "í’ˆëª…",
        ]

        sum_cols = [
            "ERPë¶ˆì¶œìˆ˜ëŸ‰",
            "í˜„ì¥ì‹¤ë¬¼ì…ê³ ",
            "ì§€ì‹œìˆ˜ëŸ‰",
            "ìƒì‚°ìˆ˜ëŸ‰",
            "QCìƒ˜í”Œ",
            "ê¸°íƒ€ìƒ˜í”Œ",
            "ì›ë¶ˆ",
            "ì‘ë¶ˆ",
            "ì˜ˆìƒì¬ê³ ",
        ]

        unit_col = "ë‹¨ìœ„ìˆ˜ëŸ‰"

        if "í’ˆë²ˆ" in work.columns:
            for part, part_df in work.groupby("í’ˆë²ˆ"):
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëŒ€í‘œ ìˆ˜ì£¼ë²ˆí˜¸ ì ìš©
                if part in merge_choices:
                    sel_suju, _, _ = merge_choices[part].partition(" ")
                    base = part_df[part_df["ìˆ˜ì£¼ë²ˆí˜¸"].astype(str) == sel_suju]
                    header_row = base.iloc[0] if not base.empty else part_df.iloc[0]
                else:
                    header_row = part_df.iloc[0]

                row = {}
                row["í’ˆë²ˆ"] = part

                # í—¤ë” ê³„ì—´: ëŒ€í‘œ ìˆ˜ì£¼/ì§€ì‹œì˜ ê°’ ìœ ì§€
                for col in header_cols:
                    row[col] = header_row.get(col, None)

                # ìˆ˜ëŸ‰ ê³„ì—´: ëª¨ë‘ í•©ê³„
                for col in sum_cols:
                    if col in part_df.columns:
                        row[col] = part_df[col].apply(safe_num).sum()
                    else:
                        row[col] = 0

                # ë‹¨ìœ„ìˆ˜ëŸ‰: í•©ì¹˜ì§€ ì•Šê³  ëŒ€í‘œê°’ only
                row[unit_col] = safe_num(header_row.get(unit_col, 0))

                # ERPì¬ê³ : ê°™ì€ í’ˆë²ˆì´ë©´ ë™ì¼ â†’ ëŒ€í‘œê°’ë§Œ
                if "ERPì¬ê³ " in part_df.columns:
                    non_na = part_df["ERPì¬ê³ "].dropna()
                    row["ERPì¬ê³ "] = (
                        safe_num(non_na.iloc[0]) if not non_na.empty else 0
                    )
                else:
                    row["ERPì¬ê³ "] = 0

                result_rows.append(row)

        grouped = pd.DataFrame(result_rows) if result_rows else work.copy()

        # CSV ì»¬ëŸ¼ ì •ë¦¬
        for col in CSV_COLS:
            if col not in grouped.columns:
                grouped[col] = None

        csv_export_df = grouped[CSV_COLS].copy()

        # CSV ë°›ê¸° ë²„íŠ¼
        csv_data = csv_export_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ CSV ë°›ê¸°",
            data=csv_data,
            file_name="í™˜ì…_ì˜ˆìƒì¬ê³ _í†µí•©.csv",
            mime="text/csv",
        )

        # PDF ë°›ê¸° ë²„íŠ¼ (ìµœì¢… CSVìš© ë°ì´í„° ê¸°ì¤€)
        if REPORTLAB_AVAILABLE and not csv_export_df.empty:

            st.markdown("### ğŸ“ PDF ìƒë‹¨ì— ë“¤ì–´ê°ˆ ë©”ëª¨ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¶™ì—¬ë„£ê¸°(Ctrl+V) í•˜ì„¸ìš”")

            pasted_text = st.text_area(
                "PDF ë©”ëª¨",
                height=100,
                key="pdf_note_text",
                placeholder="ì—¬ê¸°ì— ë©”ëª¨ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ì…ë ¥/ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”."
            )

            # í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ì„œ PDF ìƒì„± (ì´ë¯¸ì§€ëŠ” ì‚¬ìš© ì•ˆ í•¨)
            pdf_bytes = generate_pdf(csv_export_df, pasted_text=pasted_text)

            st.download_button(
                "ğŸ“„ PDF ë°›ê¸°",
                data=pdf_bytes,
                file_name="í™˜ì…_ì˜ˆìƒì¬ê³ .pdf",
                mime="application/pdf",
            )

        elif not REPORTLAB_AVAILABLE:
            st.info("PDF ì €ì¥ ê¸°ëŠ¥ì„ ì“°ë ¤ë©´ `pip install reportlab` ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ---------- ì…ê³  ì‹œíŠ¸ ë¹„ê³ (êµ¬ ë¹„ê³ 2) ì½”ë©˜íŠ¸ ----------
        in_suju_col = pick_col(df_in_raw, "B", ["ìˆ˜ì£¼ë²ˆí˜¸"])
        in_jisi_col = pick_col(df_in_raw, "C", ["ì§€ì‹œë²ˆí˜¸"])
        in_part_col = pick_col(df_in_raw, "M", ["í’ˆë²ˆ"])
        # ì´ë¦„ì„ "ë¹„ê³ "ë¡œ ë°”ê¿¨ìœ¼ë¯€ë¡œ ìš°ì„  "ë¹„ê³ "ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ Vì—´/ë¹„ê³ 2ë„ í—ˆìš©
        in_cmt_col = pick_col(df_in_raw, "V", ["ë¹„ê³ ", "ë¹„ê³ 2"])

        if in_suju_col and in_jisi_col and in_part_col and in_cmt_col:
            df_in_comment = df_in_raw[
                [in_suju_col, in_jisi_col, in_part_col, in_cmt_col]
            ].copy()
            df_in_comment.columns = ["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ", "ë¹„ê³ 2"]
            df_in_comment = df_in_comment.dropna(subset=["ë¹„ê³ 2"])

            if not df_in_comment.empty:
                df_comment_merge = df_full.merge(
                    df_in_comment,
                    how="left",
                    on=["ìˆ˜ì£¼ë²ˆí˜¸", "ì§€ì‹œë²ˆí˜¸", "í’ˆë²ˆ"],
                )

                df_comment_show = df_comment_merge.dropna(subset=["ë¹„ê³ 2"])[
                    ["í’ˆë²ˆ", "í’ˆëª…", "ë¹„ê³ 2"]
                ].drop_duplicates()

                if not df_comment_show.empty:
                    st.markdown("#### ì…ê³  ë¹„ê³  ì½”ë©˜íŠ¸")
                    for _, row in df_comment_show.iterrows():
                        st.markdown(
                            f"- **{row['í’ˆë²ˆ']} / {row['í’ˆëª…']}** : {row['ë¹„ê³ 2']}"
                        )
